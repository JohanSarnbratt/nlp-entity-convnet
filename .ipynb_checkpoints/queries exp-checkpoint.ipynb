{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from theano import *\n",
    "from lasagne.layers import InputLayer, get_output\n",
    "import lasagne\n",
    "import lasagne.layers\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "from helpers import SimpleMaxingLayer\n",
    "from wordvecs import WordVectors, EmbeddingLayer\n",
    "import json\n",
    "\n",
    "theano.config.floatX = 'float32'\n",
    "theano.config.linker = 'cvm_nogc'\n",
    "theano.config.openmp = True\n",
    "theano.config.openmp_elemwise_minsize = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/matthew/external-wiki1.json') as f:\n",
    "    queries = json.load(f)['queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9915"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8917"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([any([g['gold'] for g in v.values()]) for v in queries.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8993444276348966"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8917/9915."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "wordvectors = WordVectors(\n",
    "    fname=\"/data/matthew/GoogleNews-vectors-negative300.bin\",\n",
    "    negvectors=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/matthew/enwiki-20141208-pages-articles-multistream-redirects5.json') as f:\n",
    "    page_redirects = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wikireader import WikiRegexes, WikipediaReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PreProcessedQueries(wikipedia_dump_fname, wordvec=wordvectors, queries=queries, redirects=page_redirects):\n",
    "    \n",
    "    queried_pages = set()\n",
    "    for docs, q in queries.iteritems():\n",
    "        wordvec.tokenize(docs)\n",
    "        for sur, v in q.iteritems():\n",
    "            wordvec.tokenize(sur)\n",
    "            for link in v['vals'].keys():\n",
    "                wordvec.tokenize(link)\n",
    "                tt = WikiRegexes.convertToTitle(link)\n",
    "                #self.wordvecs.tokenize(tt)\n",
    "                queried_pages.add(tt)\n",
    "\n",
    "    added_pages = set()\n",
    "    for title in queried_pages:\n",
    "        if title in redirects:\n",
    "            #wordvec.tokenize(self.redirects[title])\n",
    "            added_pages.add(redirects[title])\n",
    "    queried_pages |= added_pages\n",
    "\n",
    "    page_content = {}\n",
    "\n",
    "    class GetWikipediaWords(WikipediaReader, WikiRegexes):\n",
    "\n",
    "        def readPage(ss, title, content):\n",
    "            tt = ss.convertToTitle(title)\n",
    "            if tt in queried_pages:\n",
    "                cnt = ss._wikiToText(content)\n",
    "                page_content[tt] = wordvec.tokenize(cnt)\n",
    "\n",
    "    GetWikipediaWords(wikipedia_dump_fname).read()\n",
    "    \n",
    "    rr = redirects\n",
    "    rq = queried_pages\n",
    "    rc = page_content\n",
    "\n",
    "    class PreProcessedQueriesCls(object):\n",
    "        \n",
    "        wordvecs = wordvec\n",
    "        queries = queries\n",
    "        redirects = rr\n",
    "        queried_pages = rq\n",
    "        page_content = rc\n",
    "        \n",
    "        \n",
    "    return PreProcessedQueriesCls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basePreProcessedQueries = PreProcessedQueries('/data/matthew/enwiki-20141208-pages-articles-multistream.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EntityVectorLinkExp(basePreProcessedQueries):\n",
    "    \n",
    "    batch_size = 200\n",
    "    \n",
    "    def __init__(self): #, wikipedia_dump_fname, wordvec=wordvectors, queries=queries, redirects=page_redirects):\n",
    "        #self.wordvecs = wordvec\n",
    "        #self.queries = queries\n",
    "        self.sentence_length = self.wordvecs.sentence_length\n",
    "        self.num_words_to_use_conv = 3\n",
    "        #self.redirects = redirects\n",
    "        #self.page_content = {}\n",
    "        #self.wikipedia_dump_fname = wikipedia_dump_fname\n",
    "        \n",
    "        #self._process_queries()\n",
    "        \n",
    "        self._setup()\n",
    "        \n",
    "#     def _process_queries(self):\n",
    "#         queried_pages = set()\n",
    "#         for docs, q in self.queries.iteritems():\n",
    "#             self.wordvecs.tokenize(docs)\n",
    "#             for sur, v in q.iteritems():\n",
    "#                 self.wordvecs.tokenize(sur)\n",
    "#                 for link in v['vals'].keys():\n",
    "#                     self.wordvecs.tokenize(link)\n",
    "#                     tt = WikiRegexes.convertToTitle(link)\n",
    "#                     #self.wordvecs.tokenize(tt)\n",
    "#                     queried_pages.add(tt)\n",
    "\n",
    "#         added_pages = set()\n",
    "#         for title in queried_pages:\n",
    "#             if title in self.redirects:\n",
    "#                 #self.wordvecs.tokenize(self.redirects[title])\n",
    "#                 added_pages.add(self.redirects[title])\n",
    "#         queried_pages |= added_pages\n",
    "        \n",
    "#         self.queried_pages = queried_pages\n",
    "                \n",
    "#         class GetWikipediaWords(WikipediaReader, WikiRegexes):\n",
    "            \n",
    "#             def readPage(ss, title, content):\n",
    "#                 tt = ss.convertToTitle(title)\n",
    "#                 if tt in queried_pages:\n",
    "#                     cnt = ss._wikiToText(content)\n",
    "#                     self.page_content[tt] = self.wordvecs.tokenize(cnt)\n",
    "        \n",
    "#         GetWikipediaWords(self.wikipedia_dump_fname).read()\n",
    "               \n",
    "        \n",
    "    def _setup(self):\n",
    "        self.x_document_input = T.imatrix('x_sent')\n",
    "        self.x_surface_text_input = T.imatrix('x_surface')\n",
    "        self.x_target_input = T.imatrix('x_target')\n",
    "        self.x_document_id = T.ivector('x_sent_id')\n",
    "        self.x_link_id = T.ivector('x_link_id')\n",
    "        self.y_score = T.vector('y')\n",
    "        \n",
    "        self.embedding_W = theano.shared(self.wordvecs.get_numpy_matrix().astype(theano.config.floatX))\n",
    "        \n",
    "        self.document_l = lasagne.layers.InputLayer(\n",
    "            (None,self.sentence_length), \n",
    "            input_var=self.x_document_input\n",
    "        )\n",
    "    \n",
    "        self.document_embedding_l = EmbeddingLayer(\n",
    "            self.document_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=False,\n",
    "        )\n",
    "        \n",
    "        self.document_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.document_embedding_l,\n",
    "            num_filters=350,\n",
    "            filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "            name='document_conv1',\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        )\n",
    "        \n",
    "        self.document_max_l = lasagne.layers.Pool2DLayer(\n",
    "            self.document_conv1_l,\n",
    "            name='document_pool1',\n",
    "            pool_size=(self.sentence_length - self.num_words_to_use_conv, 1),\n",
    "            mode='max',\n",
    "        )\n",
    "\n",
    "        self.document_dens1 = lasagne.layers.DenseLayer(\n",
    "            self.document_max_l,\n",
    "            num_units=300,\n",
    "            name='doucment_dens1',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.document_drop1 = lasagne.layers.DropoutLayer(\n",
    "            self.document_dens1,\n",
    "            p=.25,\n",
    "        )\n",
    "        \n",
    "        document_output_length = 250\n",
    "        \n",
    "        self.document_dens2 = lasagne.layers.DenseLayer(\n",
    "            self.document_drop1,\n",
    "            num_units=document_output_length,\n",
    "            name='document_dens2',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.document_output = lasagne.layers.get_output(self.document_dens2)\n",
    "                \n",
    "        self.surface_input_l = lasagne.layers.InputLayer(\n",
    "            (None, self.sentence_length), \n",
    "            input_var=self.x_surface_text_input\n",
    "        )\n",
    "        \n",
    "        self.surface_embedding_l = EmbeddingLayer(\n",
    "            self.surface_input_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=False,\n",
    "        )\n",
    "        \n",
    "        self.surface_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.surface_embedding_l,\n",
    "            num_filters=350,\n",
    "            filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "            name='surface_conv1',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.surface_dens1 = lasagne.layers.DenseLayer(\n",
    "            self.surface_conv1_l,\n",
    "            name='surface_dens1',\n",
    "            num_units=300,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.surface_drop1 = lasagne.layers.DropoutLayer(\n",
    "            self.surface_dens1,\n",
    "            p=.25,\n",
    "        )\n",
    "        \n",
    "        self.surface_dens2 = lasagne.layers.DenseLayer(\n",
    "            self.surface_drop1,\n",
    "            name='surface_dens2',\n",
    "            num_units=250,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.document_aligned_l = InputLayer(\n",
    "            (None, document_output_length),\n",
    "            input_var=self.document_output[self.x_document_id,:]\n",
    "        )\n",
    "        \n",
    "        self.source_l = lasagne.layers.ConcatLayer(\n",
    "            [self.document_aligned_l, self.surface_dens2]\n",
    "        )\n",
    "        \n",
    "        self.source_dens1 = lasagne.layers.DenseLayer(\n",
    "            self.source_l,\n",
    "            num_units=300,\n",
    "            name='source_dens1',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.source_drop1 = lasagne.layers.DropoutLayer(\n",
    "            self.source_dens1,\n",
    "            p=.25,\n",
    "        )\n",
    "        \n",
    "        self.source_dens2 = lasagne.layers.DenseLayer(\n",
    "            self.source_drop1,\n",
    "            num_units=300,\n",
    "            name='source_dens2',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.source_out = lasagne.layers.get_output(self.source_dens2)\n",
    "        \n",
    "        self.target_input_l = lasagne.layers.InputLayer(\n",
    "            (None,self.sentence_length), \n",
    "            input_var=self.x_target_input\n",
    "        )\n",
    "        \n",
    "        self.target_embedding_l = EmbeddingLayer(\n",
    "            self.target_input_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=False,\n",
    "        )\n",
    "        \n",
    "        self.target_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.target_embedding_l,\n",
    "            name='target_conv1',\n",
    "            filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "            num_filters=300,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.target_dens1 = lasagne.layers.DenseLayer(\n",
    "            self.target_conv1_l,\n",
    "            name='target_dens1',\n",
    "            num_units=300,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.target_drop1 = lasagne.layers.DropoutLayer(\n",
    "            self.target_dens1,\n",
    "            p=.25,\n",
    "        )\n",
    "        \n",
    "        self.target_dens2 = lasagne.layers.DenseLayer(\n",
    "            self.target_drop1,\n",
    "            name='target_dens2',\n",
    "            num_units=300,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.target_out = lasagne.layers.get_output(self.target_dens2)\n",
    "        \n",
    "        # compute the cosine distance between the two layers\n",
    "        self.source_aligned_l = self.source_out[self.x_link_id, :]\n",
    "        \n",
    "        # this uses scan internally, which means that it comes back into python code to run the loop.....fml\n",
    "        self.dotted_vectors =  T.batched_dot(self.target_out, self.source_aligned_l)\n",
    "        # diag also does not support a C version.........\n",
    "        #self.dotted_vectors = T.dot(self.target_out, self.source_aligned_l.T).diagonal()\n",
    "        \n",
    "        def augNorm(v):\n",
    "            return T.maximum(T.basic.pow(T.basic.pow(T.basic.abs_(v), 2).sum(axis=1) + .001, .5), .001)\n",
    "    \n",
    "        self.res_l = self.dotted_vectors / (augNorm(self.target_out) * augNorm(self.source_aligned_l) + .001)\n",
    "#         self.res_l = self.dotted_vectors / ((self.target_out.norm(1, axis=1) + .001) * \n",
    "#                                             (self.source_aligned_l.norm(1, axis=1) + .001))\n",
    "        \n",
    "    \n",
    "        self.all_params = (\n",
    "            lasagne.layers.get_all_params(self.target_dens2) + \n",
    "            lasagne.layers.get_all_params(self.source_dens2) +\n",
    "            lasagne.layers.get_all_params(self.document_dens2)\n",
    "        )\n",
    "        \n",
    "        self.loss_vec = T.nnet.binary_crossentropy(T.clip(self.res_l, .001, .999), self.y_score)\n",
    "        \n",
    "        self.updates = lasagne.updates.sgd(self.loss_vec.mean(), self.all_params, 0.1)\n",
    "        \n",
    "        self.train_func = theano.function(\n",
    "            [self.x_document_input,\n",
    "             self.x_surface_text_input, self.x_document_id,\n",
    "             self.x_target_input, self.x_link_id, self.y_score],\n",
    "            [self.res_l, self.loss_vec.sum(), self.loss_vec],\n",
    "            updates=self.updates\n",
    "        )\n",
    "        \n",
    "        self.test_func = theano.function(\n",
    "            [self.x_document_input,\n",
    "             self.x_surface_text_input, self.x_document_id,\n",
    "             self.x_target_input, self.x_link_id, self.y_score],\n",
    "            [self.res_l, self.loss_vec.sum(), self.loss_vec],\n",
    "        )\n",
    "        \n",
    "    def reset_accums(self):\n",
    "        self.current_documents = []\n",
    "        self.current_surface_text = []\n",
    "        self.current_link_id = []\n",
    "        self.current_target_input = []\n",
    "        self.current_target_id = []\n",
    "        self.current_target_goal = []\n",
    "        self.learning_targets = []\n",
    "        \n",
    "    def compute_batch(self, isTraining=True):\n",
    "        if isTraining:\n",
    "            func = self.train_func\n",
    "        else:\n",
    "            func = self.test_func\n",
    "        self.reset_accums()\n",
    "        self.total_links = 0\n",
    "        self.total_loss = 0.0\n",
    "        \n",
    "        for doc, queries in self.queries.iteritems():\n",
    "            # skip the testing documents while training and vice versa\n",
    "            if queries.values()[0]['training'] is not isTraining:\n",
    "                continue\n",
    "            docid = len(self.current_documents)\n",
    "            self.current_documents.append(self.wordvecs.tokenize(doc))\n",
    "            for surtxt, targets in queries.iteritems():\n",
    "                self.current_link_id.append(docid)\n",
    "                surid = len(self.current_surface_text)\n",
    "                self.current_surface_text.append(self.wordvecs.tokenize(surtxt))\n",
    "                for target in targets['vals'].keys():\n",
    "                    # skip the items that we don't know the gold for\n",
    "                    if not targets['gold'] and isTraining:\n",
    "                        continue\n",
    "                    isGold = target == targets['gold']\n",
    "                    cnt = self.page_content.get(WikiRegexes.convertToTitle(target))\n",
    "                    if cnt is None:\n",
    "                        # were not able to find this wikipedia document\n",
    "                        # so just ignore tihs result since trying to train on it will cause\n",
    "                        # issues\n",
    "                        continue\n",
    "                    self.current_target_input.append(cnt)  # page_content already tokenized\n",
    "                    self.current_target_id.append(surid)\n",
    "                    self.current_target_goal.append(isGold)\n",
    "                    self.learning_targets.append((targets, target))\n",
    "            if len(self.current_target_id) > self.batch_size:\n",
    "                return\n",
    "                self.run_batch(func)\n",
    "        \n",
    "        if len(self.current_target_id) > 0:\n",
    "            self.run_batch(func)\n",
    "            \n",
    "        return self.total_loss / self.total_links\n",
    "        \n",
    "    def run_batch(self, func):\n",
    "        res_vec, loss_sum, loss_vec = func(\n",
    "            self.current_documents,\n",
    "            self.current_surface_text, self.current_link_id,\n",
    "            self.current_target_input, self.current_target_id, self.current_target_goal\n",
    "        )\n",
    "        self.check_params()\n",
    "        self.total_links += len(self.current_target_id)\n",
    "        self.total_loss += loss_sum\n",
    "        for i in xrange(len(res_vec)):\n",
    "            # save the results from this pass\n",
    "            l = self.learning_targets[i]\n",
    "            l[0]['vals'][ l[1] ] = res_vec[i]\n",
    "        self.reset_accums()\n",
    "        \n",
    "    def check_params(self):\n",
    "        if any([np.isnan(v.get_value(borrow=True)).any() for v in self.all_params]):\n",
    "            raise RuntimeError('nan in some of the parameters')\n",
    "        \n",
    "\n",
    "        \n",
    "queries_exp = EntityVectorLinkExp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queries_exp.check_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.compute_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gg_res = queries_exp.test_func(\n",
    "    queries_exp.current_documents, \n",
    "    queries_exp.current_surface_text, queries_exp.current_link_id,\n",
    "    queries_exp.current_target_input, queries_exp.current_target_id, queries_exp.current_target_goal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(gg_res[0]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31486937"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg_res[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011132491"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg_res[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(target_conv1.W, True),\n",
       " (target_conv1.b, True),\n",
       " (target_dens1.W, True),\n",
       " (target_dens1.b, True),\n",
       " (target_dens2.W, True),\n",
       " (target_dens2.b, True),\n",
       " (surface_conv1.W, False),\n",
       " (surface_conv1.b, False),\n",
       " (surface_dens1.W, False),\n",
       " (surface_dens1.b, False),\n",
       " (surface_dens2.W, False),\n",
       " (surface_dens2.b, False),\n",
       " (source_dens1.W, False),\n",
       " (source_dens1.b, False),\n",
       " (source_dens2.W, False),\n",
       " (source_dens2.b, False),\n",
       " (document_conv1.W, False),\n",
       " (document_conv1.b, False),\n",
       " (doucment_dens1.W, False),\n",
       " (doucment_dens1.b, False),\n",
       " (document_dens2.W, False),\n",
       " (document_dens2.b, False)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(v, np.isnan(v.get_value(borrow=True)).all()) for v in queries_exp.all_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_exp.total_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file is available at /home/matthew/.theano/compiledir_Linux-3.10-el7.mfl.x86_64-x86_64-with-centos-7.1.1503-Core-x86_64-2.7.5-64/theano.pydotprint.cpu.png\n"
     ]
    }
   ],
   "source": [
    "theano.printing.pydotprint(T.grad(queries_exp.loss_vec.mean(), queries_exp.all_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_func = theano.function(\n",
    "            [queries_exp.x_document_input,\n",
    "             queries_exp.x_surface_text_input, queries_exp.x_document_id,\n",
    "             queries_exp.x_target_input, queries_exp.x_link_id, queries_exp.y_score],\n",
    "            T.grad(queries_exp.loss_vec.mean(), lasagne.layers.get_all_params(queries_exp.target_dens2)),\n",
    "#           T.grad(queries_exp.loss_vec.mean(), queries_exp.all_params),\n",
    "    #             [queries_exp.target_out, queries_exp.source_aligned_l, \n",
    "#              T.dot(queries_exp.target_out, queries_exp.source_aligned_l.T).diagonal(),\n",
    "#              queries_exp.target_out.norm(2, axis=1) * queries_exp.source_aligned_l.norm(2, axis=1),\n",
    "#              T.batched_dot(queries_exp.target_out, queries_exp.source_aligned_l),\n",
    "#              lasagne.layers.get_output(queries_exp.target_dens2),\n",
    "#              queries_exp.target_out.norm(2, axis=1),\n",
    "#              #T.grad(queries_exp.loss_vec.mean(), queries_exp.all_params)\n",
    "#             ],\n",
    "        #[queries_exp.res_l, queries_exp.loss_vec.sum(), queries_exp.loss_vec],\n",
    "    on_unused_input='ignore',\n",
    "    mode='DebugMode'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    gg_grad_res = gg_func(\n",
    "        queries_exp.current_documents,\n",
    "        queries_exp.current_surface_text, queries_exp.current_link_id,\n",
    "        queries_exp.current_target_input, queries_exp.current_target_id, queries_exp.current_target_goal\n",
    "    )\n",
    "except Exception as e:\n",
    "    eeee = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False, False]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.isnan(v).any() for v in gg_grad_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eeee' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-9a1975c68779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meeee\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'eeee' is not defined"
     ]
    }
   ],
   "source": [
    "eeee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8,  25,  28,  45,  46,  48,  53,  67,  79,  80,  82,  85,  90,\n",
       "         91, 103, 104, 109, 110, 121, 132, 134, 137, 141, 142, 143, 145,\n",
       "        148, 154, 160, 162, 164, 167, 169, 170, 175, 177, 179, 181, 184,\n",
       "        185, 194, 195, 199, 206, 216, 221, 223, 231, 235, 240, 243, 244,\n",
       "        245, 249, 253, 255, 279, 282, 284, 285, 286, 293, 294, 297, 299,\n",
       "        305, 309, 313, 324, 325, 326, 327, 333, 338, 339, 341, 345, 353,\n",
       "        371, 374, 377, 383, 385, 386, 389, 396, 398]),)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(eeee.v[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_exp.current_target_input[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries_exp.current_target_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res = gg_func(\n",
    "    queries_exp.current_documents,\n",
    "    queries_exp.current_surface_text, queries_exp.current_link_id,\n",
    "    queries_exp.current_target_input, queries_exp.current_target_id, queries_exp.current_target_goal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries_exp.current_target_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29542816,  0.28095254,  0.33144516,  0.26033801,  0.30518502,\n",
       "        0.30744812,  0.27378052,  0.29007095,  0.        ,  0.31962284,\n",
       "        0.29219297,  0.26807615,  0.26198399,  0.33053309,  0.28264579,\n",
       "        0.30185467,  0.30974212,  0.30415824,  0.26452494,  0.31237864,\n",
       "        0.28515667,  0.30756474,  0.26825306,  0.29566792,  0.26348299,\n",
       "        0.        ,  0.34485948,  0.29251757,  0.        ,  0.32832944,\n",
       "        0.31134653,  0.31885624,  0.29913256,  0.31034139,  0.3021968 ,\n",
       "        0.27235064,  0.29672292,  0.34496826,  0.3004064 ,  0.28319165,\n",
       "        0.30542776,  0.31852266,  0.35591626,  0.26192859,  0.36398679,\n",
       "        0.        ,  0.        ,  0.35293648,  0.        ,  0.32233551,\n",
       "        0.32399803,  0.31052122,  0.33514592,  0.        ,  0.33839938,\n",
       "        0.30342132,  0.30080143,  0.33954608,  0.31676838,  0.27356973,\n",
       "        0.29861012,  0.2438335 ,  0.26769674,  0.32690597,  0.30777121,\n",
       "        0.31307751,  0.33897728,  0.        ,  0.36814642,  0.26832426,\n",
       "        0.31021395,  0.31349629,  0.28937471,  0.32566446,  0.31176493,\n",
       "        0.34921747,  0.34489673,  0.29198456,  0.27322602,  0.        ,\n",
       "        0.        ,  0.26788726,  0.        ,  0.29529476,  0.33767366,\n",
       "        0.        ,  0.30098793,  0.29692057,  0.31511092,  0.30036825,\n",
       "        0.        ,  0.        ,  0.30070147,  0.33196563,  0.26818323,\n",
       "        0.29960513,  0.29345712,  0.27731073,  0.29009792,  0.2959609 ,\n",
       "        0.30089176,  0.32542744,  0.29032877,  0.        ,  0.        ,\n",
       "        0.29709989,  0.34453338,  0.31070626,  0.34837198,  0.        ,\n",
       "        0.        ,  0.28243071,  0.28924936,  0.2470035 ,  0.32511407,\n",
       "        0.30602816,  0.32922035,  0.33116603,  0.29893151,  0.29174843,\n",
       "        0.31713143,  0.        ,  0.29720655,  0.2775971 ,  0.28872147,\n",
       "        0.30859792,  0.3076528 ,  0.25572059,  0.28934869,  0.2934444 ,\n",
       "        0.30671602,  0.28661722,  0.        ,  0.29175797,  0.        ,\n",
       "        0.30682176,  0.32392079,  0.        ,  0.36952749,  0.29769188,\n",
       "        0.32293147,  0.        ,  0.        ,  0.        ,  0.32052067,\n",
       "        0.        ,  0.3169888 ,  0.31616572,  0.        ,  0.29240081,\n",
       "        0.31151229,  0.31084713,  0.27947903,  0.34205404,  0.        ,\n",
       "        0.38257107,  0.25076056,  0.28960979,  0.23181026,  0.27663788,\n",
       "        0.        ,  0.28280926,  0.        ,  0.27467287,  0.        ,\n",
       "        0.25885403,  0.28653196,  0.        ,  0.28506729,  0.        ,\n",
       "        0.        ,  0.2927295 ,  0.27296627,  0.31269732,  0.34473568,\n",
       "        0.        ,  0.35062647,  0.        ,  0.33096698,  0.        ,\n",
       "        0.27853626,  0.        ,  0.2960982 ,  0.27137041,  0.        ,\n",
       "        0.        ,  0.30757734,  0.29239121,  0.31286332,  0.29093161,\n",
       "        0.31298119,  0.30968076,  0.29403374,  0.25890502,  0.        ,\n",
       "        0.        ,  0.29682121,  0.31770211,  0.26751727,  0.        ,\n",
       "        0.29386449,  0.34028774,  0.29879823,  0.33286747,  0.27738652,\n",
       "        0.28976372,  0.        ,  0.24052905,  0.29630905,  0.26434919,\n",
       "        0.29210371,  0.28604096,  0.2740722 ,  0.32243475,  0.29768759,\n",
       "        0.25603038,  0.        ,  0.30366766,  0.28090942,  0.28691003,\n",
       "        0.32590267,  0.        ,  0.28106838,  0.        ,  0.27513862,\n",
       "        0.28470016,  0.30690828,  0.31368774,  0.26680201,  0.31027678,\n",
       "        0.30789107,  0.        ,  0.29652464,  0.31733862,  0.29764411,\n",
       "        0.        ,  0.29336649,  0.29502711,  0.30762583,  0.27769154,\n",
       "        0.        ,  0.30545104,  0.29425266,  0.        ,  0.        ,\n",
       "        0.        ,  0.26541331,  0.31605241,  0.27000108,  0.        ,\n",
       "        0.31125468,  0.27751371,  0.3108232 ,  0.        ,  0.2735821 ,\n",
       "        0.        ,  0.30850244,  0.33901194,  0.30887157,  0.28529975,\n",
       "        0.29010463,  0.30872697,  0.33517241,  0.31497374,  0.34567696,\n",
       "        0.30128658,  0.30975178,  0.336018  ,  0.31579539,  0.322992  ,\n",
       "        0.2675432 ,  0.27934557,  0.25968477,  0.29816592,  0.29070574,\n",
       "        0.27466059,  0.27109817,  0.26938012,  0.30011845,  0.        ,\n",
       "        0.2786189 ,  0.32860026,  0.        ,  0.32649794,  0.        ,\n",
       "        0.        ,  0.        ,  0.28813034,  0.339053  ,  0.33500993,\n",
       "        0.29680517,  0.3007406 ,  0.32703903,  0.        ,  0.        ,\n",
       "        0.33116823,  0.32683209,  0.        ,  0.27406442,  0.        ,\n",
       "        0.32610953,  0.32275766,  0.32217866,  0.30318296,  0.32084256,\n",
       "        0.        ,  0.26146254,  0.30284518,  0.29815453,  0.        ,\n",
       "        0.29360193,  0.31370628,  0.30732664,  0.        ,  0.32471812,\n",
       "        0.32068467,  0.30848292,  0.29412729,  0.29222441,  0.28952995,\n",
       "        0.29735628,  0.32908991,  0.25165281,  0.29500812,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.29276806,  0.30738676,\n",
       "        0.30351666,  0.32818541,  0.30726966,  0.        ,  0.3065531 ,\n",
       "        0.29355946,  0.29713514,  0.26594886,  0.        ,  0.        ,\n",
       "        0.3246786 ,  0.        ,  0.26540419,  0.30132705,  0.31273243,\n",
       "        0.        ,  0.3754389 ,  0.30774423,  0.30076635,  0.31659725,\n",
       "        0.26750413,  0.31446609,  0.33230007,  0.        ,  0.2738125 ,\n",
       "        0.25259164,  0.23311655,  0.313131  ,  0.27988052,  0.27825791,\n",
       "        0.31026897,  0.30296513,  0.28519186,  0.32260257,  0.35038328,\n",
       "        0.31701207,  0.34905753,  0.2982851 ,  0.38117871,  0.28713059,\n",
       "        0.31251472,  0.        ,  0.31255892,  0.30330062,  0.        ,\n",
       "        0.32459745,  0.29573476,  0.        ,  0.28923634,  0.2585533 ,\n",
       "        0.31821397,  0.30237946,  0.31351176,  0.        ,  0.33346361,\n",
       "        0.        ,  0.        ,  0.30643043,  0.29538551,  0.        ,\n",
       "        0.29043189,  0.27024582,  0.30678961,  0.31621343,  0.28356943,\n",
       "        0.25225803,  0.        ,  0.34628633,  0.        ,  0.29228273], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg_res[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.isnan(gg_res[4]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(gg_res[5]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[0].shape, gg_res[1].shape, gg_res[2].shape, gg_res[3].shape, gg_res[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.inner(gg_res[0], gg_res[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[0] * gg_res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = np.dot(gg_res[0], gg_res[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa.diagonal().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.queried_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_surface_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_link_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_target_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "nan in some of the parameters",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-f9466b6d9ed8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mexp_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries_exp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-e8d48a36d8a1>\u001b[0m in \u001b[0;36mcompute_batch\u001b[1;34m(self, isTraining)\u001b[0m\n\u001b[0;32m    289\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_targets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_target_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_target_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-e8d48a36d8a1>\u001b[0m in \u001b[0;36mrun_batch\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vals'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_accums\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-e8d48a36d8a1>\u001b[0m in \u001b[0;36mcheck_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mborrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_params\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nan in some of the parameters'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: nan in some of the parameters"
     ]
    }
   ],
   "source": [
    "exp_results = []\n",
    "\n",
    "for i in xrange(5):\n",
    "    exp_results.append((i, queries_exp.compute_batch()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.total_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.total_loss / queries_exp.total_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_target_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.compute_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time queries_exp.run_batch(queries_exp.test_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
