{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Working on adding a lot of features just to see if it can get the score up regardless of how complicated or where the data is coming from\n",
    "\n",
    "Features that I will be adding\n",
    "\n",
    "* Taget given surface counts\n",
    "* words from the target and source document\n",
    "  * possible back prop into these vectors, idea is to replace tf-idf with some nn and back prop here\n",
    "* using a linear layer near the output to combine the features\n",
    "\n",
    "* adding the indicator features from the berkeley entity system\n",
    "  * I guess that these will be on the final linear layer\n",
    "  \n",
    "* the tesor product type stuff did not really work, going to try and maybe increase the dim of the convs somehow\n",
    "\n",
    "* going to add the join system since the features on the queries appear to matter a lot\n",
    "    * The score of the query is multiplied by the score of the join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from theano import *\n",
    "from lasagne.layers import InputLayer, get_output\n",
    "import lasagne\n",
    "import lasagne.layers\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "from helpers import SimpleMaxingLayer, SimpleAverageLayer\n",
    "from wordvecs import WordVectors, EmbeddingLayer, WordTokenizer\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "theano.config.floatX = 'float32'\n",
    "#theano.config.linker = 'cvm_nogc'\n",
    "theano.config.openmp = True\n",
    "theano.config.openmp_elemwise_minsize = 20000\n",
    "\n",
    "\n",
    "# for debugging`\n",
    "# theano.config.exception_verbosity = 'high'\n",
    "# theano.config.optimizer = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/matthew/external-wiki-ace6.json') as f:\n",
    "    externalWikiJ = json.load(f)\n",
    "    queries = externalWikiJ['queries']\n",
    "    featuresNames = externalWikiJ['featIndex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8705416746137707"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evalNumPossible(qus):\n",
    "    total = 0\n",
    "    possible = 0\n",
    "    for qu in qus.values():\n",
    "        for q in qu.values():\n",
    "            total += 1\n",
    "            if q['gold'] in q['vals']:\n",
    "                possible += 1\n",
    "    return float(possible) / total\n",
    "\n",
    "evalNumPossible(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37841"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([any([g['gold'] for g in v.values()]) for v in queries.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(not g['training'] for g in v.values()) for v in queries.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14507"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(g['training'] for g in v.values()) for v in queries.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37841"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51,\n",
       " 58,\n",
       " 60,\n",
       " 62,\n",
       " 64,\n",
       " 66,\n",
       " 68,\n",
       " 70,\n",
       " 72,\n",
       " 74,\n",
       " 79,\n",
       " 80,\n",
       " 82,\n",
       " 85,\n",
       " 113,\n",
       " 330,\n",
       " 331,\n",
       " 1180,\n",
       " 1181,\n",
       " 1182,\n",
       " 1183,\n",
       " 1184,\n",
       " 1185]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max(max(max(a[1]) for a in g['vals'].values()) for g in v.values()) for v in queries.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for q,v in queries.items():\n",
    "#     if not v.values()[0]['training']:\n",
    "#         del queries[q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # load the samples from the provided testing set\n",
    "\n",
    "# with open('/data/matthew/external-wiki-testing.json') as f:\n",
    "#     queries.update(**json.load(f)['queries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for q,v in queries.items():\n",
    "    for v2 in v.values():\n",
    "        v2['gold'] = v2['gold'].replace('_', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordvectors = WordVectors(\n",
    "    fname=\"/data/matthew/enwiki-20141208-pages-articles-multistream-links7-output1.bin\",\n",
    "    redir_fname='/data/matthew/enwiki-20141208-pages-articles-multistream-redirect7.json',\n",
    "    negvectors=False,\n",
    "    sentence_length=200,\n",
    ")\n",
    "wordvectors.add_unknown_words = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('/data/matthew/enwiki-20141208-pages-articles-multistream-redirects5.json') as f:\n",
    "#     page_redirects = json.load(f)\n",
    "page_redirects = wordvectors.redirects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4056055"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordvectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/matthew/enwiki-20141208-pages-articles-multistream-surface-counts7.json') as f:\n",
    "    surface_counts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try and make the surfaces items match what we are looking for\n",
    "surface_counts_re = re.compile('([\\.,!\\?])')\n",
    "for sk in surface_counts.keys():\n",
    "    nsk = sk.replace('(', '-lrb-').replace(')', '-rrb-')\n",
    "    nsk = surface_counts_re.sub(' \\\\1', nsk)\n",
    "    if nsk != sk:\n",
    "        surface_counts[nsk] = surface_counts[sk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wikireader import WikiRegexes, WikipediaReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PreProcessedQueries(wikipedia_dump_fname, vectors=wordvectors, queries=queries, redirects=page_redirects, surface=surface_counts):\n",
    "    \n",
    "    get_words = re.compile('[^a-zA-Z0-9 ]')\n",
    "    get_link = re.compile('.*?\\[(.*?)\\].*?')\n",
    "    \n",
    "    wordvec = WordTokenizer(vectors, sentence_length=200)\n",
    "    documentvec = WordTokenizer(vectors, sentence_length=1)\n",
    "    \n",
    "    queried_pages = set()\n",
    "    for docs, q in queries.iteritems():\n",
    "        wordvec.tokenize(docs)\n",
    "        for sur, v in q.iteritems():\n",
    "            wrds_sur = get_words.sub(' ', sur)\n",
    "            wordvec.tokenize(wrds_sur)\n",
    "            link_sur = get_link.match(sur).group(1)\n",
    "            wordvec.tokenize(link_sur)\n",
    "            for link in v['vals'].keys():\n",
    "                wrds = get_words.sub(' ', link)\n",
    "                wordvec.tokenize(wrds)\n",
    "                tt = WikiRegexes.convertToTitle(link)\n",
    "                documentvec.get_location(tt)\n",
    "                queried_pages.add(tt)\n",
    "\n",
    "    added_pages = set()\n",
    "    for title in queried_pages:\n",
    "        if title in redirects:\n",
    "            #wordvec.tokenize(self.redirects[title])\n",
    "            documentvec.get_location(redirects[title])\n",
    "            added_pages.add(redirects[title])\n",
    "    queried_pages |= added_pages\n",
    "    \n",
    "    for w in queried_pages:\n",
    "        wordvec.tokenize(get_words.sub(' ', w))\n",
    "\n",
    "    page_content = {}\n",
    "\n",
    "    class GetWikipediaWords(WikipediaReader, WikiRegexes):\n",
    "\n",
    "        def readPage(ss, title, content, namespace):\n",
    "            if namespace != 0:\n",
    "                return\n",
    "            tt = ss.convertToTitle(title)\n",
    "            if tt in queried_pages:\n",
    "                cnt = ss._wikiToText(content)\n",
    "                page_content[tt] = wordvec.tokenize(cnt)\n",
    "\n",
    "    GetWikipediaWords(wikipedia_dump_fname).read()\n",
    "    \n",
    "    rr = redirects\n",
    "    rq = queried_pages\n",
    "    rc = page_content\n",
    "    rs = surface\n",
    "\n",
    "    class PreProcessedQueriesCls(object):\n",
    "        \n",
    "        wordvecs = wordvec\n",
    "        documentvecs = documentvec\n",
    "        queries = queries\n",
    "        redirects = rr\n",
    "        queried_pages = rq\n",
    "        page_content = rc\n",
    "        surface_counts = rs\n",
    "        \n",
    "        \n",
    "    return PreProcessedQueriesCls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 20s, sys: 14.4 s, total: 7min 34s\n",
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "%time basePreProcessedQueries = PreProcessedQueries('/data/matthew/enwiki-20141208-pages-articles-multistream.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4056055"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordvectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195105"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(basePreProcessedQueries.wordvecs.reverse_word_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for qu in queries.values():\n",
    "    for en in qu.values():\n",
    "        en['boosted'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanUpMultipleLinks():\n",
    "    for qu in queries.values():\n",
    "        for en in qu.values():\n",
    "            gold_page = en['gold']\n",
    "            gold_title = WikiRegexes.convertToTitle(gold_page)\n",
    "            gold_title = page_redirects.get(gold_title, gold_title)\n",
    "            pages = set()\n",
    "            for p in en['vals'].keys():\n",
    "                wiki_title = WikiRegexes.convertToTitle(p)\n",
    "                wiki_title = page_redirects.get(wiki_title, wiki_title)\n",
    "                if wiki_title == gold_title and p != en['gold']:\n",
    "                    del en['vals'][p]\n",
    "                elif wiki_title not in pages:\n",
    "                    pages.add(wiki_title)\n",
    "                else:\n",
    "                    del en['vals'][p]\n",
    "cleanUpMultipleLinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218099"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(q) for q in queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def removeSingleLinkTargets():\n",
    "#     \"items that the surface link set only has a single item are trival, so remove\"\n",
    "#     get_link = re.compile('.*?\\[(.*?)\\].*?')\n",
    "#     for quk, qu in queries.items():\n",
    "#         for sur in qu.keys():\n",
    "#             surlink = get_link.match(sur).group(1)\n",
    "#             surmatch = surlink.lower()\n",
    "#             surcounts = surface_counts.get(surmatch)\n",
    "#             if surcounts and len(surcounts) == 1:\n",
    "#                 # this is trival since there is only one item\n",
    "#                 del qu[sur]\n",
    "#         if not qu:\n",
    "#             # we removed all the links on this page, remove it otherwise the program crashes\n",
    "#             del queries[quk]\n",
    "# removeSingleLinkTargets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " [[18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18],\n",
       "  [18]]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.values()[0].values()[0]['vals'].values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EntityVectorLinkExp(basePreProcessedQueries):\n",
    "\n",
    "    batch_size = 250 #20000\n",
    "    num_training_items = 500000 #200000\n",
    "    dim_compared_vec = 1  # 100\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sentence_length = self.wordvecs.sentence_length\n",
    "        self.sentence_length_short = 10\n",
    "        self.document_length = 100\n",
    "        \n",
    "        self.num_words_to_use_conv = 5\n",
    "        self.enable_boosting = False\n",
    "        self.num_negative_target_samples = 1\n",
    "        #self.enable_match_surface = False\n",
    "        #self.enable_link_counts = True\n",
    "        self.enable_train_wordvecs = False\n",
    "        self.enable_cap_boosting = True\n",
    "        \n",
    "        self.num_indicator_features = len(featuresNames)\n",
    "        \n",
    "        self.main_nl = lasagne.nonlinearities.softmax# leaky_rectify\n",
    "        \n",
    "        self.impossible_query = featuresNames.index('Impossible')\n",
    "\n",
    "        self._setup()\n",
    "\n",
    "    def _setup(self):\n",
    "        \n",
    "        self.all_params = []\n",
    "        \n",
    "        self.x_document_input = T.imatrix('x_doc')  # words from the source document\n",
    "\n",
    "        self.x_document_id = T.ivector('x_doc_id')  # index of which source doucment this is from\n",
    "        self.x_surface_text_input = T.imatrix('x_surface_link')  # text of the surface link\n",
    "        self.x_surface_context_input = T.imatrix('x_surface_cxt')  #  words surrounding the surface link\n",
    "\n",
    "        self.x_target_input = T.ivector('x_target')  # id of the target vector\n",
    "        self.x_target_words = T.imatrix('x_target_words')  # words from the target title link\n",
    "        self.x_matches_surface = T.ivector('x_match_surface')  # indicator if the target title matches the surface\n",
    "        self.x_matches_counts = T.imatrix('x_matches_counts')  # info about the link counts\n",
    "        self.x_target_document_words = T.imatrix('x_target_document_words')  # words from the body of target document\n",
    "        self.x_link_id = T.ivector('x_link_id')  # indx of what link to compare to in the matrix\n",
    "\n",
    "        #self.x_indicator_features = T.matrix('x_indicator_features', dtype='int8')\n",
    "        \n",
    "        self.x_denotaiton_features = T.matrix('x_denotation_ind_feats', dtype='int8')  # the joint denotation query features\n",
    "        self.x_query_featurs = T.matrix('x_query_ind_feats', dtype='int8')  # the query features\n",
    "        self.x_query_link_id = T.ivector('x_match_query')  # the query that a denotation links to\n",
    "        self.x_denotation_ranges = T.imatrix('x_denotation_ranges')  # the range of joint denotations to sum over\n",
    "        \n",
    "        self.x_target_link_id = T.ivector('x_match_target')  # the target document that maches with a given denotation\n",
    "        \n",
    "        #self.y_score = T.vector('y')\n",
    "        self.y_answer = T.ivector('y_ans')  # (Not used) contains the location of the gold answer so we can compute the loss\n",
    "        self.y_grouping = T.imatrix('y_grouping')  # matrix containing [start_idx, end_idx, gold_idx]\n",
    "        self.y_boosted = T.vector('y_boosted')  # only used if boosting enabled, vector of how much to boost items\n",
    "\n",
    "        self.embedding_W = theano.shared(self.wordvecs.get_numpy_matrix().astype(theano.config.floatX),name='embedding_W')\n",
    "        self.embedding_W_docs = theano.shared(self.documentvecs.get_numpy_matrix().astype(theano.config.floatX),name='embedding_W_docs')\n",
    "        \n",
    "#         def convSoftMax(t):\n",
    "#             shape = t.shape  # (document_sample, num_filters, output_rows, output_cols)\n",
    "#             new_shape = (shape[0] * shape[2] * shape[3], shape[1])\n",
    "#             return T.nnet.softmax(t.reshape(new_shape)).reshape(shape)\n",
    "        \n",
    "#             return lasagne.nonlinearities.leaky_rectify(t)\n",
    "\n",
    "        def augRectify(x):\n",
    "            # if x is zero, then the gradient failes due to computation: x / |x|\n",
    "            return lasagne.nonlinearities.leaky_rectify(x + .001)\n",
    "        \n",
    "        simpleConvNonLin = augRectify # lasagne.nonlinearities.rectify# leaky_rectify\n",
    "        \n",
    "        self.document_l = lasagne.layers.InputLayer(\n",
    "            (None,self.document_length),\n",
    "            input_var=self.x_document_input\n",
    "        )\n",
    "\n",
    "        self.document_embedding_l = EmbeddingLayer(\n",
    "            self.document_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=self.enable_train_wordvecs,\n",
    "        )\n",
    "        \n",
    "        self.document_simple_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.document_embedding_l,\n",
    "            num_filters=self.dim_compared_vec,\n",
    "            filter_size=(2, self.wordvecs.vector_size),\n",
    "            name='document_simple_conv',\n",
    "            nonlinearity=simpleConvNonLin,#lasagne.nonlinearities.leaky_rectify,\n",
    "        )\n",
    "        \n",
    "        self.document_simple_sum_l = lasagne.layers.Pool2DLayer(\n",
    "            #lasagne.layers.reshape(self.document_embedding_l, ([0],[3],[2],1)),\n",
    "            self.document_simple_conv1_l,\n",
    "            name='document_simple_pool',\n",
    "            pool_size=(self.document_length - 2, 1),\n",
    "            mode='sum',\n",
    "        )\n",
    "        \n",
    "#         self.document_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "#             self.document_embedding_l,\n",
    "#             num_filters=30,  # was 75, 100, 500\n",
    "#             filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "#             name='document_conv1',\n",
    "#             nonlinearity=self.main_nl,# lasagne.nonlinearities.softmax,  # was leaky_rectify\n",
    "#         )\n",
    "\n",
    "#         self.document_max_l = lasagne.layers.Pool2DLayer(\n",
    "#             self.document_conv1_l,\n",
    "#             name='document_pool1',\n",
    "#             pool_size=(self.document_length - self.num_words_to_use_conv, 1),\n",
    "#             mode='max',  # was sum\n",
    "#         )\n",
    "\n",
    "#         document_output_length = 25 # was 100, 200\n",
    "        \n",
    "#         self.document_dens1 = lasagne.layers.DenseLayer(\n",
    "#             self.document_max_l,\n",
    "#             num_units=document_output_length,\n",
    "#             name='doucment_dens1',\n",
    "#             nonlinearity=lasagne.nonlinearities.leaky_rectify,\n",
    "#         )\n",
    "\n",
    "        self.document_output = lasagne.layers.get_output(\n",
    "            lasagne.layers.reshape(self.document_simple_sum_l, ([0],-1)))\n",
    "        \n",
    "        self.all_params += lasagne.layers.get_all_params(self.document_simple_sum_l)\n",
    "    \n",
    "    \n",
    "        ##########################################\n",
    "        ## surface text\n",
    "\n",
    "        self.surface_context_l = lasagne.layers.InputLayer(\n",
    "            (None, self.sentence_length),\n",
    "            input_var=self.x_surface_context_input,\n",
    "        )\n",
    "\n",
    "        self.surface_context_embedding_l = EmbeddingLayer(\n",
    "            self.surface_context_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=self.enable_train_wordvecs,\n",
    "        )\n",
    "\n",
    "        self.surface_context_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.surface_context_embedding_l,\n",
    "            num_filters=self.dim_compared_vec,  # was 300\n",
    "            filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "            name='surface_cxt_conv1',\n",
    "            nonlinearity=simpleConvNonLin,# self.main_nl,\n",
    "        )\n",
    "\n",
    "        self.surface_context_pool1_l = lasagne.layers.Pool2DLayer(\n",
    "            self.surface_context_conv1_l,\n",
    "            name='surface_cxt_pool1',\n",
    "            pool_size=(self.sentence_length - self.num_words_to_use_conv, 1),\n",
    "            mode='max', #sum',\n",
    "        )\n",
    "    \n",
    "        self.surface_output = lasagne.layers.get_output(\n",
    "            lasagne.layers.reshape(self.surface_context_pool1_l, ([0], -1))\n",
    "        )\n",
    "        \n",
    "        self.all_params += lasagne.layers.get_all_params(self.surface_context_pool1_l)\n",
    "\n",
    "        self.surface_input_l = lasagne.layers.InputLayer(\n",
    "            (None, self.sentence_length_short),\n",
    "            input_var=self.x_surface_text_input\n",
    "        )\n",
    "\n",
    "        self.surface_embedding_l = EmbeddingLayer(\n",
    "            self.surface_input_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=self.enable_train_wordvecs,\n",
    "        )\n",
    "\n",
    "        self.surface_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.surface_embedding_l,\n",
    "            num_filters=self.dim_compared_vec,  # was 300\n",
    "            filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "            name='surface_conv1',\n",
    "            nonlinearity=simpleConvNonLin, #self.main_nl,\n",
    "        )\n",
    "\n",
    "        self.surface_pool1_l = lasagne.layers.Pool2DLayer(\n",
    "            self.surface_conv1_l,\n",
    "            name='surface_pool1',\n",
    "            pool_size=(self.sentence_length_short - self.num_words_to_use_conv, 1),\n",
    "            mode='sum',\n",
    "        )\n",
    "    \n",
    "        self.surface_words_output = lasagne.layers.get_output(\n",
    "            lasagne.layers.reshape(self.surface_pool1_l, ([0], -1))\n",
    "        )\n",
    "        \n",
    "        self.all_params += lasagne.layers.get_all_params(self.surface_pool1_l)\n",
    "\n",
    "        ##################################################\n",
    "        ## merge the documents with the surface info\n",
    "\n",
    "        \n",
    "        ###################################################\n",
    "        ## dealing with the target side\n",
    "\n",
    "        matched_surface_reshaped = self.x_matches_surface.reshape(\n",
    "            (self.x_matches_surface.shape[0], 1, 1, 1)).astype(theano.config.floatX)\n",
    "\n",
    "        self.target_input_l = lasagne.layers.InputLayer(\n",
    "            (None,),\n",
    "            input_var=self.x_target_input\n",
    "        )\n",
    "        \n",
    "        #################################\n",
    "        ## target indicators features\n",
    "\n",
    "        self.target_matched_surface_input_l = lasagne.layers.InputLayer(\n",
    "            (None,1,1,1),\n",
    "            input_var=matched_surface_reshaped,\n",
    "        )\n",
    "        \n",
    "        self.target_matched_counts_input_l = lasagne.layers.InputLayer(\n",
    "            (None,5),\n",
    "            input_var=self.x_matches_counts.astype(theano.config.floatX),\n",
    "        )\n",
    "\n",
    "#         # embedding of the target documents\n",
    "#         self.target_embedding_l = EmbeddingLayer(\n",
    "#             lasagne.layers.reshape(self.target_input_l, ([0], 1)),\n",
    "#             W=self.embedding_W_docs,\n",
    "#             add_word_params=False,\n",
    "#         )\n",
    "        \n",
    "#         self.target_embedding_dens_l = lasagne.layers.DenseLayer(\n",
    "#             lasagne.layers.reshape(self.target_embedding_l, ([0], -1)),\n",
    "#             name='target_embedding_dens',\n",
    "#             num_units=self.dim_compared_vec,\n",
    "#             nonlinearity=augRectify,# lasagne.nonlinearities.leaky_rectify,  # should be compariable to the simpleConvNonLin\n",
    "#         )\n",
    "        \n",
    "#         self.target_embedding_out = lasagne.layers.get_output(\n",
    "#             lasagne.layers.reshape(self.target_embedding_dens_l, ([0],-1)),\n",
    "#         )\n",
    "\n",
    "        # words from the title of the target\n",
    "        self.target_words_input_l = lasagne.layers.InputLayer(\n",
    "            (None,self.sentence_length_short),\n",
    "            input_var=self.x_target_words,\n",
    "        )\n",
    "\n",
    "        self.target_words_embedding_l = EmbeddingLayer(\n",
    "            self.target_words_input_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=self.enable_train_wordvecs,\n",
    "        )\n",
    "\n",
    "        self.target_words_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.target_words_embedding_l,\n",
    "            name='target_wrds_conv1',\n",
    "            filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "            num_filters=self.dim_compared_vec,  # was 75, 150, 350\n",
    "            nonlinearity=simpleConvNonLin,# self.main_nl,# lasagne.nonlinearities.leaky_rectify,\n",
    "        )\n",
    "\n",
    "        self.target_words_pool1_l = lasagne.layers.Pool2DLayer(\n",
    "            self.target_words_conv1_l,\n",
    "            name='target_wrds_pool1',\n",
    "            pool_size=(self.sentence_length_short - self.num_words_to_use_conv, 1),\n",
    "            mode='sum',  # was sum\n",
    "        )\n",
    "        \n",
    "        self.target_title_out = lasagne.layers.get_output(\n",
    "            lasagne.layers.reshape(self.target_words_pool1_l, ([0],-1))\n",
    "        )\n",
    "        \n",
    "        self.all_params += lasagne.layers.get_all_params(self.target_words_pool1_l)\n",
    "        \n",
    "        \n",
    "        # words from the body of the target\n",
    "        self.target_body_words_input_l = lasagne.layers.InputLayer(\n",
    "            (None,self.sentence_length),\n",
    "            input_var=self.x_target_document_words,\n",
    "        )\n",
    "        \n",
    "        self.target_body_words_embedding_l = EmbeddingLayer(\n",
    "            self.target_body_words_input_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=self.enable_train_wordvecs,\n",
    "        )\n",
    "        \n",
    "        self.target_body_simple_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.target_body_words_embedding_l,\n",
    "            name='target_body_simple_conv',\n",
    "            filter_size=(2, self.wordvecs.vector_size),\n",
    "            num_filters=self.dim_compared_vec,\n",
    "            nonlinearity=simpleConvNonLin,# self.main_nl,# lasagne.nonlinearities.leaky_rectify,\n",
    "        )\n",
    "        \n",
    "        self.target_body_simple_sum_l = lasagne.layers.Pool2DLayer(\n",
    "            #lasagne.layers.reshape(self.target_body_words_embedding_l, ([0],[3],[2],1)),\n",
    "            self.target_body_simple_conv1_l,\n",
    "            name='target_body_simple_sum',\n",
    "            pool_size=(self.sentence_length - 2, 1),\n",
    "            mode='sum',\n",
    "        )\n",
    "        \n",
    "#         self.target_body_words_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "#             self.target_body_words_embedding_l,\n",
    "#             name='target_body_wrds_conv1',\n",
    "#             filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "#             num_filters=150,\n",
    "#             nonlinearity=lasagne.nonlinearities.leaky_rectify,\n",
    "#         )\n",
    "        \n",
    "#         self.target_body_words_pool1_l = lasagne.layers.Pool2DLayer(\n",
    "#             self.target_body_words_conv1_l,\n",
    "#             name='target_body_wrds_pool1',\n",
    "#             pool_size=(self.sentence_length - self.num_words_to_use_conv, 1),\n",
    "#             mode='max',\n",
    "#         )\n",
    "    \n",
    "#         self.target_merge_l = lasagne.layers.ConcatLayer(\n",
    "#             [lasagne.layers.reshape(self.target_words_pool1_l, ([0], [1])),\n",
    "#              lasagne.layers.reshape(self.target_body_words_pool1_l, ([0], [1])),\n",
    "#             # lasagne.layers.reshape(self.target_embedding_l, ([0], [3]))\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "        self.target_out = lasagne.layers.get_output(\n",
    "            lasagne.layers.reshape(self.target_body_simple_sum_l, ([0],-1)))\n",
    "        \n",
    "        self.all_params += lasagne.layers.get_all_params(self.target_body_simple_sum_l)\n",
    "\n",
    "        #########################################################\n",
    "        ## compute the cosine distance between the two layers\n",
    "       \n",
    "        # source body\n",
    "        self.source_aligned_l = self.document_output[self.x_document_id,:][self.x_link_id,:] #self.source_out[self.x_link_id, :]\n",
    "        # source context\n",
    "        self.source_context_aligned_l = self.surface_output[self.x_link_id,:]\n",
    "        # source surface words\n",
    "        self.source_surface_words_aligned_l = self.surface_words_output[self.x_link_id,:]\n",
    "        \n",
    "        # this uses scan internally, which means that it comes back into python code to run the loop.....fml\n",
    "#         self.dotted_vectors =  T.batched_dot(self.target_out, self.source_aligned_l)\n",
    "        # diag also does not support a C version.........\n",
    "        #self.dotted_vectors = T.dot(self.target_out, self.source_aligned_l.T).diagonal()\n",
    "\n",
    "        def augNorm(v):\n",
    "            return T.basic.pow(T.basic.pow(T.basic.abs_(v), 2).sum(axis=1) + .001, .5)\n",
    "\n",
    "#         self.res_l = self.dotted_vectors / (augNorm(self.target_out) * augNorm(self.source_aligned_l) + .001)\n",
    "        \n",
    "#         self.res_cap = T.clip((T.tanh(self.res_l) + 1) / 2, .001, .999)\n",
    "        \n",
    "        def cosinsim(a, b):\n",
    "            dotted = T.batched_dot(a, b)\n",
    "            return dotted / (augNorm(a) * augNorm(b))\n",
    "        \n",
    "        ##############################################\n",
    "        ## tensor product stuff\n",
    "        \n",
    "#         def tensorP(a,b):\n",
    "#             res, _ = theano.scan(\n",
    "#                 fn=lambda x_vec, y_vec, x_norm, y_norm: T.concatenate(\n",
    "#                     [x_vec, y_vec, \n",
    "#                      T.outer(x_vec / x_norm, y_vec / y_norm).flatten()]\n",
    "#                 ),\n",
    "#                 outputs_info=None,\n",
    "#                 sequences=[a,b, augNorm(a), augNorm(b)],\n",
    "#                 non_sequences=None\n",
    "#             )\n",
    "#             return res\n",
    "        \n",
    "                \n",
    "        def comparedVLayers(a, b):\n",
    "            dv = cosinsim(a, b)\n",
    "            #dv = (a[:,0] + .001) * (b[:,0] + .001)\n",
    "            return lasagne.layers.InputLayer(\n",
    "                (None,1),\n",
    "                input_var=dv.reshape((dv.shape[0], 1))\n",
    "            )\n",
    "        \n",
    "#         def comparedVLayers2(a,b):\n",
    "#             dv = theano.gradient.disconnected_grad(tensorP(a,b))  # just see how well this performs without learning this\n",
    "#             return lasagne.layers.InputLayer(\n",
    "#                 (None,self.dim_compared_vec ** 2 + self.dim_compared_vec*2 ),\n",
    "#                 input_var=dv\n",
    "#             )\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        ######################################################\n",
    "        ## indicator feature input\n",
    "    \n",
    "#         self.indicator_feat_l = lasagne.layers.InputLayer(\n",
    "#             (None, self.num_indicator_features),\n",
    "#             input_var=self.x_indicator_features.astype(theano.config.floatX),\n",
    "#         )\n",
    "\n",
    "        self.cosine_combined = lasagne.layers.concat(\n",
    "            [\n",
    "               comparedVLayers(self.target_out, self.source_aligned_l),\n",
    "               comparedVLayers(self.target_out, self.source_context_aligned_l),\n",
    "               comparedVLayers(self.target_out, self.source_surface_words_aligned_l),\n",
    "                \n",
    "               comparedVLayers(self.target_title_out, self.source_aligned_l),\n",
    "               comparedVLayers(self.target_title_out, self.source_context_aligned_l),\n",
    "               comparedVLayers(self.target_title_out, self.source_surface_words_aligned_l),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "        self.cosine_weighted = lasagne.layers.DenseLayer(\n",
    "            self.cosine_combined,\n",
    "            name='cosine_dens1',\n",
    "            num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.linear,\n",
    "        )\n",
    "        \n",
    "#         self.cosine_weighted.W.get_value(borrow=True)[:] += 1\n",
    "        \n",
    "        self.cosine_output = lasagne.layers.get_output(\n",
    "            lasagne.layers.reshape(self.cosine_weighted, (-1,)))\n",
    "        \n",
    "        self.all_params += lasagne.layers.get_all_params(self.cosine_weighted)\n",
    "\n",
    "        self.query_feat_l = lasagne.layers.InputLayer(\n",
    "            (None,self.num_indicator_features),\n",
    "            input_var=self.x_query_featurs,\n",
    "        )\n",
    "    \n",
    "        self.denotation_join_feat_l = lasagne.layers.InputLayer(\n",
    "            (None,self.num_indicator_features),\n",
    "            input_var=self.x_denotaiton_features,\n",
    "        )\n",
    "        \n",
    "        self.query_layer_l = lasagne.layers.DenseLayer(\n",
    "            self.query_feat_l,\n",
    "            name='query_lin',\n",
    "            num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.linear,\n",
    "        )\n",
    "        \n",
    "        self.query_output = lasagne.layers.get_output(\n",
    "            lasagne.layers.reshape(self.query_layer_l, (-1,))\n",
    "        )\n",
    "        \n",
    "        self.all_params += lasagne.layers.get_all_params(self.query_layer_l)\n",
    "        \n",
    "        self.aligned_queries = self.query_output[self.x_query_link_id]\n",
    "        \n",
    "        self.aligned_cosine = self.cosine_output[self.x_target_link_id]\n",
    "        \n",
    "        self.denotation_layer_l = lasagne.layers.DenseLayer(\n",
    "            self.denotation_join_feat_l,\n",
    "            name='denotation_lin',\n",
    "            num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.linear,\n",
    "        )\n",
    "        \n",
    "        self.denotation_output = lasagne.layers.get_output(\n",
    "            lasagne.layers.reshape(self.denotation_layer_l, (-1,)))\n",
    "        \n",
    "        self.all_params += lasagne.layers.get_all_params(self.denotation_layer_l)\n",
    "        \n",
    "        ###########################\n",
    "        ## multiply the two parts of the join scores\n",
    "        \n",
    "        #  \n",
    "        self.unmerged_scores = (self.aligned_queries + 1) * (self.aligned_cosine + self.denotation_output + 1)\n",
    "        \n",
    "        # this should be the fastest way to compute this\n",
    "        # however it is creating matrices too large and isn't able to allocate enough memory or something\n",
    "        \n",
    "#         def mergingSelector(indx, outputs):\n",
    "#             return T.set_subtensor(outputs[indx[0], T.arange(indx[1],indx[2])], 1)\n",
    "        \n",
    "#         merging_seq = T.concatenate([\n",
    "#                 T.arange(self.x_denotation_ranges.shape[0]).reshape((self.x_denotation_ranges.shape[0], 1)),\n",
    "#                 self.x_denotation_ranges,\n",
    "#         ], axis=1)\n",
    "        \n",
    "#         self.merging_matrix, _ = theano.scan(\n",
    "#             mergingSelector,\n",
    "#             outputs_info=T.zeros((self.x_denotation_ranges.shape[0], self.denotation_output.shape[0])),\n",
    "#             sequences=merging_seq,\n",
    "#         )\n",
    "        \n",
    "#         self.merged_scores = T.dot(self.merging_matrix, self.unmerged_scores)\n",
    "        \n",
    "    \n",
    "        def mergingSum(indx, unmerged):\n",
    "            return unmerged[T.arange(indx[0], indx[1])].mean()\n",
    "    \n",
    "        self.merged_scores, _ = theano.scan(\n",
    "            mergingSum,\n",
    "            sequences=[self.x_denotation_ranges],\n",
    "            non_sequences=[self.unmerged_scores]\n",
    "        )\n",
    "        \n",
    "#         self.merged_scores = self.cosine_output\n",
    "        \n",
    "        # prevents the softmax from blowing up\n",
    "#         self.merged_rescaled = 10 * self.merged_scores / theano.gradient.disconnected_grad(abs(self.merged_scores).max())\n",
    "        \n",
    "        \n",
    "        #############################\n",
    "        ## Linear features combined\n",
    "        #############################\n",
    "\n",
    "        \n",
    "#         self.linear_features_combined = lasagne.layers.concat(\n",
    "#             [\n",
    "                \n",
    "#                comparedVLayers(self.target_out, self.source_aligned_l),\n",
    "#                comparedVLayers(self.target_out, self.source_context_aligned_l),\n",
    "#                comparedVLayers(self.target_out, self.source_surface_words_aligned_l),\n",
    "                \n",
    "#                comparedVLayers(self.target_title_out, self.source_aligned_l),\n",
    "#                comparedVLayers(self.target_title_out, self.source_context_aligned_l),\n",
    "#                comparedVLayers(self.target_title_out, self.source_surface_words_aligned_l),\n",
    "             \n",
    "                \n",
    "# #                 comparedVLayers(self.target_embedding_out, self.source_aligned_l),\n",
    "# #                 comparedVLayers(self.target_embedding_out, self.source_context_aligned_l),\n",
    "# #                 comparedVLayers(self.target_embedding_out, self.source_surface_words_aligned_l),\n",
    "                \n",
    "#             lasagne.layers.reshape(self.target_matched_surface_input_l, ([0],1)),\n",
    "#             self.target_matched_counts_input_l,\n",
    "#              self.indicator_feat_l\n",
    "#             ],\n",
    "#             axis=1\n",
    "#         )\n",
    "        \n",
    "#         self.linear_features_dens_l = lasagne.layers.DenseLayer(\n",
    "#             self.linear_features_combined,\n",
    "#             nonlinearity=lasagne.nonlinearities.linear,  # use tanh so that too large of values don't cause the softmax issues\n",
    "#             num_units=1,\n",
    "#             name='linear_final_l',\n",
    "#             W=lasagne.init.Normal(mean=0.0),\n",
    "#         )\n",
    "        \n",
    "#         self.linear_features_dens_l.W.get_value(borrow=True)[0:9] += 1.0  # set the word vecs positive\n",
    "# #         lin_feat_W = self.linear_features_dens_l.W.get_value(borrow=True)\n",
    "# #         lin_feat_add_one = np.eye(self.dim_compared_vec).reshape(self.dim_compared_vec**2, 1)\n",
    "# #         lin_feat_W[self.dim_compared_vec*2                           :self.dim_compared_vec*2+  self.dim_compared_vec**2] += lin_feat_add_one\n",
    "# #         lin_feat_W[self.dim_compared_vec*4+  self.dim_compared_vec**2:self.dim_compared_vec*4+2*self.dim_compared_vec**2] += lin_feat_add_one\n",
    "# #         lin_feat_W[self.dim_compared_vec*6+2*self.dim_compared_vec**2:self.dim_compared_vec*6+3*self.dim_compared_vec**2] += lin_feat_add_one\n",
    "        \n",
    "#         self.linear_output = lasagne.layers.get_output(\n",
    "#             lasagne.layers.reshape(self.linear_features_dens_l, ([0],))\n",
    "#         )\n",
    "        \n",
    "#         # rescaled the output so we don't crash the softmax layer with a value that is too large\n",
    "#         # just a hack\n",
    "#         self.linear_output_rescaled = 10 * self.linear_output / theano.gradient.disconnected_grad(abs(self.linear_output).max())\n",
    "        \n",
    "        ########################################\n",
    "        ## true output values\n",
    "        ########################################\n",
    "        \n",
    "        self.unscaled_output = self.merged_scores\n",
    "        \n",
    "        \n",
    "        # rescale the scores to prevent softmax from blowing up\n",
    "        self.true_output = 10 * self.unscaled_output / theano.gradient.disconnected_grad(abs(self.unscaled_output).max())#self.cosine_output # self.merged_rescaled #self.linear_output_rescaled\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.res_l = self.dotted_vectors / ((self.target_out.norm(1, axis=1) + .001) *\n",
    "#                                             (self.source_aligned_l.norm(1, axis=1) + .001))\n",
    "\n",
    "\n",
    "        #self.golds = self.res_cap[self.y_answer]\n",
    "\n",
    "#         def maxOverRange(indx):\n",
    "#             #return T.max(self.res_cap[T.arange(indx[0],indx[1])]) - self.res_cap[indx[2]]\n",
    "#             #return -( self.res_l[indx[2]] - T.log(T.exp(self.res_l[T.arange(indx[0],indx[1])]).sum()) )\n",
    "#             return -( self.res_l[indx[2]] - self.res_l[indx[0]])\n",
    "\n",
    "#         # build a tensor to make a matrix with one set on each dimention\n",
    "#         self.grouped, grouped_update = theano.scan(maxOverRange, sequences=self.y_grouping)\n",
    "\n",
    "        def setSubSelector(indx, outputs):\n",
    "            return T.set_subtensor(outputs[T.arange(indx[0], indx[1]), indx[3]], 1)\n",
    "\n",
    "        num_target_samples = self.true_output.shape[0]\n",
    "\n",
    "        select_seq = T.concatenate([\n",
    "            self.y_grouping,\n",
    "            T.arange(self.y_grouping.shape[0]).reshape((self.y_grouping.shape[0], 1))\n",
    "        ], axis=1)\n",
    "\n",
    "        self.selecting_matrix, _ = theano.scan(\n",
    "            setSubSelector,\n",
    "            outputs_info=T.zeros((num_target_samples, self.y_grouping.shape[0])), #num_target_samples)),\n",
    "            #n_steps=self.y_grouping.shape[0]\n",
    "            sequences=select_seq,\n",
    "        )\n",
    "\n",
    "#         self.groupped_elems = T.dot(self.selecting_matrix[-1], \n",
    "#                                     T.diag(T.exp(self.true_output)))\n",
    "#         self.groupped_res = T.log(self.groupped_elems.sum(axis=0)[T.arange(self.y_grouping.shape[0])])\n",
    "        self.groupped_elems = T.dot(self.selecting_matrix[-1].T, \n",
    "                                   T.exp(self.true_output))\n",
    "        self.groupped_res = T.log(self.groupped_elems)\n",
    "        \n",
    "        self.loss_vec = self.groupped_res - self.true_output[self.y_grouping[:,2]]\n",
    "        \n",
    "        if self.enable_boosting:\n",
    "            self.loss_scalar = T.dot(self.y_boosted, self.loss_vec)\n",
    "        else:\n",
    "            self.loss_scalar = self.loss_vec.sum()\n",
    "\n",
    "#         self.all_params = (\n",
    "#             lasagne.layers.get_all_params(self.document_simple_sum_l) +\n",
    "#             lasagne.layers.get_all_params(self.surface_context_pool1_l) +\n",
    "#             lasagne.layers.get_all_params(self.surface_pool1_l) +\n",
    "#             lasagne.layers.get_all_params(self.target_body_simple_sum_l) +\n",
    "#             lasagne.layers.get_all_params(self.target_words_pool1_l) + \n",
    "#             lasagne.layers.get_all_params(self.linear_features_dens_l)\n",
    "#         )\n",
    "        \n",
    "#         self.regularization = (self.linear_features_dens_l.W ** 2).sum() / 400\n",
    "\n",
    "        # weight the positive samples more since there are fewer of them,\n",
    "        # freaking hack\n",
    "        #self.loss_vec = -(10 * self.y_score * T.log(self.res_cap) + (1.0 - self.y_score) * T.log(1.0 - self.res_cap))\n",
    "\n",
    "        #self.loss_vec = T.nnet.binary_crossentropy(self.res_cap, self.y_score)\n",
    "\n",
    "        #self.loss_vec = T.exp(T.max(self.res_cap - self.res_cap[self.y_answer] + .1, 0)) - 1  # TODO: maybe have some squared term here or something?\n",
    "\n",
    "        # this one works reasonably well\n",
    "        #self.loss_vec = - T.log((T.clip(self.res_cap[self.y_answer] - self.res_cap, -1.0, 0.4) + 1.0) / 1.5)\n",
    "\n",
    "        #self.loss_vec = self.grouped\n",
    "\n",
    "        #self.loss_vec = - T.log((T.clip(self.res_l[self.y_answer] - self.res_l, -40.0, 10.0) + 40.0) / 51.0)\n",
    "        #self.loss_vec = T.max(self.res_l[self.y_answer] - self.res_l + .1, 0)\n",
    "\n",
    "        self.updates = lasagne.updates.adadelta(\n",
    "            self.loss_scalar / self.loss_vec.shape[0] , #+ self.regularization, \n",
    "            self.all_params)\n",
    "        \n",
    "        self.func_inputs = [\n",
    "            self.x_document_input,\n",
    "            self.x_surface_text_input, self.x_surface_context_input, self.x_document_id,\n",
    "            self.x_target_input, self.x_matches_surface, self.x_matches_counts, self.x_link_id, \n",
    "            self.x_target_words, self.x_target_document_words, #self.x_indicator_features,\n",
    "            self.x_denotaiton_features, self.x_query_featurs, self.x_query_link_id, self.x_denotation_ranges,\n",
    "            self.x_target_link_id,\n",
    "            self.y_answer, self.y_grouping, self.y_boosted\n",
    "        ]\n",
    "        \n",
    "        self.func_outputs = [\n",
    "            self.true_output,\n",
    "            self.loss_vec.sum(),\n",
    "            self.loss_scalar,\n",
    "            self.loss_vec,\n",
    "            #self.res_l,\n",
    "        ]\n",
    "\n",
    "        ################################################################3\n",
    "        ## TODO: need to return the actual output layer instead of the res_cap, since that is something else now\n",
    "        \n",
    "        self.train_func = theano.function(\n",
    "            self.func_inputs,\n",
    "            self.func_outputs,\n",
    "            updates=self.updates,\n",
    "            on_unused_input='ignore',\n",
    "        )\n",
    "\n",
    "        self.test_func = theano.function(\n",
    "            self.func_inputs,\n",
    "            self.func_outputs,\n",
    "            on_unused_input='ignore',\n",
    "        )\n",
    "\n",
    "    def reset_accums(self):\n",
    "        self.current_documents = []\n",
    "        self.current_surface_context = []\n",
    "        self.current_surface_link = []\n",
    "        self.current_link_id = []\n",
    "        self.current_target_input = []\n",
    "        self.current_target_words = []\n",
    "        self.current_target_body_words = []\n",
    "        self.current_target_matches_surface = []\n",
    "        self.current_target_id = []\n",
    "        self.current_target_goal = []\n",
    "#         self.current_feat_indicators = []\n",
    "        self.current_learning_groups = []\n",
    "        self.learning_targets = []\n",
    "        self.current_surface_target_counts = []\n",
    "        self.current_boosted_groups = []\n",
    "        \n",
    "        self.current_queries = []\n",
    "        self.current_denotations_feats_indicators = []\n",
    "        self.current_denotations_related_query = []\n",
    "        self.current_denotations_range = []\n",
    "        self.current_denotation_targets_linked = []\n",
    "        \n",
    "        self.failed_match = []\n",
    "            \n",
    "    def compute_batch(self, isTraining=True, useTrainingFunc=True):\n",
    "        if isTraining and useTrainingFunc:\n",
    "            func = self.train_func\n",
    "        else:\n",
    "            func = self.test_func\n",
    "        self.reset_accums()\n",
    "        self.total_links = 0\n",
    "        self.total_loss = 0.0\n",
    "        self.total_boosted_loss = 0.0\n",
    "\n",
    "        get_words = re.compile('[^a-zA-Z0-9 ]')\n",
    "        get_link = re.compile('.*?\\[(.*?)\\].*?')\n",
    "\n",
    "        for doc, queries in self.queries.iteritems():\n",
    "            # skip the testing documents while training and vice versa\n",
    "            if queries.values()[0]['training'] != isTraining:\n",
    "                continue\n",
    "            docid = len(self.current_documents)\n",
    "            self.current_documents.append(self.wordvecs.tokenize(doc, length=self.document_length))\n",
    "            for surtxt, targets in queries.iteritems():\n",
    "                self.current_link_id.append(docid)\n",
    "                surid = len(self.current_surface_link)\n",
    "                self.current_surface_context.append(self.wordvecs.tokenize(get_words.sub(' ' , surtxt)))\n",
    "                surlink = get_link.match(surtxt).group(1)\n",
    "                self.current_surface_link.append(self.wordvecs.tokenize(surlink, length=self.sentence_length_short))\n",
    "                surmatch = surlink.lower()\n",
    "                surcounts = self.surface_counts.get(surmatch)\n",
    "                if not surcounts:\n",
    "                    self.failed_match.append(surmatch)\n",
    "                    surcounts = {}\n",
    "                target_body_words_input = []  # words from the target document\n",
    "                target_words_input = []  # the words from the target title\n",
    "                target_matches_surface = []\n",
    "                target_inputs = []  # the target vector\n",
    "                target_learings = []\n",
    "                target_match_counts = []\n",
    "                target_gold_loc = -1\n",
    "                target_group_start = len(self.current_target_input)\n",
    "#                 target_feat_indicators = []\n",
    "                \n",
    "                denotations_joint_indicators = []\n",
    "                denotations_linked_query = []\n",
    "                denotations_range = []\n",
    "                \n",
    "                denotation_target_linked = []\n",
    "                \n",
    "                queries_feats_indicators = []\n",
    "                for ind in targets['query_vals']:\n",
    "                    query_feats = np.zeros((self.num_indicator_features,), dtype='int8')\n",
    "                    query_feats[ind] = 1\n",
    "                    queries_feats_indicators.append(query_feats)\n",
    "                queries_len = len(targets['query_vals'])\n",
    "                \n",
    "                for target in set(targets['vals'].keys() +\n",
    "                                 random.sample(self.documentvecs.reverse_word_location, self.num_negative_target_samples)\n",
    "                                  ) - {None,}:\n",
    "                    isGold = target == targets['gold']\n",
    "                    cnt_wrds = self.page_content.get(WikiRegexes.convertToTitle(target))\n",
    "                    wiki_title = WikiRegexes.convertToTitle(target)\n",
    "                    cnt = self.documentvecs.get_location(wiki_title)\n",
    "                    if wiki_title == 'nil':\n",
    "                        cnt = 0  # this is the stop symbol location\n",
    "                    if cnt is None:\n",
    "                        # were not able to find this wikipedia document\n",
    "                        # so just ignore tihs result since trying to train on it will cause\n",
    "                        # issues\n",
    "                        continue\n",
    "                    if isGold:\n",
    "                        target_gold_loc = len(target_inputs)\n",
    "                    target_body_words_input.append(cnt_wrds or [0]*self.sentence_length)\n",
    "                    target_words_input.append(self.wordvecs.tokenize(get_words.sub(' ', target), length=self.sentence_length_short))\n",
    "                    target_inputs.append(cnt)  \n",
    "                    # page_content already tokenized\n",
    "                    target_matches_surface.append(int(surmatch == target.lower()))\n",
    "                    target_learings.append((targets, target))\n",
    "                    target_match_counts.append(surcounts.get(wiki_title, 0))\n",
    "                    \n",
    "                    joint_indicators = []\n",
    "                    query_idx = []\n",
    "                    indicators_place = targets['vals'].get(target)\n",
    "                    if indicators_place:\n",
    "                        # [queries][indicator id]\n",
    "                        for indx in xrange(len(indicators_place[1])):\n",
    "                            local_feats = np.zeros((self.num_indicator_features,), dtype='int8')\n",
    "                            local_feats[indicators_place[1][indx]] = 1\n",
    "                            joint_indicators.append(local_feats)\n",
    "                            query_idx.append(len(self.current_queries) + indx)\n",
    "                    else:\n",
    "                        for indx in xrange(queries_len):\n",
    "                            local_feats = np.zeros((self.num_indicator_features,), dtype='int8')\n",
    "                            local_feats[self.impossible_query] = 1\n",
    "                            joint_indicators.append(local_feats)\n",
    "                            query_idx.append(len(self.current_queries) + indx)\n",
    "                            \n",
    "                    start_range = len(denotations_joint_indicators) + len(self.current_denotations_feats_indicators)\n",
    "                    denotations_joint_indicators += joint_indicators\n",
    "                    denotations_linked_query += query_idx\n",
    "                    denotations_range.append([start_range, start_range + len(joint_indicators)])\n",
    "                    denotation_target_linked += [len(self.current_target_words) + len(target_words_input) - 1] * len(query_idx)\n",
    "                    \n",
    "                    \n",
    "#                     indicators = np.zeros((self.num_indicator_features,), dtype='int8')\n",
    "#                     if indicators_place:\n",
    "                        \n",
    "#                         indicators[indicators_place[1]] = 1\n",
    "#                     target_feat_indicators.append(indicators)\n",
    "                    \n",
    "                    #if wiki_title not in surcounts:\n",
    "                    #    print surcounts, wiki_title\n",
    "                if target_gold_loc is not None or not isTraining:  # if we can't get the gold item\n",
    "                    # contain the index of the gold item for these items, so it can be less then it\n",
    "                    gold_loc = (len(self.current_target_goal) + target_gold_loc)\n",
    "                    sorted_match_counts = [-4,-3,-2,-1] + sorted(set(target_match_counts))\n",
    "                    #print sorted_match_counts\n",
    "                    target_match_counts_indicators = [\n",
    "                        [\n",
    "                            int(s == sorted_match_counts[-1]),\n",
    "                            int(s == sorted_match_counts[-2]),\n",
    "                            int(s == sorted_match_counts[-3]),\n",
    "                            int(0 < s <= sorted_match_counts[-4]),\n",
    "                            int(s == 0),\n",
    "                        ]\n",
    "                        for s in target_match_counts\n",
    "                    ]\n",
    "                    self.current_target_goal += [gold_loc] * len(target_inputs)\n",
    "                    self.current_target_input += target_inputs\n",
    "                    self.current_target_id += [surid] * len(target_inputs)\n",
    "                    self.current_target_words += target_words_input\n",
    "                    self.current_target_matches_surface += target_matches_surface\n",
    "                    self.current_surface_target_counts += target_match_counts_indicators\n",
    "                    self.current_target_body_words += target_body_words_input\n",
    "#                     self.current_feat_indicators += target_feat_indicators\n",
    "                    \n",
    "                    target_group_end = len(self.current_target_input)\n",
    "                    self.current_learning_groups.append(\n",
    "                        [target_group_start, target_group_end,\n",
    "                         gold_loc])\n",
    "                    self.current_boosted_groups.append(targets['boosted'])\n",
    "                    \n",
    "                    self.current_queries += queries_feats_indicators\n",
    "                    \n",
    "                    self.current_denotations_feats_indicators += denotations_joint_indicators\n",
    "                    self.current_denotations_related_query += denotations_linked_query\n",
    "                    self.current_denotations_range += denotations_range\n",
    "                    \n",
    "                    self.current_denotation_targets_linked += denotation_target_linked\n",
    "\n",
    "                #self.current_target_goal.append(isGold)\n",
    "                self.learning_targets += target_learings\n",
    "            if len(self.current_target_id) > self.batch_size:\n",
    "                self.run_batch(func)\n",
    "                if self.total_links > self.num_training_items:\n",
    "                    return self.total_loss / self.total_links, self.total_boosted_loss / self.total_links\n",
    "\n",
    "        if len(self.current_target_id) > 0:\n",
    "            self.run_batch(func)\n",
    "\n",
    "        return self.total_loss / self.total_links, self.total_boosted_loss / self.total_links\n",
    "\n",
    "    def run_batch(self, func):\n",
    "        res_vec, loss_sum, loss_boosted, loss_vec, = func(\n",
    "            self.current_documents,\n",
    "            self.current_surface_link, self.current_surface_context, self.current_link_id,\n",
    "            self.current_target_input, self.current_target_matches_surface, self.current_surface_target_counts, self.current_target_id, \n",
    "            self.current_target_words, self.current_target_body_words, #self.current_feat_indicators,\n",
    "            self.current_denotations_feats_indicators, self.current_queries, self.current_denotations_related_query, self.current_denotations_range,\n",
    "            self.current_denotation_targets_linked,\n",
    "            self.current_target_goal, self.current_learning_groups, self.current_boosted_groups,\n",
    "        )\n",
    "        self.check_params()\n",
    "        self.total_links += len(self.current_target_id)\n",
    "        self.total_loss += loss_sum\n",
    "        self.total_boosted_loss += loss_boosted\n",
    "        learned_groups = []  # right...dict not hashable....\n",
    "        for i in xrange(len(res_vec)):\n",
    "            # save the results from this pass\n",
    "            l = self.learning_targets[i]\n",
    "            if l[1] in l[0]['vals']:\n",
    "                l[0]['vals'][ l[1] ][0] = float(res_vec[i]), 0#float(nn_outs[i])\n",
    "            if l[0] not in learned_groups:\n",
    "                learned_groups.append(l[0])\n",
    "        for group in learned_groups:\n",
    "            if group['gold']:\n",
    "                correct = max(group['vals']) == group['vals'].get(group['gold'])\n",
    "                group['boosted'] *= .4 if correct else 2.0\n",
    "                if self.enable_cap_boosting:\n",
    "                    if group['boosted'] > 10:\n",
    "                        group['boosted'] = 10.0\n",
    "                    elif group['boosted'] < 0.1:\n",
    "                        group['boosted'] = 0.1\n",
    "        self.reset_accums()\n",
    "\n",
    "    def check_params(self):\n",
    "        if any([np.isnan(v.get_value(borrow=True)).any() for v in self.all_params]):\n",
    "            raise RuntimeError('nan in some of the parameters')\n",
    "\n",
    "\n",
    "\n",
    "queries_exp = EntityVectorLinkExp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.7 s, sys: 4.34 s, total: 42 s\n",
      "Wall time: 9.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.32305233190555382, 0.32305233190555382)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# queries_exp.num_training_items = 5000\n",
    "# %time queries_exp.compute_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[document_simple_conv.W,\n",
       " document_simple_conv.b,\n",
       " surface_cxt_conv1.W,\n",
       " surface_cxt_conv1.b,\n",
       " surface_conv1.W,\n",
       " surface_conv1.b,\n",
       " target_wrds_conv1.W,\n",
       " target_wrds_conv1.b,\n",
       " target_body_simple_conv.W,\n",
       " target_body_simple_conv.b,\n",
       " cosine_dens1.W,\n",
       " cosine_dens1.b,\n",
       " query_lin.W,\n",
       " query_lin.b,\n",
       " denotation_lin.W,\n",
       " denotation_lin.b]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_exp.all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalCurrentState(trainingData=True, numSamples=50000):\n",
    "    all_measured = 0\n",
    "    all_correct = 0\n",
    "    all_trained = 0\n",
    "    for qu in queries.values():\n",
    "        for en in qu.values():\n",
    "            if en['training'] != trainingData:\n",
    "                continue\n",
    "            if en['gold']:\n",
    "                if all_trained > numSamples:\n",
    "                    break\n",
    "                all_measured += 1\n",
    "                all_trained += len(en['vals'].values())\n",
    "                m = max(en['vals'].values())\n",
    "                if en['vals'].get(en['gold']) == m and m != 0:\n",
    "                    all_correct += 1\n",
    "           \n",
    "    r = all_measured, float(all_correct) / all_measured\n",
    "    print r\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalCurrentStateRank(trainingData=True, numSamples=50000):\n",
    "    all_measured = 0\n",
    "    all_correct_place = 0\n",
    "    p_counts = dict((k,0) for k in range(0,10))\n",
    "    all_trained = 0\n",
    "    for qu in queries.values():\n",
    "        for en in qu.values():\n",
    "            if en['training'] != trainingData:\n",
    "                continue\n",
    "            if en['gold']:\n",
    "                if all_trained > numSamples:\n",
    "                    break\n",
    "                svals = sorted(en['vals'].values(), key=lambda x: 0 if not isinstance(x, tuple) else -x[0])\n",
    "                gv = en['vals'][en['gold']]\n",
    "                if gv == 0:\n",
    "                    continue\n",
    "                all_measured += 1\n",
    "                for i in xrange(len(svals)):\n",
    "                    if svals[i] == gv:\n",
    "                        if i < 10:\n",
    "                            p_counts[i] += 1\n",
    "                        all_correct_place += i + 1\n",
    "                        break\n",
    "\n",
    "    r = all_measured, float(all_correct_place) / all_measured, p_counts\n",
    "    print r\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalCurrentStateF1(trainingData=True, numSamples=50000):\n",
    "    correct = 0\n",
    "    precDenom = 0\n",
    "    recDenom = 0\n",
    "    all_trained = 0\n",
    "    all_measured = 0\n",
    "    for qu in queries.values():\n",
    "        if qu.values()[0]['training'] != trainingData:\n",
    "            continue\n",
    "        allGold = set()\n",
    "        allChoosen = set()\n",
    "        if all_trained > numSamples:\n",
    "            break\n",
    "        for en in qu.values():\n",
    "            if en['gold']:  # we can eval this item\n",
    "                all_measured += 1\n",
    "                allGold.add(en['gold'])\n",
    "                svals = sorted(en['vals'].values())\n",
    "                picked = None\n",
    "                for k,v in en['vals'].iteritems():\n",
    "                    all_trained += 1\n",
    "                    if v == svals[-1]:\n",
    "                        picked = k\n",
    "                allChoosen.add(picked)\n",
    "                #if svals[0] == svals[1] and en['gold'] != picked:\n",
    "                #    raise NotImplementedError()\n",
    "#                 if en['gold'] == picked:\n",
    "#                     correct += 1\n",
    "#             if len(svals) > 5 and en['gold'] != picked:\n",
    "#                 raise NotImplementedError()\n",
    "        precDenom += len(allChoosen)\n",
    "        recDenom += len(allGold)\n",
    "        correct += len(allGold & allChoosen)\n",
    "    correct = float(correct)\n",
    "    prec = correct / precDenom\n",
    "    rec = correct / recDenom\n",
    "    f1 = 2 * prec * rec / (prec + rec)\n",
    "    r = all_measured, 'Prec = {}/{} = {}, Rec = {}/{} = {}, F1 = {}'.format(\n",
    "        correct, precDenom, prec, \n",
    "        correct, recDenom, rec, \n",
    "        f1)\n",
    "    print r\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorted(queries.values()[0].values()[0]['vals'].values(), key=lambda x: 0 if not isinstance(x, tuple) else -x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# def augmentTrainingData():\n",
    "#     for quk in queries.keys():\n",
    "#         qu = queries[quk]\n",
    "#         for enk in qu.keys():\n",
    "#             en = qu[enk]\n",
    "#             if not en['gold']:\n",
    "#                 del qu[enk]\n",
    "#         if not qu:\n",
    "#             del queries[quk]\n",
    "#     for qu in queries.values():\n",
    "#         training = random.random() > .15\n",
    "#         for en in qu.values():\n",
    "#             en['training'] = training\n",
    "# augmentTrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findWrongItems(trainingData=True, numSamples=50):\n",
    "    ret = {}\n",
    "    for qu in queries.values():\n",
    "        for ek, en in qu.items():\n",
    "            if en['training'] != trainingData:\n",
    "                continue\n",
    "            for e in en:\n",
    "                if en['gold']:\n",
    "                    if len(ret) > numSamples:\n",
    "                        return ret\n",
    "                    m = max(en['vals'].values())\n",
    "                    g = en['vals'].get(en['gold'], 0)\n",
    "                    if g != m and g != 0:\n",
    "                        ret[ek] = en\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.check_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queries_exp.num_training_items = 250000# 250000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'target' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-9fc22472df6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mqueries_exp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_training_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time print queries_exp.compute_batch()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2334\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2335\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2336\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2338\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2255\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2256\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2257\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2258\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-1ac72bc9ed3b>\u001b[0m in \u001b[0;36mcompute_batch\u001b[1;34m(self, isTraining, useTrainingFunc)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 \u001b[0mqueries_feats_indicators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'query_vals'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m                     \u001b[0mquery_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_indicator_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                     \u001b[0mquery_feats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'target' referenced before assignment"
     ]
    }
   ],
   "source": [
    "queries_exp.num_training_items = 50000\n",
    "%time print queries_exp.compute_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[  2.25418884e-09,  -1.05965441e-08,  -1.08542056e-11,\n",
       "             1.48679971e-10,  -3.70079661e-10,   8.10984879e-09,\n",
       "             2.83995782e-09,  -7.58791163e-09,   1.44092704e-09,\n",
       "            -5.21039156e-10,   3.83327015e-09,  -6.97350977e-09,\n",
       "             7.41164152e-09,   2.56155741e-09,   7.06192482e-09,\n",
       "            -2.65219424e-09,  -5.10543030e-09,  -2.67997929e-10,\n",
       "            -6.05010930e-09,   1.29151201e-09,   3.90672739e-09,\n",
       "            -1.60321534e-09,  -6.67960531e-09,  -1.06834408e-08,\n",
       "            -1.52408985e-09,  -3.43769013e-09,   5.71510705e-09,\n",
       "            -1.50977730e-09,  -1.31514755e-08,  -4.86911178e-09,\n",
       "             1.11039511e-09,  -8.41305869e-09,   7.66608166e-10,\n",
       "            -1.93872030e-09,  -2.17447549e-09,  -1.01494866e-08,\n",
       "             2.11311568e-09,  -2.87067126e-09,  -1.14038743e-08,\n",
       "             7.45462359e-09,  -2.55842503e-09,   5.26563948e-09,\n",
       "            -9.17957443e-09,   2.05164019e-09,   7.46965778e-09,\n",
       "            -1.56707554e-08,  -1.27694930e-08,   1.27478490e-08,\n",
       "             5.60636826e-09,  -8.67548700e-09,  -3.41519235e-09,\n",
       "             4.33632819e-09,   3.20805427e-09,  -3.91220745e-09,\n",
       "             5.76125503e-09,   2.55927168e-09,   1.42821168e-08,\n",
       "             8.18381185e-09,   5.38777334e-09,  -1.71546937e-08,\n",
       "             7.82390241e-09,  -9.24628907e-09,   1.31901357e-09,\n",
       "             1.86055771e-09,   7.25623606e-09,   5.43153567e-09,\n",
       "             1.11143139e-09,   3.35055872e-09,   6.66255628e-09,\n",
       "             1.89060056e-09,  -1.12690124e-08,   2.61726774e-09,\n",
       "            -2.53900345e-09,  -5.83661963e-09,  -1.25988411e-08,\n",
       "             2.95584668e-09,   9.01037733e-09,   1.34833522e-09,\n",
       "            -9.99624272e-10,   5.30082334e-09,   1.39490197e-08,\n",
       "             8.23977953e-09,   5.55332134e-11,  -4.23266844e-09,\n",
       "             4.05027789e-09,   9.79824577e-09,  -8.14735224e-10,\n",
       "             3.88781363e-09,   9.64455071e-10,   1.26614328e-08,\n",
       "             1.63983471e-09,   5.21439159e-09,  -2.70074674e-09,\n",
       "            -8.57608118e-09,   2.77175699e-10,   1.69556835e-09,\n",
       "            -5.85176396e-09,   2.44671239e-09,  -1.35073486e-09,\n",
       "            -1.89760829e-09,   3.60058872e-09,   2.72938960e-09,\n",
       "             4.07875600e-09,   2.59414912e-09,   2.33853381e-10,\n",
       "             4.46799292e-10,   1.11411946e-09,   8.43232328e-09,\n",
       "             4.13807122e-09,   9.01706620e-09,  -2.12384044e-09,\n",
       "            -1.08055556e-08,  -1.37490053e-09,  -5.80889337e-09,\n",
       "            -5.35745359e-09,   2.83246093e-09,  -2.45345033e-09,\n",
       "             2.28963870e-09,  -8.11768253e-09,  -3.28999805e-09,\n",
       "            -1.66121854e-08,   2.68263967e-09,   1.06421288e-10,\n",
       "            -7.10011516e-09,  -3.91197474e-09,   1.27534676e-08,\n",
       "             3.20398930e-09,   5.23434851e-09,   5.09999243e-09,\n",
       "            -1.21127652e-09,   1.16684893e-08,  -7.21738225e-09,\n",
       "             3.79664211e-09,   4.48841853e-09,   4.60921878e-09,\n",
       "            -1.95483296e-09,   4.60063143e-09,   1.91762450e-09,\n",
       "            -1.38365834e-08,   8.11763812e-09,  -6.73108813e-09,\n",
       "            -1.78493149e-08,   9.07906372e-09,  -7.45709539e-09,\n",
       "            -6.48707266e-09,  -1.60976921e-08,   1.13594059e-08,\n",
       "            -5.99047922e-09,   1.02047668e-08,  -1.97309564e-08,\n",
       "             1.22828272e-08,  -2.45104631e-10,  -8.80051232e-09,\n",
       "            -8.83122642e-09,   4.39903758e-09,   2.86157564e-09,\n",
       "            -6.79838896e-09,  -9.63983471e-09,  -3.18488652e-10,\n",
       "            -2.41995690e-09,  -5.97102012e-09,   3.83615895e-09,\n",
       "             8.71004247e-09,  -3.60397290e-09,   5.72549341e-09,\n",
       "             6.06299955e-10,   1.74014190e-08,  -7.21061033e-09,\n",
       "             2.19340368e-09,   8.25865687e-09,   6.22429042e-09,\n",
       "            -8.34391845e-09,  -1.21235821e-09,   4.25501190e-09,\n",
       "            -3.46070994e-09,  -5.82473270e-09,  -3.34755779e-09,\n",
       "            -6.49484733e-09,   7.38630446e-09,   1.32945628e-08,\n",
       "            -3.05609510e-10,  -2.46961229e-09,   5.13608134e-09,\n",
       "            -4.93598007e-09,  -1.07241913e-08,   3.61679886e-09,\n",
       "             4.23188595e-09,   3.13359916e-09,  -2.45213405e-09,\n",
       "             1.34093725e-09,   1.20855832e-08,  -1.22751320e-09,\n",
       "             1.26239341e-09,   1.01761544e-09,  -7.18731075e-09,\n",
       "             3.52191232e-09,  -8.27318036e-09,  -1.14773979e-09,\n",
       "             2.81069545e-09,  -4.01447497e-09,  -9.84288917e-09,\n",
       "             1.07891185e-09,  -8.59746052e-09,  -2.97224223e-09,\n",
       "            -2.89039082e-09,   4.41754144e-09,  -9.47153822e-09,\n",
       "             9.23248944e-09,   3.01948844e-09,  -3.18724891e-09,\n",
       "             2.57498955e-09,   1.32115003e-08,   2.90277780e-09,\n",
       "             5.77687986e-09,  -1.46589418e-09,   1.02966462e-08,\n",
       "            -1.04628195e-09,   9.41393896e-09,   1.35407330e-09,\n",
       "            -6.54501520e-09,  -9.39623934e-09,  -5.00439734e-09,\n",
       "             2.49498067e-09,   1.27237838e-08,   9.96324534e-09,\n",
       "            -8.95181884e-09,   5.30454791e-10,   1.74645187e-08,\n",
       "            -6.99531943e-09,  -3.20390803e-09,   3.26095151e-09,\n",
       "            -3.15662518e-09,  -3.44685303e-09,   5.05321340e-09,\n",
       "             7.84784349e-10,   6.32360653e-09,  -1.87267979e-09,\n",
       "             2.79634343e-10,   1.65155019e-08,   2.80469137e-09,\n",
       "             3.45875928e-09,   4.29423608e-09,  -8.45204173e-09,\n",
       "            -3.07240611e-09,   6.52873311e-09,  -4.30958114e-09,\n",
       "             5.36607159e-09,  -6.54442278e-09,   3.41880346e-09,\n",
       "             7.33041494e-09,  -9.76647874e-10,  -2.06307083e-09,\n",
       "            -2.25778019e-09,   7.17010895e-09,   6.88591539e-09,\n",
       "            -1.47940526e-09,   4.19493151e-09,   4.30796554e-09,\n",
       "            -1.46109724e-09,   1.03407620e-08,  -6.09161965e-09,\n",
       "             6.05089800e-09,  -3.05035464e-09,   3.17754961e-10,\n",
       "            -1.11820544e-08,  -1.08710652e-09,  -1.09660805e-08,\n",
       "            -1.60280747e-10,  -8.70329675e-09,  -4.72533479e-09,\n",
       "             1.28288473e-08,  -2.92294811e-09,  -9.55744461e-09,\n",
       "             4.05699563e-09,   9.97516025e-09,  -9.97171767e-09,\n",
       "            -8.45932124e-09,   5.40379741e-09,  -2.79637313e-09,\n",
       "             5.58798008e-10,  -4.72541561e-09,   4.93382624e-09,\n",
       "             3.02116354e-09,  -6.17871754e-09,   3.49070950e-09,\n",
       "            -5.50095747e-09,  -1.02807696e-09,  -7.76080356e-09,\n",
       "             3.87778165e-09,   3.72971698e-09,   1.04766134e-08,\n",
       "            -5.27463406e-10,  -8.86130547e-09,  -1.63784790e-08,\n",
       "            -2.23316587e-09,   9.20935772e-09,  -1.25036275e-08,\n",
       "             1.21582744e-09,  -6.81992418e-09,   3.79976894e-09],\n",
       "          [  3.92041777e-09,  -8.06953082e-09,  -6.19985008e-10,\n",
       "             4.31129266e-09,  -3.49954044e-09,   5.75421599e-10,\n",
       "            -1.02421982e-09,  -4.44401138e-09,   2.86818103e-09,\n",
       "            -6.38932862e-09,   2.36594699e-09,  -6.19747054e-09,\n",
       "             4.78598627e-09,  -3.12895398e-09,   1.45154999e-09,\n",
       "            -3.06006331e-09,  -1.58306912e-09,  -2.06167527e-09,\n",
       "            -6.06216499e-09,  -1.13527088e-09,  -5.10254594e-09,\n",
       "            -1.60976832e-09,  -1.47717580e-08,  -3.87556787e-09,\n",
       "             4.06020023e-10,  -2.87565616e-09,   1.31547184e-09,\n",
       "            -1.09679621e-09,  -1.00857003e-08,  -8.37887359e-09,\n",
       "             2.77451995e-09,  -6.56506138e-09,  -3.45028739e-09,\n",
       "            -3.63425978e-09,  -4.07178202e-09,  -5.99689809e-09,\n",
       "             3.63197716e-09,  -3.49009688e-09,  -1.06671019e-08,\n",
       "             7.40704786e-09,   3.08659293e-10,   2.01081082e-10,\n",
       "            -6.94235291e-09,   1.15035856e-08,   5.82585091e-09,\n",
       "            -1.26220598e-08,  -9.47673406e-09,   9.77443637e-09,\n",
       "             7.31732142e-09,  -9.48055678e-09,  -3.23280358e-09,\n",
       "            -8.92879798e-11,   3.21411942e-09,   1.78171835e-11,\n",
       "             2.67804157e-09,  -1.85937898e-09,   1.13102407e-08,\n",
       "             7.14776727e-09,  -9.64941571e-10,  -1.00433306e-08,\n",
       "             7.56759722e-09,  -6.00019634e-09,  -9.13273623e-11,\n",
       "             3.27159499e-09,   7.00718150e-09,  -6.50538123e-10,\n",
       "             6.59885091e-10,  -2.92104119e-09,   4.78652895e-10,\n",
       "             2.23545382e-09,  -6.35185771e-09,   1.93565874e-09,\n",
       "            -5.98863448e-09,  -2.04332062e-09,  -9.90248505e-09,\n",
       "             7.45195017e-09,   6.54729382e-09,  -2.23068231e-09,\n",
       "            -2.96686831e-09,   9.78465753e-09,   9.29155508e-09,\n",
       "             8.54327986e-09,   7.91271382e-10,  -2.66357714e-09,\n",
       "            -9.80964199e-10,   8.40222647e-09,  -2.54941601e-09,\n",
       "             7.20507876e-09,  -2.57177613e-10,   1.18371037e-08,\n",
       "             8.78827322e-09,   4.82704765e-09,   1.88755611e-09,\n",
       "            -7.89841170e-09,   3.80087029e-09,  -3.08646841e-09,\n",
       "             9.47922074e-10,   7.52675422e-10,  -3.14898130e-09,\n",
       "             1.60739158e-10,   3.62670960e-09,   7.77712472e-09,\n",
       "             3.84357257e-09,   1.03612208e-09,  -4.86115370e-09,\n",
       "            -4.43305226e-10,  -2.84760948e-09,   8.05625167e-09,\n",
       "             6.31630082e-09,   8.23487145e-09,  -5.05301445e-09,\n",
       "            -7.67877495e-09,   2.05897543e-09,  -8.19585555e-09,\n",
       "            -2.42859821e-09,   5.95328720e-09,  -8.35721448e-09,\n",
       "             4.19661683e-09,  -4.93727548e-09,  -4.75364947e-09,\n",
       "            -1.33666118e-08,   1.05647346e-09,   6.57285160e-09,\n",
       "            -1.55217084e-09,  -2.62565236e-09,   1.01540021e-08,\n",
       "             4.89324048e-09,   2.16147544e-09,   8.36676772e-09,\n",
       "             1.77705151e-09,   4.30236424e-09,  -3.09577342e-09,\n",
       "            -8.94977648e-10,   6.34436148e-09,   5.28092547e-09,\n",
       "            -3.08454795e-09,   1.02490627e-09,   1.75196269e-09,\n",
       "            -1.00789173e-08,   1.08170193e-08,  -3.30641359e-09,\n",
       "            -7.94232236e-09,   1.25492319e-08,  -6.70585232e-09,\n",
       "            -5.67619862e-09,  -1.38690259e-08,   7.68670638e-09,\n",
       "            -1.23417330e-08,   1.23468986e-08,  -1.47677968e-08,\n",
       "             7.70457209e-09,   4.88228069e-11,  -1.27756907e-08,\n",
       "            -2.54747357e-09,   1.06532321e-08,   5.52184787e-09,\n",
       "            -4.39653292e-09,  -1.51018364e-09,   8.47929282e-10,\n",
       "            -4.49010917e-09,  -1.94279526e-09,   5.22488142e-09,\n",
       "             9.78348069e-09,  -2.59017363e-09,   2.96054270e-09,\n",
       "             1.17586585e-09,   1.08481686e-08,  -7.80408360e-09,\n",
       "            -9.99088479e-10,   1.09118456e-08,   4.92975882e-10,\n",
       "            -4.81933116e-09,   4.52394833e-09,   6.23102236e-09,\n",
       "             1.03973263e-09,  -6.08253359e-09,  -5.89343241e-09,\n",
       "            -3.18242521e-09,   8.44695514e-09,   1.32780889e-08,\n",
       "            -3.76344511e-09,  -3.39378303e-09,   4.66291139e-09,\n",
       "             1.53728319e-09,  -5.63405722e-09,   2.75677814e-09,\n",
       "            -3.93232114e-09,   7.55124230e-09,  -4.99699526e-09,\n",
       "            -1.75456971e-09,   8.55563353e-09,  -2.07329029e-10,\n",
       "             3.36519368e-09,   7.89810772e-10,  -4.75983297e-09,\n",
       "             2.29521357e-09,  -7.50124940e-09,   4.34181757e-09,\n",
       "            -6.63396449e-10,   1.01482511e-09,  -1.05618447e-08,\n",
       "             1.32775169e-09,  -1.03596678e-08,   7.15339787e-10,\n",
       "            -2.74776396e-10,  -3.29679239e-09,  -1.29419062e-08,\n",
       "             7.83053178e-09,   2.67827271e-09,  -4.67782202e-10,\n",
       "             7.85036747e-09,   1.43254271e-08,   5.98409633e-09,\n",
       "             1.20975310e-08,   1.46183909e-09,   1.53258046e-08,\n",
       "            -1.05937636e-09,   5.66373970e-09,  -3.13067960e-10,\n",
       "            -8.71469386e-09,  -9.06274167e-09,  -5.34965761e-09,\n",
       "            -3.51735752e-09,   3.67556252e-09,   5.39876366e-09,\n",
       "            -6.41477405e-09,  -1.31041608e-10,   9.56239887e-09,\n",
       "            -3.23651173e-09,  -6.47718190e-09,   4.81370022e-12,\n",
       "            -4.72285633e-09,  -5.01018116e-10,   1.60514824e-09,\n",
       "             2.28170993e-09,   2.59869259e-09,  -3.45910300e-09,\n",
       "             5.31026112e-09,   5.44317924e-09,   5.35008926e-09,\n",
       "             4.40336523e-09,  -5.54724933e-10,  -1.08387099e-09,\n",
       "            -2.98668357e-09,   4.15182866e-09,   1.89467397e-09,\n",
       "             2.36380610e-10,  -3.38953687e-09,   4.79849138e-09,\n",
       "             2.62678013e-09,  -4.65642724e-09,  -3.70858699e-09,\n",
       "            -1.19290666e-08,   4.52859927e-09,   1.91193816e-09,\n",
       "            -1.85503024e-09,   3.16393067e-09,  -1.20602806e-09,\n",
       "             4.33431424e-09,   2.96159852e-09,  -7.73271758e-09,\n",
       "            -1.99073003e-09,  -5.93009863e-09,  -1.86008497e-09,\n",
       "            -6.43411679e-09,  -7.71662290e-09,  -1.27721727e-08,\n",
       "             6.97051794e-09,  -8.82409878e-09,  -9.37395495e-10,\n",
       "             1.20379520e-08,   5.47344792e-09,  -8.38171754e-09,\n",
       "             1.50773038e-09,   1.04905480e-08,  -4.51730520e-09,\n",
       "            -3.43660234e-09,   4.34533209e-09,  -1.19644328e-09,\n",
       "            -1.75853065e-09,  -9.08425690e-09,   3.95900068e-09,\n",
       "             2.26484609e-09,  -1.68405623e-09,   5.04938003e-09,\n",
       "            -3.67792063e-09,   1.30298428e-09,  -4.15695389e-09,\n",
       "             5.86300741e-09,   3.82108123e-09,   1.09948033e-08,\n",
       "            -8.69503403e-09,  -1.05433022e-08,  -1.41904151e-08,\n",
       "             1.16658927e-09,   1.06393943e-08,  -1.27851898e-08,\n",
       "             2.65776468e-09,  -1.18893917e-08,  -3.16592613e-10]]]], dtype=float32),\n",
       " array([  1.30993492e-08], dtype=float32),\n",
       " array([[[[ -1.19491615e-05,   4.50207190e-05,  -2.68788608e-06, ...,\n",
       "             5.31095393e-05,  -1.53016415e-04,   4.42343880e-05],\n",
       "          [ -4.22706544e-05,   8.14286905e-05,  -1.17256037e-04, ...,\n",
       "            -1.60058757e-04,   4.42603887e-05,  -3.77055170e-04],\n",
       "          [  6.17816404e-05,   1.85015801e-04,  -6.88909437e-04, ...,\n",
       "             1.48144594e-04,  -5.28295350e-04,  -4.99047273e-05],\n",
       "          [ -1.13958813e-04,   2.37222790e-04,   3.93367343e-04, ...,\n",
       "             2.78840656e-04,  -6.24595967e-04,   2.81574539e-05],\n",
       "          [ -9.69138055e-05,  -5.29745244e-04,  -4.45291953e-04, ...,\n",
       "             1.91644445e-04,  -2.43894770e-04,   2.98372732e-04]]]], dtype=float32),\n",
       " array([ 78.03722382], dtype=float32),\n",
       " array([[[[ 0.17404141, -0.20638171, -0.04222938, ...,  0.28350037,\n",
       "           -0.62854183, -0.1058534 ],\n",
       "          [-0.48253235,  0.0481697 ,  0.15434474, ..., -0.13061652,\n",
       "            0.76728982,  0.07479483],\n",
       "          [-0.31643194, -0.02892325, -0.06594513, ...,  0.34675223,\n",
       "           -1.22552383,  0.37006757],\n",
       "          [-4.35167074,  1.98585629,  0.56091869, ..., -2.15621328,\n",
       "            0.81895667,  1.13911819],\n",
       "          [ 0.54828423,  0.7423175 ,  0.42645946, ..., -1.23054206,\n",
       "            0.72306842, -0.77960742]]]], dtype=float32),\n",
       " array([-119.41152954], dtype=float32),\n",
       " array([[[[ -2.02411029e-04,  -8.80977546e-04,  -5.23896597e-04, ...,\n",
       "            -8.58682673e-04,   6.22522726e-04,   1.15417072e-03],\n",
       "          [  1.09835891e-02,   6.33919472e-03,   7.24717742e-03, ...,\n",
       "             4.63823555e-03,  -2.01287456e-02,   9.47237760e-03],\n",
       "          [ -7.05136135e-02,   4.42644730e-02,   7.60935917e-02, ...,\n",
       "            -1.54918671e-01,   8.43211636e-02,  -1.68485511e-02],\n",
       "          [ -1.88356593e-01,  -1.35234863e-01,   2.65012011e-02, ...,\n",
       "            -4.24185306e-01,   1.67231262e-01,   2.32557431e-01],\n",
       "          [ -2.39773035e+00,   3.25888610e+00,   1.14626455e+00, ...,\n",
       "            -2.63788486e+00,   5.96734858e+00,   2.53831565e-01]]]], dtype=float32),\n",
       " array([-120.73056793], dtype=float32),\n",
       " array([[[[  3.49777203e-08,   9.84108297e-08,  -6.88066208e-08,\n",
       "             1.19747412e-07,  -3.16622568e-08,  -1.07251118e-07,\n",
       "             3.99807902e-08,   2.64998885e-08,   6.21771292e-08,\n",
       "            -5.89827120e-09,  -4.22830801e-08,  -8.82156854e-08,\n",
       "             2.77856476e-08,  -2.06101589e-08,  -1.50942142e-07,\n",
       "             1.48316881e-09,   1.41054759e-08,   1.15481342e-07,\n",
       "            -7.52470299e-08,   1.13672435e-07,  -5.87237849e-08,\n",
       "             5.51525048e-08,   2.12853095e-08,   1.14131782e-09,\n",
       "            -4.61197445e-08,  -9.93232163e-08,  -1.34632074e-07,\n",
       "             5.94304943e-08,   1.30082043e-07,   9.70490248e-08,\n",
       "            -1.33788216e-08,  -1.15425330e-07,  -4.27737206e-08,\n",
       "            -4.70350976e-08,   1.06031388e-08,   8.00114179e-08,\n",
       "            -6.62785666e-08,   1.00708874e-07,   2.32432029e-08,\n",
       "            -8.59497646e-08,  -1.01976688e-07,  -3.49155229e-08,\n",
       "            -2.80108150e-08,  -5.06732327e-08,  -3.77134022e-08,\n",
       "            -1.11740590e-08,  -5.37260014e-08,  -4.06658174e-08,\n",
       "             8.55999502e-08,   8.41764916e-08,  -3.55536685e-08,\n",
       "             2.08851905e-08,  -2.37133079e-07,   1.49784029e-07,\n",
       "             5.87382054e-08,   5.34259321e-08,  -1.02725593e-07,\n",
       "            -8.69779893e-09,  -1.84828730e-09,   2.18515723e-07,\n",
       "            -2.82249779e-08,   1.11217297e-07,   7.43146744e-09,\n",
       "             2.42662637e-08,  -7.09361530e-08,  -4.21530046e-08,\n",
       "             8.34859009e-08,   3.44392319e-08,  -6.61485657e-08,\n",
       "            -1.58166898e-07,   9.07322999e-08,   1.80245632e-08,\n",
       "            -5.16356060e-08,   4.70532626e-08,   1.48214156e-07,\n",
       "            -1.33257771e-07,   8.86277931e-08,   1.16885639e-08,\n",
       "            -3.35752048e-08,  -6.03191452e-08,  -1.48826217e-07,\n",
       "            -9.43827345e-08,  -8.29334610e-08,   1.05652042e-07,\n",
       "             6.07370723e-08,  -2.88905593e-08,   2.21260208e-07,\n",
       "             1.09419894e-07,  -1.30975719e-08,  -1.09031312e-07,\n",
       "            -7.14778281e-08,  -2.57327066e-08,  -2.69878946e-08,\n",
       "            -1.41003781e-07,  -8.05552176e-08,  -1.20108709e-07,\n",
       "             4.64205137e-08,  -5.42637189e-08,   7.27588159e-08,\n",
       "            -1.47693697e-08,  -4.32707026e-08,  -1.37034508e-08,\n",
       "            -6.27354240e-08,  -3.80495813e-08,  -9.85987398e-08,\n",
       "            -2.92322540e-08,   1.25922357e-08,  -4.77358864e-09,\n",
       "            -6.05599411e-08,  -1.12049996e-07,   5.31201074e-08,\n",
       "             7.65610153e-08,  -9.55099377e-09,   1.53038584e-07,\n",
       "            -9.26509571e-08,   3.89057817e-08,   7.94526471e-08,\n",
       "            -1.90935037e-08,   3.32951338e-08,   1.10633103e-07,\n",
       "             1.68983092e-07,  -9.69720233e-08,  -2.87333846e-09,\n",
       "             1.34291724e-07,  -5.24267341e-09,   5.72994807e-09,\n",
       "             6.76184939e-08,   5.02238029e-09,  -4.15287822e-08,\n",
       "             9.25947106e-08,  -3.91587065e-08,  -1.06025810e-08,\n",
       "            -4.65692622e-08,  -7.17639370e-09,  -5.61616798e-09,\n",
       "             2.99662126e-08,  -5.73309311e-09,  -8.41104875e-09,\n",
       "             5.10679250e-08,   8.34764222e-08,   6.13148643e-08,\n",
       "            -5.64605749e-08,  -1.37505040e-07,   1.82006019e-08,\n",
       "            -1.38326754e-07,   9.28992776e-08,  -2.81152204e-08,\n",
       "             3.88310326e-08,  -1.30586415e-07,   3.43281279e-08,\n",
       "            -3.40433886e-08,   4.51898536e-08,   1.71125890e-07,\n",
       "            -3.41898208e-08,  -1.69229594e-07,  -1.57172551e-07,\n",
       "            -1.19949661e-07,  -1.47482766e-07,  -5.52972672e-08,\n",
       "            -1.52635913e-08,   1.83894056e-08,   5.38570122e-09,\n",
       "            -1.10074353e-07,  -4.19052455e-08,   2.23895054e-08,\n",
       "             8.72429506e-09,  -1.39263534e-07,   1.52561853e-07,\n",
       "            -5.06249798e-08,  -9.94140663e-08,   5.70546588e-09,\n",
       "            -4.35024958e-08,   1.60120273e-08,   2.11250129e-08,\n",
       "            -7.58247722e-08,  -9.34910389e-08,   5.53406778e-08,\n",
       "             5.34968549e-08,  -5.72032688e-09,  -1.18826435e-07,\n",
       "            -5.22428500e-08,  -3.81382250e-08,   7.26807237e-09,\n",
       "            -1.01248695e-07,   3.87431562e-08,  -1.05573534e-07,\n",
       "             1.26730370e-07,  -3.75996159e-08,   4.87265428e-09,\n",
       "             7.91988910e-08,  -2.25167980e-07,  -1.30997364e-07,\n",
       "            -3.21425766e-08,   6.51392114e-08,  -1.96529779e-08,\n",
       "            -6.11151521e-08,   1.06525398e-07,   2.37376199e-08,\n",
       "            -1.82157081e-08,  -3.68043835e-08,  -5.65849732e-08,\n",
       "            -3.25462288e-08,   1.85260642e-08,  -2.98043545e-09,\n",
       "            -2.33835529e-08,  -8.41958041e-08,   5.05053990e-08,\n",
       "             3.75084284e-08,   3.66999253e-09,   6.47079190e-08,\n",
       "            -8.41799075e-09,  -5.05181674e-08,  -6.13786924e-08,\n",
       "             1.81401774e-08,   5.81461741e-08,  -1.60267319e-08,\n",
       "            -2.85153572e-08,   1.83042879e-08,   1.27639680e-07,\n",
       "             3.87939707e-08,  -5.96828471e-08,   1.16030471e-07,\n",
       "             2.59066848e-08,  -7.40461203e-08,  -1.90642382e-08,\n",
       "             1.05444435e-07,  -2.11625242e-08,  -8.78446116e-08,\n",
       "             3.61107340e-08,  -3.62277390e-08,   8.15641314e-08,\n",
       "             2.97517992e-08,   4.92509713e-08,  -8.88690188e-09,\n",
       "             1.93352161e-08,   6.21663219e-08,   6.12887661e-08,\n",
       "            -7.47922400e-08,  -3.06548600e-08,   3.28140395e-08,\n",
       "            -7.20195317e-08,  -8.68322747e-09,   1.51959902e-08,\n",
       "             1.24197925e-07,  -1.44365472e-07,  -9.01285020e-08,\n",
       "            -1.10708470e-07,   7.06187180e-08,   1.69208747e-07,\n",
       "            -3.68432858e-08,   7.65578889e-08,   9.52009049e-09,\n",
       "             1.56377240e-08,  -1.77148905e-07,  -4.33428653e-08,\n",
       "             1.21982451e-08,  -7.12813275e-08,   7.31028660e-09,\n",
       "            -7.25009457e-08,  -9.96412695e-08,   1.40445607e-07,\n",
       "            -1.82820628e-07,   3.54740273e-08,   1.40763362e-07,\n",
       "            -8.79030679e-08,   1.65488629e-07,   1.08046876e-07,\n",
       "             7.42632977e-08,   4.02080147e-08,   6.19546157e-08,\n",
       "            -5.11874383e-08,  -1.14208703e-07,   4.36331931e-08,\n",
       "             1.83010030e-07,  -6.78669849e-08,  -1.30339028e-09,\n",
       "             1.00840587e-07,  -6.37064872e-08,   6.34012451e-08,\n",
       "            -8.31175626e-08,   2.54452779e-08,  -6.84954049e-09,\n",
       "            -8.87143230e-08,   1.18221905e-07,  -1.26882341e-07,\n",
       "             1.60653116e-07,  -1.35466784e-08,   1.08405033e-07,\n",
       "            -1.93747255e-07,  -5.61333593e-08,  -1.34174542e-07,\n",
       "             2.89934050e-08,   2.06086355e-07,   2.07857468e-07,\n",
       "            -3.32077086e-08,   1.57298743e-07,   2.34950718e-07,\n",
       "            -1.14943283e-07,   2.72516900e-07,  -5.66512846e-08],\n",
       "          [ -2.60022777e-08,   3.07556327e-08,  -1.35468355e-07,\n",
       "             1.42024206e-07,   4.37041194e-08,  -1.00777086e-07,\n",
       "             7.25800717e-08,  -1.30786670e-08,   4.10404226e-08,\n",
       "             7.43722381e-08,   1.30185512e-07,  -1.22521243e-07,\n",
       "            -1.09959380e-07,   5.41604557e-08,  -1.34915595e-07,\n",
       "            -1.09892440e-09,   4.43158257e-08,   6.28383390e-08,\n",
       "            -1.60175887e-07,   2.00829504e-08,  -9.70843885e-08,\n",
       "             3.79481229e-08,   9.78570753e-08,  -2.39867290e-08,\n",
       "             2.91906019e-08,  -7.07755063e-08,  -8.18071797e-08,\n",
       "            -5.73337964e-08,   2.06041506e-07,   1.31752413e-08,\n",
       "            -1.14459318e-07,  -1.60539017e-07,   1.28028034e-07,\n",
       "            -8.65912355e-08,   1.22867556e-08,  -4.00910380e-08,\n",
       "             9.77183401e-09,   1.56025578e-07,   8.04777400e-08,\n",
       "            -5.55336079e-08,  -9.97043017e-08,  -1.27515293e-07,\n",
       "            -7.20337141e-08,  -1.83344994e-07,  -3.54162943e-09,\n",
       "            -2.53428691e-08,  -1.04022099e-07,  -1.23129311e-07,\n",
       "            -3.61510750e-08,   1.34216194e-07,  -2.55532733e-08,\n",
       "             1.18150517e-07,  -1.36842544e-07,   1.33629683e-07,\n",
       "             9.00247557e-08,   1.15740811e-07,   1.02942641e-08,\n",
       "            -7.98198041e-09,  -1.32726852e-08,   2.38236666e-07,\n",
       "            -3.81612679e-08,   1.06589404e-07,   9.68468257e-08,\n",
       "             1.22509533e-07,  -1.02312017e-08,   3.47226106e-08,\n",
       "             1.69374545e-07,   1.04449953e-07,   9.56940269e-08,\n",
       "            -1.25251873e-07,   8.92669227e-09,   3.96855988e-08,\n",
       "            -7.13580590e-08,   3.59661136e-08,  -1.08488996e-08,\n",
       "            -2.22996533e-07,   9.17948313e-08,   1.15625646e-07,\n",
       "            -3.83620558e-09,  -7.10344210e-08,  -1.87754338e-07,\n",
       "             3.02410790e-08,  -8.75104718e-08,   5.36021751e-08,\n",
       "             1.60814736e-07,   3.31318297e-08,   2.16627825e-07,\n",
       "             7.63831807e-08,  -7.71694530e-09,  -1.53070616e-07,\n",
       "            -1.31737409e-07,   4.76826081e-08,   1.90065763e-09,\n",
       "            -1.95503404e-07,   1.46358605e-08,   2.06685069e-08,\n",
       "            -8.91668037e-08,  -1.49635748e-09,  -2.00235686e-08,\n",
       "            -5.76035086e-09,   5.47702470e-08,   1.54440194e-08,\n",
       "            -5.05693620e-08,   2.80978032e-08,  -9.34724724e-08,\n",
       "             4.06152942e-08,   2.10220321e-08,   8.99842760e-08,\n",
       "            -8.20084693e-08,  -6.75969147e-08,   7.13084134e-08,\n",
       "             9.09813167e-08,  -5.94556440e-08,   1.18885815e-07,\n",
       "            -8.71727295e-08,   1.02571349e-07,   1.28691568e-07,\n",
       "            -2.25821957e-08,   3.31641417e-08,   8.55278515e-08,\n",
       "             6.93733710e-08,  -9.38838269e-08,  -3.08606509e-08,\n",
       "             7.98038187e-08,   4.39927987e-08,   1.60798535e-07,\n",
       "            -5.12759568e-09,   8.83498785e-08,  -3.51638008e-08,\n",
       "             8.90874716e-08,  -3.63926844e-08,   8.32835170e-08,\n",
       "             3.49088980e-09,   5.14138208e-08,  -6.25217851e-08,\n",
       "             1.22497426e-07,   9.43201783e-08,  -8.86831728e-08,\n",
       "             1.02319461e-07,   2.21329145e-07,   4.98783770e-08,\n",
       "            -1.07534518e-07,  -1.56665863e-07,   8.48717576e-08,\n",
       "            -1.22219319e-07,   4.94684400e-08,  -5.18107370e-08,\n",
       "            -2.33714967e-08,  -6.74422225e-08,   1.17205303e-08,\n",
       "             7.84511087e-08,   6.70942342e-08,   1.34231314e-07,\n",
       "            -8.01147522e-08,  -2.56651219e-07,  -1.51528241e-07,\n",
       "            -1.50948139e-07,  -1.61252686e-07,  -1.45857570e-07,\n",
       "             9.48028216e-08,  -1.31086878e-07,  -1.90961913e-08,\n",
       "             8.56027516e-09,  -1.01550043e-07,   9.52459729e-08,\n",
       "             6.93700457e-08,  -1.82469918e-07,   2.14531397e-07,\n",
       "            -8.67520811e-08,   2.20832597e-08,  -1.89551148e-08,\n",
       "            -3.69604720e-08,   5.73484371e-09,  -1.45746082e-08,\n",
       "            -4.37451817e-08,  -1.65691233e-07,   7.25111207e-08,\n",
       "             1.74210442e-07,   5.40539951e-08,  -5.73302605e-09,\n",
       "            -5.05301188e-08,  -1.05979673e-07,  -4.23172750e-08,\n",
       "            -1.32863789e-07,  -4.35783569e-08,  -1.97618846e-07,\n",
       "             1.53261865e-07,   7.51851204e-08,   1.01774020e-08,\n",
       "             1.18797026e-07,  -3.46880626e-07,  -1.12319881e-07,\n",
       "            -4.01727647e-08,   4.21048902e-08,  -1.56973854e-07,\n",
       "            -1.00329531e-08,   7.29909928e-08,   8.64805738e-09,\n",
       "             7.50984341e-08,   5.07833633e-08,  -4.67974210e-08,\n",
       "            -1.34143434e-07,   7.15262232e-08,  -4.91424288e-08,\n",
       "            -4.07237835e-08,   2.63347868e-08,   9.29081673e-11,\n",
       "             1.83454375e-07,   3.89431776e-08,   2.55690455e-08,\n",
       "             1.36944067e-07,  -4.01627709e-08,  -7.95245896e-08,\n",
       "             5.51374022e-08,   4.88630434e-08,  -2.59000323e-08,\n",
       "             9.55463832e-08,   1.04300014e-07,   2.10774743e-07,\n",
       "             5.43175886e-08,  -1.47095790e-07,   9.36746076e-08,\n",
       "            -4.55672406e-08,  -6.31339674e-08,   9.10083120e-09,\n",
       "             6.09092794e-08,   1.44238035e-08,  -1.07174444e-07,\n",
       "             2.23480390e-09,  -8.81605544e-08,   1.14654277e-07,\n",
       "             5.78151678e-08,   1.46519854e-08,   1.64233185e-07,\n",
       "             5.32600950e-08,   6.47967013e-08,   6.96736535e-08,\n",
       "             2.82349042e-08,  -5.90489602e-10,  -2.10746531e-08,\n",
       "            -1.33883304e-07,   2.49450185e-08,  -5.38495026e-09,\n",
       "             1.35840921e-07,  -4.61436933e-08,   6.55969457e-09,\n",
       "             5.57897266e-08,  -8.39830534e-08,   1.56659638e-07,\n",
       "            -3.43896644e-08,   1.14210422e-07,   1.30112355e-07,\n",
       "             6.62385489e-08,  -2.03194560e-07,  -3.03250793e-08,\n",
       "            -7.61988339e-09,  -2.15323482e-07,  -1.97948613e-09,\n",
       "            -9.86597826e-08,  -6.15483842e-08,   1.32470646e-07,\n",
       "            -1.23985942e-07,  -9.49267260e-08,   1.14017872e-07,\n",
       "            -1.39819932e-07,   8.56771507e-08,   1.27520991e-07,\n",
       "             2.08838191e-08,   2.35868236e-09,   6.47182006e-08,\n",
       "            -1.04111500e-07,  -1.49544675e-07,   2.03650234e-08,\n",
       "             3.51360285e-07,  -3.78503735e-08,   8.09196479e-08,\n",
       "             2.96229175e-08,  -1.22791036e-07,   1.03774148e-07,\n",
       "            -1.83414798e-07,   1.10221194e-07,   2.63970499e-08,\n",
       "            -9.60767732e-09,  -7.67887727e-08,  -1.53144484e-07,\n",
       "             1.11199391e-07,  -1.00985908e-07,   2.89958049e-08,\n",
       "            -2.57061345e-07,  -3.62258135e-08,  -1.24830478e-07,\n",
       "             8.19904571e-08,   2.13917389e-07,   2.62911357e-07,\n",
       "            -7.69814505e-08,   2.03562067e-07,   2.22693629e-07,\n",
       "            -5.41900214e-08,   2.33121966e-07,  -1.20028654e-09]]]], dtype=float32),\n",
       " array([-13.24436951], dtype=float32),\n",
       " array([[ -6.60608197e-03],\n",
       "        [ -6.57985965e-03],\n",
       "        [ -1.42791818e-04],\n",
       "        [  4.95346129e-01],\n",
       "        [  4.80940223e-01],\n",
       "        [ -1.35114443e+00]], dtype=float32),\n",
       " array([ -1.13681011e-08], dtype=float32),\n",
       " array([[ 1.22410524],\n",
       "        [ 0.12684232],\n",
       "        [ 0.01912257],\n",
       "        ..., \n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]], dtype=float32),\n",
       " array([ 1.40768933], dtype=float32),\n",
       " array([[ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        ..., \n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]], dtype=float32),\n",
       " array([ -7.11175829e-09], dtype=float32),\n",
       " array([[ 0.98748505,  0.98745435,  0.98704004,  0.99997151,  0.9999404 ,\n",
       "          0.99952078],\n",
       "        [ 0.99999988,  0.99996889,  0.99954927, -0.06117745, -0.06117554,\n",
       "         -0.06114987],\n",
       "        [ 0.99999976,  0.99996871,  0.99954915,  0.03397742,  0.03397635,\n",
       "          0.0339621 ],\n",
       "        ..., \n",
       "        [ 0.99999988,  0.99967867,  0.9972598 ,  0.99998146,  0.99966019,\n",
       "          0.99724138],\n",
       "        [ 0.99999982,  0.99967843,  0.99725968,  0.99986005,  0.99953878,\n",
       "          0.99712038],\n",
       "        [ 0.99999982,  0.99967843,  0.99725968,  0.99246418,  0.9921453 ,\n",
       "          0.9897446 ]], dtype=float32),\n",
       " array([[  1.98000222e-01],\n",
       "        [  1.35050781e+02],\n",
       "        [  8.15525665e+01],\n",
       "        ..., \n",
       "        [  2.45000168e+02],\n",
       "        [  1.33831543e+02],\n",
       "        [  1.42430710e+02]], dtype=float32),\n",
       " array([[ 71.43159485],\n",
       "        [ 71.43159485],\n",
       "        [ 71.43159485],\n",
       "        ..., \n",
       "        [ 71.43159485],\n",
       "        [ 71.43159485],\n",
       "        [ 71.43159485]], dtype=float32),\n",
       " array([  1.42151022e+01,   9.64709961e+03,   5.82558301e+03, ...,\n",
       "          1.75010703e+04,   9.56000586e+03,   1.01742666e+04], dtype=float32),\n",
       " array([[ 0.98748505,  0.98745435,  0.98704004,  0.99997151,  0.9999404 ,\n",
       "          0.99952078],\n",
       "        [ 0.99999988,  0.99996889,  0.99954927, -0.06117745, -0.06117554,\n",
       "         -0.06114987],\n",
       "        [ 0.99999976,  0.99996871,  0.99954915,  0.03397742,  0.03397635,\n",
       "          0.0339621 ],\n",
       "        ..., \n",
       "        [ 0.99999988,  0.99967867,  0.9972598 ,  0.99998146,  0.99966019,\n",
       "          0.99724138],\n",
       "        [ 0.99999982,  0.99967843,  0.99725968,  0.99986005,  0.99953878,\n",
       "          0.99712038],\n",
       "        [ 0.99999982,  0.99967843,  0.99725968,  0.99246418,  0.9921453 ,\n",
       "          0.9897446 ]], dtype=float32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano.compile.nanguardmode import NanGuardMode\n",
    "\n",
    "\n",
    "def gg_test():\n",
    "    self = queries_exp\n",
    "    gg_f = theano.function(\n",
    "            self.func_inputs,\n",
    "            #self.func_outputs,\n",
    "           T.grad(self.loss_vec.mean(), self.all_params) + \n",
    "        [lasagne.layers.get_output(self.cosine_combined), self.target_out, self.source_aligned_l, T.batched_dot(self.target_out + .001, self.source_aligned_l + .001), lasagne.layers.get_output(self.cosine_combined)],\n",
    "            #updates=self.updates,\n",
    "            on_unused_input='ignore',\n",
    "            mode=NanGuardMode(nan_is_error=True, inf_is_error=True, big_is_error=False)\n",
    "    )\n",
    "    return gg_f(\n",
    "            self.current_documents,\n",
    "            self.current_surface_link, self.current_surface_context, self.current_link_id,\n",
    "            self.current_target_input, self.current_target_matches_surface, self.current_surface_target_counts, self.current_target_id, \n",
    "            self.current_target_words, self.current_target_body_words, #self.current_feat_indicators,\n",
    "            self.current_denotations_feats_indicators, self.current_queries, self.current_denotations_related_query, self.current_denotations_range,\n",
    "            self.current_denotation_targets_linked,\n",
    "            self.current_target_goal, self.current_learning_groups, self.current_boosted_groups,\n",
    "        )\n",
    "\n",
    "gg_res = gg_test()\n",
    "gg_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, (0.11484926603409955, 0.11484926603409955))\n",
      "(14507, 0.6353484524712207)\n",
      "(2786, 0.624551328068916)\n",
      "(1, (0.094122598006404823, 0.094122598006404823))\n",
      "(14507, 0.677190321913559)\n",
      "(2786, 0.6363962670495333)\n",
      "(2, (0.086904316827909167, 0.086904316827909167))\n",
      "(14507, 0.7031777762459502)\n",
      "(2786, 0.6446518305814788)\n",
      "(3, (0.083614086752157368, 0.083614086752157368))\n",
      "(14507, 0.7123457641138761)\n",
      "(2786, 0.6529073941134242)\n",
      "(4, (0.081057140368035657, 0.081057140368035657))\n",
      "(14507, 0.7174467498449024)\n",
      "(2786, 0.6608040201005025)\n",
      "(5, (0.079649350485318557, 0.079649350485318557))\n",
      "(14507, 0.7268215344316536)\n",
      "(2786, 0.6590093323761665)\n",
      "(6, (0.078404673863115143, 0.078404673863115143))\n",
      "(14507, 0.7305438753705108)\n",
      "(2786, 0.6536252692031587)\n",
      "(7, (0.077305001956545327, 0.077305001956545327))\n",
      "(14507, 0.734886606465844)\n",
      "(2786, 0.659727207465901)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-ad85bd80526d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mqueries_exp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_training_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_num_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries_exp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mexp_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-50f14d97467a>\u001b[0m in \u001b[0;36mcompute_batch\u001b[1;34m(self, isTraining, useTrainingFunc)\u001b[0m\n\u001b[0;32m    788\u001b[0m                         \u001b[1;31m# [queries][indicator id]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mindx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindicators_place\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m                             \u001b[0mlocal_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_indicator_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m                             \u001b[0mlocal_feats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindicators_place\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m                             \u001b[0mjoint_indicators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_feats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp_results = []\n",
    "\n",
    "true_num_samples = 500000 #queries_exp.num_training_items\n",
    "\n",
    "for i in xrange(10):\n",
    "    queries_exp.num_training_items = true_num_samples\n",
    "    res = (i, queries_exp.compute_batch())\n",
    "    print res\n",
    "    exp_results.append(res)\n",
    "    #if i % 2 == 1:\n",
    "    exp_results.append(('training state', evalCurrentState(True, queries_exp.num_training_items)))\n",
    "    queries_exp.num_training_items = 50000  # don't need that many samples to see how well it performs\n",
    "    exp_results.append(('testing run', queries_exp.compute_batch(False)))\n",
    "    exp_results.append(('testing state', evalCurrentState(False, queries_exp.num_training_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2786, 'Prec = 1205.0/1511 = 0.797485109199, Rec = 1205.0/1491 = 0.808182427901, F1 = 0.802798134577')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2786,\n",
       " 'Prec = 1205.0/1511 = 0.797485109199, Rec = 1205.0/1491 = 0.808182427901, F1 = 0.802798134577')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalCurrentStateF1(False, 50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
