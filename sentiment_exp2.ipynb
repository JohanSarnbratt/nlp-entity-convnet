{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from theano import *\n",
    "from lasagne.layers import EmbeddingLayer, InputLayer, get_output\n",
    "import lasagne\n",
    "import lasagne.layers\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wordvecs import WordVectors, EmbeddingLayer\n",
    "\n",
    "wordvectors = WordVectors(fname=\"../GoogleNews-vectors-negative300.bin\", negvectors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sentiment_sents import Sentiment\n",
    "\n",
    "# just load the sentences from the CNN system\n",
    "sentiment = Sentiment(\"prevwork/CNN_sentence/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordvectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for w in sentiment.test_X:\n",
    "    wordvectors.tokenize(w)\n",
    "for w in sentiment.train_X:\n",
    "    wordvectors.tokenize(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19077"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordvectors.word_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
      "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n",
      "/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
      "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n"
     ]
    }
   ],
   "source": [
    "class SentimentExp(object):\n",
    "    \n",
    "    def __init__(self, train_X, train_Y, wordvecs=wordvectors):\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y\n",
    "        self.wordvecs = wordvecs\n",
    "        \n",
    "        self.input_size = 10\n",
    "        self.batch_size = 10\n",
    "        \n",
    "        self.learning_rate = .01\n",
    "        self.momentum = .9\n",
    "        \n",
    "        #self.train_X_rep = np.array([[self.getRep(x)] for x in self.train_X])\n",
    "        self.train_X_rep = np.array([wordvecs.tokenize(x) for x in self.train_X])\n",
    "        \n",
    "        self._setup()\n",
    "\n",
    "    def getRep(self, sent):\n",
    "        ret = []\n",
    "        for i in xrange(self.input_size):\n",
    "            if i < len(sent):\n",
    "                ret.append(self.wordvecs[sent[i]])\n",
    "            else:\n",
    "                ret.append(np.zeros(self.wordvecs.vector_size))\n",
    "        return np.matrix(ret).reshape((1, self.input_size, self.wordvecs.vector_size))\n",
    "\n",
    "    def _setup(self):\n",
    "        self.x_batch = T.imatrix('x')\n",
    "        self.y_batch = T.ivector('y')\n",
    "        \n",
    "        self.input_l = lasagne.layers.InputLayer((self.batch_size, 50))\n",
    "        \n",
    "        self.embedding_l = EmbeddingLayer(self.input_l, W=self.wordvecs.get_numpy_matrix()) \n",
    "        \n",
    "        self.first_l = lasagne.layers.Conv2DLayer(\n",
    "            self.embedding_l,\n",
    "            num_filters=100,\n",
    "            filter_size=(2, self.wordvecs.vector_size),\n",
    "            name='conv1',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.first_l_max = lasagne.layers.MaxPool2DLayer(\n",
    "            self.first_l,\n",
    "            pool_size=(1,9)\n",
    "        )\n",
    "        \n",
    "        self.hidden1_l = lasagne.layers.DenseLayer(\n",
    "            self.first_l_max,\n",
    "            num_units=50,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.hidden1_l_drop = lasagne.layers.DropoutLayer(\n",
    "            self.hidden1_l,\n",
    "            p=.25,\n",
    "        )\n",
    "                \n",
    "        self.out_l = lasagne.layers.DenseLayer(\n",
    "            self.hidden1_l_drop,\n",
    "            num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.output = lasagne.layers.get_output(self.out_l, self.x_batch)\n",
    "        \n",
    "        self.loss_vec_old = (self.output.reshape((self.output.size,)) - self.y_batch) ** 2\n",
    "        self.output_diff = T.neq((self.output.flatten() > .5),(self.y_batch > .5)).sum()\n",
    "        self.loss_vec = lasagne.objectives.binary_crossentropy(T.clip(self.output.reshape((self.output.size,)), .01, .99), self.y_batch)\n",
    "        \n",
    "        self.all_params = lasagne.layers.get_all_params(self.out_l)\n",
    "        \n",
    "        self.updates = lasagne.updates.adagrad(self.loss_vec.mean(), self.all_params, .01)\n",
    "        #self.updates = lasagne.updates.apply_momentum(self.updates_adagrad)\n",
    "        \n",
    "        self.train_func = theano.function(\n",
    "            [self.x_batch, self.y_batch],\n",
    "            [self.loss_vec.mean(), self.loss_vec],\n",
    "            updates=self.updates,\n",
    "        )\n",
    "        \n",
    "        self.loss_func = theano.function(\n",
    "            [self.x_batch, self.y_batch],\n",
    "            [self.loss_vec.sum(), self.loss_vec, self.output_diff],\n",
    "        )\n",
    "        \n",
    "    def train(self):\n",
    "        for s in xrange(0, len(self.train_X_rep), self.batch_size):\n",
    "            X_vals = np.array(self.train_X_rep[s:(s + self.batch_size)]).astype('int32')\n",
    "            y_vals = np.array(self.train_Y[s:(s + self.batch_size)]).astype('int32')\n",
    "            loss, _ = self.train_func(X_vals, y_vals)\n",
    "            \n",
    "    def test_loss(self, test_X, test_Y):\n",
    "        test_X_rep = np.array([self.wordvecs.tokenize(x) for x in test_X])\n",
    "        loss_sum = 0.0\n",
    "        wrong = 0.0\n",
    "        for s in xrange(0, len(test_X_rep), self.batch_size):\n",
    "            X_vals = np.array(self.train_X_rep[s:(s + self.batch_size)]).astype('int32')\n",
    "            y_vals = np.array(self.train_Y[s:(s + self.batch_size)]).astype('int32')\n",
    "            loss, _, output_diff = self.loss_func(X_vals, y_vals)\n",
    "            wrong += output_diff\n",
    "            loss_sum += loss\n",
    "        return loss_sum / len(test_X_rep), wrong / len(test_X_rep)\n",
    "    \n",
    "experiment = SentimentExp(sentiment.train_X, sentiment.train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Embeddings, conv1.W, conv1.b, W, b, W, b]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3006071474328893, 0.49847596717467763)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.test_loss(sentiment.test_X, sentiment.test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(5):\n",
    "    experiment.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3006071474328893, 0.49847596717467763)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.test_loss(sentiment.train_X, sentiment.train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3006075460619382, 0.49847596717467763)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.test_loss(sentiment.test_X, sentiment.test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_func = theano.function(\n",
    "    [experiment.x_batch, experiment.y_batch],\n",
    "    [experiment.loss_vec.mean(), experiment.loss_vec, experiment.output, \n",
    "     T.grad(experiment.loss_vec.mean(), experiment.out_l.get_params()[0]),\n",
    "     experiment.out_l.get_params()[0], experiment.y_batch, \n",
    "     #lasagne.layers.get_output(experiment.first_l, experiment.x_batch)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Bad input argument to theano function with name \"<ipython-input-16-571e25a0f946>:5\"  at index 0(0-based)', 'TensorType(int32, matrix) cannot store a value of dtype int64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to int32, or 2) set \"allow_input_downcast=True\" when calling \"function\".', array([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,   7,  11,  12,\n         13,  14,  15,   7,  16,  17,  18,  19,  20,   7,  21,  10,  22,\n         23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [  7,  24,  25,  23,  23,  23,  26,  27,  28,  29,  30,  31,  32,\n         33,   7,  34,  35,  36,  10,  37,  38,  23,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 39,  40,  41,  42,  43,  44,  45,   7,  46,  14,  15,  47,  48,\n         49,  50,  51,  52,   7,  53,  54,  55,  56,  57,  58,  59,  60,\n         23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 61,  62,  63,  64,  57,  65,  66,  10,  67,  68,  56,  69,  33,\n          7,  70,  71,  23,  72,  73,   7,  74,  75,  35,   7,  76,  77,\n         78,  14,   7,  79,  25,  45,  80,  81,  23,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 32,  82,  18,  83,  14,  15,  84,   7,  85,  10,  86,  87,  88,\n         23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 89,  90,  91,  10,  92,  15,  93,  25,  94,  95,  96,  97,  98,\n         28,  57,  99, 100,  35,  57, 101,  88,  23,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [102, 103, 104, 105,  56,  57, 106, 107,  14, 108,  57, 109, 110,\n         23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [111,  52,  86, 112, 113,  10,   7, 114, 115,  10, 116, 117,  56,\n        118, 119,  35, 120, 121, 122, 120, 123,  23,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 35, 124,  56, 125, 126, 127,  32, 128,  57, 129, 130, 131,  10,\n        132, 133, 134, 135, 136,   7, 137,  23,  23,  23, 138,  56, 139,\n        140,  23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [141,  14, 142,  15, 143, 122, 144, 145,  14,   7,  16, 146, 147,\n        148, 149, 150, 151,   7, 110, 152, 153,   7, 154, 155,  15, 156,\n         56, 157, 158,  95, 159,   7,  24, 160, 161,  23,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0]]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5f597661048a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_X_rep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    532\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[0;32m    533\u001b[0m                             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[0;32m    128\u001b[0m                             \u001b[1;34m'\"function\".'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                             % (self, data.dtype, self.dtype))\n\u001b[1;32m--> 130\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                 elif (allow_downcast is None and\n\u001b[0;32m    132\u001b[0m                         \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Bad input argument to theano function with name \"<ipython-input-16-571e25a0f946>:5\"  at index 0(0-based)', 'TensorType(int32, matrix) cannot store a value of dtype int64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to int32, or 2) set \"allow_input_downcast=True\" when calling \"function\".', array([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,   7,  11,  12,\n         13,  14,  15,   7,  16,  17,  18,  19,  20,   7,  21,  10,  22,\n         23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [  7,  24,  25,  23,  23,  23,  26,  27,  28,  29,  30,  31,  32,\n         33,   7,  34,  35,  36,  10,  37,  38,  23,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 39,  40,  41,  42,  43,  44,  45,   7,  46,  14,  15,  47,  48,\n         49,  50,  51,  52,   7,  53,  54,  55,  56,  57,  58,  59,  60,\n         23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 61,  62,  63,  64,  57,  65,  66,  10,  67,  68,  56,  69,  33,\n          7,  70,  71,  23,  72,  73,   7,  74,  75,  35,   7,  76,  77,\n         78,  14,   7,  79,  25,  45,  80,  81,  23,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 32,  82,  18,  83,  14,  15,  84,   7,  85,  10,  86,  87,  88,\n         23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 89,  90,  91,  10,  92,  15,  93,  25,  94,  95,  96,  97,  98,\n         28,  57,  99, 100,  35,  57, 101,  88,  23,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [102, 103, 104, 105,  56,  57, 106, 107,  14, 108,  57, 109, 110,\n         23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [111,  52,  86, 112, 113,  10,   7, 114, 115,  10, 116, 117,  56,\n        118, 119,  35, 120, 121, 122, 120, 123,  23,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [ 35, 124,  56, 125, 126, 127,  32, 128,  57, 129, 130, 131,  10,\n        132, 133, 134, 135, 136,   7, 137,  23,  23,  23, 138,  56, 139,\n        140,  23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0],\n       [141,  14, 142,  15, 143, 122, 144, 145,  14,   7,  16, 146, 147,\n        148, 149, 150, 151,   7, 110, 152, 153,   7, 154, 155,  15, 156,\n         56, 157, 158,  95, 159,   7,  24, 160, 161,  23,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0]]))"
     ]
    }
   ],
   "source": [
    "test_func(np.array(experiment.train_X_rep[0:10]),np.array(experiment.train_Y[0:10]).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "range() integer end argument expected, got TensorVariable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-8b1e23fc6408>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgg_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgg_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgg_update\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mgg_k\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgg_k\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgg_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: range() integer end argument expected, got TensorVariable."
     ]
    }
   ],
   "source": [
    "gg_k = theano.shared(0.)\n",
    "gg_i = T.iscalar('x')\n",
    "\n",
    "gg_res, gg_update = theano.scan(lambda: {gg_k:(gg_k + 1)}, sequences=[range(gg_i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1 = T.matrix()\n",
    "f1 = theano.function([a1], [a1.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = np.array([[1,2,3,0,0],[4,5,6,7,0],[2,2,2,2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext wordvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
