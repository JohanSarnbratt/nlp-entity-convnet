{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import *\n",
    "from lasagne.layers import EmbeddingLayer, InputLayer, get_output\n",
    "import lasagne\n",
    "import lasagne.layers\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordvecs import WordVectors\n",
    "\n",
    "wordvectors = WordVectors(fname=\"/data/matthew/GoogleNews-vectors-negative300.bin\", negvectors=False)\n",
    "\n",
    "from sentiment_sents import Sentiment\n",
    "\n",
    "# just load the sentences from the CNN system\n",
    "sentiment = Sentiment(\"prevwork/CNN_sentence/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordvectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
      "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n",
      "/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
      "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n"
     ]
    }
   ],
   "source": [
    "class SentimentExp(object):\n",
    "    \n",
    "    def __init__(self, train_X, train_Y, wordvecs=wordvectors):\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y\n",
    "        self.wordvecs = wordvecs\n",
    "        \n",
    "        self.input_size = 10\n",
    "        self.batch_size = 10\n",
    "        \n",
    "        self.learning_rate = .01\n",
    "        self.momentum = .9\n",
    "        \n",
    "        self.train_X_rep = np.array([[self.getRep(x)] for x in self.train_X])\n",
    "        \n",
    "        self._setup()\n",
    "        \n",
    "    def getRep(self, sent):\n",
    "        ret = []\n",
    "        for i in xrange(self.input_size):\n",
    "            if i < len(sent):\n",
    "                ret.append(self.wordvecs[sent[i]])\n",
    "            else:\n",
    "                ret.append(np.zeros(self.wordvecs.vector_size))\n",
    "        return np.matrix(ret).reshape((1, self.input_size, self.wordvecs.vector_size))\n",
    "\n",
    "    def _setup(self):\n",
    "        self.x_batch = T.tensor4('x')\n",
    "        self.y_batch = T.ivector('y')\n",
    "        \n",
    "        self.input_l = lasagne.layers.InputLayer((self.batch_size, 1, self.input_size, self.wordvecs.vector_size))\n",
    "        \n",
    "        self.first_l = lasagne.layers.Conv2DLayer(\n",
    "            self.input_l,\n",
    "            num_filters=100,\n",
    "            filter_size=(2, self.wordvecs.vector_size),\n",
    "            name='conv1',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.first_l_max = lasagne.layers.MaxPool2DLayer(\n",
    "            self.first_l,\n",
    "            pool_size=(1,9)\n",
    "        )\n",
    "        \n",
    "        self.hidden1_l = lasagne.layers.DenseLayer(\n",
    "            self.first_l_max,\n",
    "            num_units=50,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.hidden1_l_drop = lasagne.layers.DropoutLayer(\n",
    "            self.hidden1_l,\n",
    "            p=.25,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.out_l = lasagne.layers.DenseLayer(\n",
    "            self.hidden1_l_drop,\n",
    "            num_units=1,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.output = lasagne.layers.get_output(self.out_l, self.x_batch)\n",
    "        \n",
    "        self.loss_vec_old = (self.output.reshape((self.output.size,)) - self.y_batch) ** 2\n",
    "        self.output_diff = T.neq((self.output.flatten() > .5),(self.y_batch > .5)).sum()\n",
    "        self.loss_vec = lasagne.objectives.binary_crossentropy(T.clip(self.output.reshape((self.output.size,)), .01, .99), self.y_batch)\n",
    "        \n",
    "        self.all_params = lasagne.layers.get_all_params(self.out_l)\n",
    "        \n",
    "        self.updates = lasagne.updates.adagrad(self.loss_vec.mean(), self.all_params, .01)\n",
    "        #self.updates = lasagne.updates.apply_momentum(self.updates_adagrad)\n",
    "        \n",
    "        self.train_func = theano.function(\n",
    "            [self.x_batch, self.y_batch],\n",
    "            [self.loss_vec.mean(), self.loss_vec],\n",
    "            updates=self.updates,\n",
    "        )\n",
    "        \n",
    "        self.loss_func = theano.function(\n",
    "            [self.x_batch, self.y_batch],\n",
    "            [self.loss_vec.sum(), self.loss_vec, self.output_diff],\n",
    "        )\n",
    "        \n",
    "    def train(self):\n",
    "        for s in xrange(0, len(self.train_X_rep), self.batch_size):\n",
    "            X_vals = np.array(self.train_X_rep[s:(s + self.batch_size)])\n",
    "            y_vals = np.array(self.train_Y[s:(s + self.batch_size)]).astype('int32')\n",
    "            loss, _ = self.train_func(X_vals, y_vals)\n",
    "            \n",
    "    def test_loss(self, test_X, test_Y):\n",
    "        test_X_rep = np.array([[self.getRep(x)] for x in test_X])\n",
    "        loss_sum = 0.0\n",
    "        wrong = 0.0\n",
    "        for s in xrange(0, len(test_X_rep), self.batch_size):\n",
    "            X_vals = np.array(self.train_X_rep[s:(s + self.batch_size)])\n",
    "            y_vals = np.array(self.train_Y[s:(s + self.batch_size)]).astype('int32')\n",
    "            loss, _, output_diff = self.loss_func(X_vals, y_vals)\n",
    "            wrong += output_diff\n",
    "            loss_sum += loss\n",
    "        return loss_sum / len(test_X_rep), wrong / len(test_X_rep)\n",
    "    \n",
    "experiment = SentimentExp(sentiment.train_X, sentiment.train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.96447922654103, 0.49976553341148888)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.test_loss(sentiment.test_X, sentiment.test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(30):\n",
    "    experiment.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.66851129851808089, 0.4112543962485346)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.test_loss(sentiment.train_X, sentiment.train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.67122119794100388, 0.41652989449003519)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.test_loss(sentiment.test_X, sentiment.test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.66388316478248988, 0.40633059788980069) (0.66474253603649258, 0.40808909730363424)\n",
      "(0.66274806755047166, 0.40574443141852284) (0.66225249328675462, 0.40515826494724499)\n",
      "(0.65785578142608914, 0.40082063305978899) (0.65884283285573486, 0.40175849941383351)\n",
      "(0.65727619583062391, 0.39882766705744432) (0.65849965178438508, 0.40410316529894491)\n",
      "(0.65296838451322214, 0.39179366940211019) (0.65437862553757198, 0.39859320046893315)\n",
      "(0.65016349795351103, 0.38980070339976552) (0.65284976424894681, 0.39495896834701055)\n",
      "(0.64628572937323314, 0.38604923798358731) (0.64672449388498576, 0.3853458382180539)\n",
      "(0.63919562783281514, 0.37151230949589681) (0.64194379848230554, 0.38089097303634234)\n",
      "(0.63297061203097715, 0.36576787807737399) (0.63310950977570113, 0.37116060961313013)\n",
      "(0.6299980158280104, 0.35650644783118407) (0.62551188427002935, 0.35885111371629541)\n",
      "(0.61672973409990395, 0.34947245017584994) (0.61590539488710672, 0.3459554513481829)\n",
      "(0.60679452054998229, 0.34161781946072683) (0.61103623039469013, 0.33821805392731535)\n",
      "(0.59660725899106803, 0.32391559202813597) (0.59628080584262444, 0.32356389214536929)\n",
      "(0.58169407914910631, 0.31301289566236812) (0.58792895100667064, 0.31735052754982412)\n",
      "(0.57700727216741432, 0.30386869871043376) (0.5769293446421746, 0.30480656506447829)\n",
      "(0.57260304953424912, 0.29988276670574443) (0.57365541794405484, 0.30527549824150058)\n",
      "(0.5585591151761895, 0.29331770222743259) (0.5650629086794704, 0.29648300117233295)\n",
      "(0.55174277843777086, 0.28698710433763186) (0.55299433909840634, 0.28429073856975379)\n",
      "(0.54720429088621714, 0.27960140679953105) (0.55002852603220698, 0.28769050410316532)\n",
      "(0.53681216116669939, 0.27690504103165298) (0.53798876086692804, 0.27409144196951934)\n",
      "(0.53596808824937325, 0.27010550996483002) (0.53629584467503821, 0.27702227432590854)\n",
      "(0.53154022408988399, 0.26940211019929661) (0.51964157948574763, 0.26236811254396247)\n",
      "(0.52592182173874202, 0.26318874560375144) (0.51875484460139265, 0.25381008206330596)\n",
      "(0.51214053698877449, 0.26025791324736225) (0.51134491687676997, 0.25756154747948418)\n",
      "(0.49924340637691383, 0.24443141852286049) (0.50191962061138773, 0.24912075029308323)\n",
      "(0.50115070538633466, 0.24982415005861663) (0.5004687205517927, 0.25041031652989448)\n",
      "(0.49119775887605904, 0.24407971864009378) (0.49497148840858307, 0.24314185228604923)\n",
      "(0.49116007761376662, 0.24279015240328253) (0.4831572975391682, 0.23493552168815943)\n",
      "(0.48087973547264679, 0.23364595545134817) (0.47688455341735397, 0.22473622508792498)\n",
      "(0.47731734168504741, 0.23364595545134817) (0.47616560857753637, 0.2328253223915592)\n"
     ]
    }
   ],
   "source": [
    "for a in xrange(30):\n",
    "    for i in xrange(30):\n",
    "        experiment.train()\n",
    "    print experiment.test_loss(sentiment.train_X, sentiment.train_Y), experiment.test_loss(sentiment.test_X, sentiment.test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.38952828786908505, 0.17667057444314185) (0.39206873468067305, 0.17866354044548652)\n",
      "(0.38043483175432624, 0.170926143024619) (0.38512070176808499, 0.17878077373974208)\n",
      "(0.38610296200502925, 0.17678780773739741) (0.39308066984619927, 0.18030480656506448)\n",
      "(0.39554778139391478, 0.17456037514654163) (0.38243363466646668, 0.17631887456037515)\n",
      "(0.386200265016311, 0.18089097303634233) (0.3857410003310367, 0.18030480656506448)\n",
      "(0.37595950630907993, 0.17139507620164127) (0.38190551848933874, 0.17209847596717467)\n",
      "(0.38000809741969149, 0.17069167643610786) (0.38623100050767972, 0.17936694021101993)\n",
      "(0.38585288481447888, 0.17139507620164127) (0.37866630664976825, 0.16682297772567409)\n",
      "(0.38320463002406918, 0.17491207502930833) (0.38471597699086041, 0.17549824150058616)\n",
      "(0.38115490652845974, 0.17409144196951934) (0.37929606335055688, 0.17456037514654163)\n",
      "(0.37938493620545888, 0.17139507620164127) (0.37956517720338717, 0.17502930832356389)\n",
      "(0.37197219163554751, 0.17116060961313012) (0.37993588585742971, 0.16834701055099649)\n",
      "(0.37932276997526448, 0.17033997655334115) (0.38328382362406438, 0.17198124267291912)\n",
      "(0.37279306333115753, 0.16400937866354046) (0.37928553515851327, 0.16834701055099649)\n",
      "(0.36473338025874591, 0.15955451348182884) (0.37576997011198315, 0.16987104337631886)\n",
      "(0.374768704791618, 0.16576787807737398) (0.361024094153437, 0.15920281359906213)\n",
      "(0.37046581606147455, 0.17338804220398593) (0.37197664022776161, 0.17139507620164127)\n",
      "(0.36583669805379748, 0.16342321219226261) (0.36691744248803149, 0.1675263774912075)\n",
      "(0.37399492748284757, 0.16916764361078546) (0.36459622804204872, 0.16365767878077375)\n",
      "(0.37136913068739696, 0.16623681125439624) (0.37236127832183885, 0.16776084407971864)\n",
      "(0.36882758192679332, 0.16588511137162953) (0.36473400840711218, 0.16354044548651817)\n",
      "(0.35927534839114939, 0.1675263774912075) (0.35757145153766234, 0.16131301289566236)\n",
      "(0.35615796554883761, 0.16131301289566236) (0.35917428703424908, 0.15732708089097303)\n",
      "(0.36438340498383415, 0.16518171160609613) (0.36758306691723308, 0.16436107854630716)\n",
      "(0.3593172721273018, 0.16014067995310668) (0.36324560220076524, 0.16049237983587339)\n",
      "(0.3628486631667262, 0.16565064478311842) (0.35776886677740616, 0.16213364595545135)\n",
      "(0.36223991511864495, 0.16424384525205157) (0.35812471338847901, 0.16107854630715124)\n",
      "(0.36714638241590514, 0.15990621336459554) (0.35889921402420433, 0.16365767878077375)\n",
      "(0.35190792035352991, 0.15732708089097303) (0.34940117944576421, 0.15767878077373973)\n",
      "(0.35571531231472675, 0.1533411488862837) (0.34946445787450925, 0.15615474794841736)\n"
     ]
    }
   ],
   "source": [
    "for a in xrange(30):\n",
    "    for i in xrange(30):\n",
    "        experiment.train()\n",
    "    print experiment.test_loss(sentiment.train_X, sentiment.train_Y), experiment.test_loss(sentiment.test_X, sentiment.test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_func = theano.function(\n",
    "    [experiment.x_batch, experiment.y_batch],\n",
    "    [experiment.loss_vec.mean(), experiment.loss_vec, experiment.output, \n",
    "     T.grad(experiment.loss_vec.mean(), experiment.out_l.get_params()[0]),\n",
    "     experiment.out_l.get_params()[0], experiment.y_batch, \n",
    "     #lasagne.layers.get_output(experiment.first_l, experiment.x_batch)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.4591309667630588),\n",
       " array([ 0.07750704,  0.61353829,  0.05907035,  0.97992656,  0.34614112,\n",
       "         0.01005034,  0.49995063,  0.0756924 ,  0.48670261,  1.44273033]),\n",
       " array([[ 0.92542051],\n",
       "        [ 0.54143173],\n",
       "        [ 0.05735955],\n",
       "        [ 0.62466134],\n",
       "        [ 0.70741265],\n",
       "        [-0.29911896],\n",
       "        [ 0.6065606 ],\n",
       "        [ 0.92710133],\n",
       "        [ 0.6146498 ],\n",
       "        [ 0.76371825]]),\n",
       " array([[ -8.66662033e-02],\n",
       "        [ -3.51529348e-01],\n",
       "        [  3.11204463e-01],\n",
       "        [  2.20292754e-01],\n",
       "        [  1.03859721e-01],\n",
       "        [  3.85837135e-01],\n",
       "        [ -1.68557975e-01],\n",
       "        [ -2.24012511e-01],\n",
       "        [ -4.20686046e-01],\n",
       "        [  5.02028522e-02],\n",
       "        [  8.16099461e-02],\n",
       "        [  5.05576201e-02],\n",
       "        [ -2.11320017e-01],\n",
       "        [ -1.07135243e-01],\n",
       "        [  1.08823628e-01],\n",
       "        [ -1.11018641e-01],\n",
       "        [ -5.49380369e-01],\n",
       "        [ -8.30568215e-02],\n",
       "        [ -2.37320920e-01],\n",
       "        [ -1.28241658e-02],\n",
       "        [  8.92973157e-02],\n",
       "        [ -2.01489694e-01],\n",
       "        [ -5.39330161e-01],\n",
       "        [ -2.46992398e-01],\n",
       "        [  7.73569697e-02],\n",
       "        [  2.17157638e-01],\n",
       "        [  3.18385379e-02],\n",
       "        [ -2.03380271e-01],\n",
       "        [ -2.63378994e-01],\n",
       "        [  4.81100016e-04],\n",
       "        [  1.90012907e-01],\n",
       "        [ -1.73531639e-01],\n",
       "        [ -3.57476533e-01],\n",
       "        [ -3.05286536e-01],\n",
       "        [ -5.63581321e-01],\n",
       "        [ -2.62660499e-01],\n",
       "        [  3.11580358e-01],\n",
       "        [ -6.27102289e-02],\n",
       "        [ -3.69504740e-01],\n",
       "        [  1.87169550e-03],\n",
       "        [  3.28881283e-01],\n",
       "        [  1.73237317e-01],\n",
       "        [ -1.55942142e-01],\n",
       "        [  1.07408753e-01],\n",
       "        [ -8.26490089e-02],\n",
       "        [ -4.15462965e-02],\n",
       "        [  5.58701805e-02],\n",
       "        [  5.49561384e-01],\n",
       "        [  1.83516435e-01],\n",
       "        [ -8.30040959e-02]]),\n",
       " array([[ 0.11078803],\n",
       "        [ 0.09731101],\n",
       "        [ 0.10079306],\n",
       "        [ 0.10993766],\n",
       "        [ 0.1139378 ],\n",
       "        [ 0.102575  ],\n",
       "        [-0.10975344],\n",
       "        [-0.09982865],\n",
       "        [ 0.11252204],\n",
       "        [ 0.10309119],\n",
       "        [-0.10100046],\n",
       "        [ 0.11177922],\n",
       "        [-0.09973821],\n",
       "        [ 0.10363347],\n",
       "        [ 0.11987002],\n",
       "        [ 0.10470406],\n",
       "        [ 0.11262093],\n",
       "        [-0.2081502 ],\n",
       "        [ 0.10383914],\n",
       "        [-0.10358969],\n",
       "        [ 0.11232121],\n",
       "        [ 0.10221356],\n",
       "        [-0.11622611],\n",
       "        [-0.11532118],\n",
       "        [-0.10786137],\n",
       "        [-0.10132451],\n",
       "        [-0.11913478],\n",
       "        [-0.09035811],\n",
       "        [-0.10596459],\n",
       "        [ 0.10152603],\n",
       "        [ 0.09995089],\n",
       "        [-0.1075264 ],\n",
       "        [-0.10330048],\n",
       "        [-0.11342651],\n",
       "        [ 0.09508929],\n",
       "        [ 0.12229226],\n",
       "        [-0.09037376],\n",
       "        [ 0.10604586],\n",
       "        [ 0.10453735],\n",
       "        [-0.09494554],\n",
       "        [-0.09470193],\n",
       "        [ 0.10105437],\n",
       "        [ 0.09787124],\n",
       "        [-0.11717462],\n",
       "        [ 0.11689001],\n",
       "        [-0.19198862],\n",
       "        [-0.09553433],\n",
       "        [-0.10920013],\n",
       "        [ 0.10024423],\n",
       "        [-0.12116054]]),\n",
       " array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0], dtype=int32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_func(np.array(experiment.train_X_rep[0:10]),np.array(experiment.train_Y[0:10]).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
