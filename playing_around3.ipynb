{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from theano import *\n",
    "from lasagne.layers import EmbeddingLayer, InputLayer, get_output\n",
    "import lasagne\n",
    "import lasagne.layers\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_in = lasagne.layers.InputLayer((10,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
      "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n"
     ]
    }
   ],
   "source": [
    "l_output = lasagne.layers.DenseLayer(l_in, num_units=2, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
      "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n"
     ]
    }
   ],
   "source": [
    "out = lasagne.layers.get_output(l_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{mul,no_inplace}.0\n"
     ]
    }
   ],
   "source": [
    "print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = theano.function([l_in.input_var], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_v = (np.random.randint(0,2,10)).astype('int32')\n",
    "target_t = np.random.randn(10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,), (10, 50))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_v.shape, target_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.61084658,  0.46393442],\n",
       "       [ 1.45270656,  0.        ],\n",
       "       [ 0.        ,  1.72213931],\n",
       "       [ 0.        ,  1.79623763],\n",
       "       [ 0.33651443,  1.30487711],\n",
       "       [ 0.        ,  0.17773661],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.34447744,  0.53940711],\n",
       "       [ 0.13516176,  1.30733922],\n",
       "       [ 0.        ,  0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(target_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_params = lasagne.layers.get_all_params(l_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.function([l_in.input_var], (out, T.argmax(out, axis=1)))(target_t)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_value = T.ivector('y')\n",
    "out_values = T.argmax(out, axis=1)\n",
    "#loss = (y_value - out_values) ** 2\n",
    "#loss_old = (y_value - ) ** 2\n",
    "loss = theano.tensor.nnet.binary_crossentropy(out_values + 1, y_value + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was some issue with the shape of the ouput vector being [10,1] and the shape of the Y values being [10]\n",
    "\n",
    "this hack above is computing the loss by transforming the output vector into a single dimentional item, and then we compute the difference between these two terms and square it\n",
    "\n",
    "maybe simply taking the transpose of the y_value matrix can make these two values compatiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update = lasagne.updates.nesterov_momentum(loss.mean(), all_params, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = theano.function([l_in.input_var, y_value], (out_values, y_value, loss, loss.mean(), update.values()[0]), updates=update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(output.W, Elemwise{add,no_inplace}.0), (output.b, Elemwise{add,no_inplace}.0), (<TensorType(float64, matrix)>, Elemwise{sub,no_inplace}.0), (<TensorType(float64, vector)>, Elemwise{sub,no_inplace}.0)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(1000):\n",
    "    _,_,_,loss_v,_= train(target_t, target_v)\n",
    "print loss_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 1, 1, 1, 1, 0, 1, 1, 0]),\n",
       " array([0, 1, 0, 1, 0, 1, 1, 1, 0, 1], dtype=int32),\n",
       " array([ nan, -inf,  nan,  nan,  nan,  nan, -inf,  nan,  nan, -inf]),\n",
       " array(nan),\n",
       " array([[ 0.04335611,  0.05118995],\n",
       "        [-0.01719553, -0.118362  ],\n",
       "        [-0.20536817,  0.07178673],\n",
       "        [-0.07122489,  0.2425208 ],\n",
       "        [-0.29429854, -0.04354277],\n",
       "        [ 0.17944093,  0.08944575],\n",
       "        [ 0.30838578,  0.04708556],\n",
       "        [ 0.0038523 , -0.22174831],\n",
       "        [-0.13206892, -0.03355977],\n",
       "        [ 0.23500965, -0.06633459],\n",
       "        [-0.27021436, -0.07395862],\n",
       "        [ 0.23376679,  0.24184481],\n",
       "        [ 0.09989518,  0.29724972],\n",
       "        [ 0.32914167, -0.12673656],\n",
       "        [-0.32831812,  0.17769959],\n",
       "        [ 0.14105618,  0.25718294],\n",
       "        [ 0.1966741 , -0.26075592],\n",
       "        [-0.14865006,  0.19150122],\n",
       "        [ 0.31101563,  0.17198993],\n",
       "        [-0.18876439, -0.08521521],\n",
       "        [ 0.11649479,  0.27220297],\n",
       "        [-0.15419455, -0.23373412],\n",
       "        [ 0.00988218,  0.04538651],\n",
       "        [ 0.12699532, -0.18325539],\n",
       "        [-0.32409988,  0.06090342],\n",
       "        [ 0.03665805,  0.09640281],\n",
       "        [-0.22748491, -0.17409015],\n",
       "        [ 0.25630842, -0.03367399],\n",
       "        [-0.27517033,  0.00332108],\n",
       "        [-0.17579756, -0.1130089 ],\n",
       "        [ 0.15023077, -0.15406822],\n",
       "        [-0.01932641,  0.11935574],\n",
       "        [-0.31897852, -0.10858847],\n",
       "        [-0.28382017,  0.315973  ],\n",
       "        [ 0.04287222, -0.15738275],\n",
       "        [ 0.00043068, -0.04973478],\n",
       "        [-0.08203783,  0.1960445 ],\n",
       "        [ 0.04344186, -0.05924052],\n",
       "        [-0.07717485, -0.28424044],\n",
       "        [-0.19695935,  0.26506121],\n",
       "        [-0.28891229,  0.11776912],\n",
       "        [ 0.29129616, -0.32486969],\n",
       "        [-0.33816893,  0.31252832],\n",
       "        [ 0.29102669, -0.07548632],\n",
       "        [ 0.12601884, -0.12938807],\n",
       "        [ 0.11145728, -0.02240625],\n",
       "        [-0.15062025,  0.15104976],\n",
       "        [ 0.28286586,  0.33257968],\n",
       "        [ 0.05387987, -0.25685315],\n",
       "        [-0.08232233,  0.11497022]])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(target_t, target_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.61084658,  0.46393442],\n",
       "        [ 1.45270656,  0.        ],\n",
       "        [ 0.        ,  1.72213931],\n",
       "        [ 0.        ,  1.79623763],\n",
       "        [ 0.33651443,  1.30487711],\n",
       "        [ 0.        ,  0.17773661],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.34447744,  0.53940711],\n",
       "        [ 0.13516176,  1.30733922],\n",
       "        [ 0.        ,  0.        ]]),\n",
       " array([0, 1, 0, 1, 0, 1, 1, 1, 0, 1], dtype=int32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(target_t), target_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
