{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from theano import *\n",
    "from lasagne.layers import InputLayer, get_output\n",
    "import lasagne\n",
    "import lasagne.layers\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "from helpers import SimpleMaxingLayer\n",
    "from wordvecs import WordVectors, EmbeddingLayer\n",
    "import json\n",
    "\n",
    "theano.config.floatX = 'float32'\n",
    "theano.config.linker = 'cvm_nogc'\n",
    "theano.config.openmp = True\n",
    "theano.config.openmp_elemwise_minsize = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/matthew/external-wiki1.json') as f:\n",
    "    queries = json.load(f)['queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9915"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8917"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([any([g['gold'] for g in v.values()]) for v in queries.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8993444276348966"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8917/9915."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "wordvectors = WordVectors(\n",
    "    fname=\"/data/matthew/GoogleNews-vectors-negative300.bin\",\n",
    "    negvectors=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/matthew/enwiki-20141208-pages-articles-multistream-redirects5.json') as f:\n",
    "    page_redirects = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wikireader import WikiRegexes, WikipediaReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PreProcessedQueries(wikipedia_dump_fname, wordvec=wordvectors, queries=queries, redirects=page_redirects):\n",
    "    \n",
    "    queried_pages = set()\n",
    "    for docs, q in queries.iteritems():\n",
    "        wordvec.tokenize(docs)\n",
    "        for sur, v in q.iteritems():\n",
    "            wordvec.tokenize(sur)\n",
    "            for link in v['vals'].keys():\n",
    "                wordvec.tokenize(link)\n",
    "                tt = WikiRegexes.convertToTitle(link)\n",
    "                #self.wordvecs.tokenize(tt)\n",
    "                queried_pages.add(tt)\n",
    "\n",
    "    added_pages = set()\n",
    "    for title in queried_pages:\n",
    "        if title in redirects:\n",
    "            #wordvec.tokenize(self.redirects[title])\n",
    "            added_pages.add(redirects[title])\n",
    "    queried_pages |= added_pages\n",
    "\n",
    "    page_content = {}\n",
    "\n",
    "    class GetWikipediaWords(WikipediaReader, WikiRegexes):\n",
    "\n",
    "        def readPage(ss, title, content):\n",
    "            tt = ss.convertToTitle(title)\n",
    "            if tt in queried_pages:\n",
    "                cnt = ss._wikiToText(content)\n",
    "                page_content[tt] = wordvec.tokenize(cnt)\n",
    "\n",
    "    GetWikipediaWords(wikipedia_dump_fname).read()\n",
    "    \n",
    "    rr = redirects\n",
    "    rq = queried_pages\n",
    "    rc = page_content\n",
    "\n",
    "    class PreProcessedQueriesCls(object):\n",
    "        \n",
    "        wordvecs = wordvec\n",
    "        queries = queries\n",
    "        redirects = rr\n",
    "        queried_pages = rq\n",
    "        page_content = rc\n",
    "        \n",
    "        \n",
    "    return PreProcessedQueriesCls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basePreProcessedQueries = PreProcessedQueries('/data/matthew/enwiki-20141208-pages-articles-multistream.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/.virtualenvs/nlp-convnet/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:135: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "class EntityVectorLinkExp(basePreProcessedQueries):\n",
    "    \n",
    "    batch_size = 20000\n",
    "    \n",
    "    def __init__(self): #, wikipedia_dump_fname, wordvec=wordvectors, queries=queries, redirects=page_redirects):\n",
    "        #self.wordvecs = wordvec\n",
    "        #self.queries = queries\n",
    "        self.sentence_length = self.wordvecs.sentence_length\n",
    "        self.num_words_to_use_conv = 3\n",
    "        #self.redirects = redirects\n",
    "        #self.page_content = {}\n",
    "        #self.wikipedia_dump_fname = wikipedia_dump_fname\n",
    "        \n",
    "        #self._process_queries()\n",
    "        \n",
    "        self._setup()\n",
    "        \n",
    "#     def _process_queries(self):\n",
    "#         queried_pages = set()\n",
    "#         for docs, q in self.queries.iteritems():\n",
    "#             self.wordvecs.tokenize(docs)\n",
    "#             for sur, v in q.iteritems():\n",
    "#                 self.wordvecs.tokenize(sur)\n",
    "#                 for link in v['vals'].keys():\n",
    "#                     self.wordvecs.tokenize(link)\n",
    "#                     tt = WikiRegexes.convertToTitle(link)\n",
    "#                     #self.wordvecs.tokenize(tt)\n",
    "#                     queried_pages.add(tt)\n",
    "\n",
    "#         added_pages = set()\n",
    "#         for title in queried_pages:\n",
    "#             if title in self.redirects:\n",
    "#                 #self.wordvecs.tokenize(self.redirects[title])\n",
    "#                 added_pages.add(self.redirects[title])\n",
    "#         queried_pages |= added_pages\n",
    "        \n",
    "#         self.queried_pages = queried_pages\n",
    "                \n",
    "#         class GetWikipediaWords(WikipediaReader, WikiRegexes):\n",
    "            \n",
    "#             def readPage(ss, title, content):\n",
    "#                 tt = ss.convertToTitle(title)\n",
    "#                 if tt in queried_pages:\n",
    "#                     cnt = ss._wikiToText(content)\n",
    "#                     self.page_content[tt] = self.wordvecs.tokenize(cnt)\n",
    "        \n",
    "#         GetWikipediaWords(self.wikipedia_dump_fname).read()\n",
    "               \n",
    "        \n",
    "    def _setup(self):\n",
    "        self.x_document_input = T.imatrix('x_sent')\n",
    "        self.x_surface_text_input = T.imatrix('x_surface')\n",
    "        self.x_target_input = T.imatrix('x_target')\n",
    "        self.x_document_id = T.ivector('x_sent_id')\n",
    "        self.x_link_id = T.ivector('x_link_id')\n",
    "        self.y_score = T.vector('y')\n",
    "        \n",
    "        self.embedding_W = theano.shared(self.wordvecs.get_numpy_matrix().astype(theano.config.floatX))\n",
    "        \n",
    "        self.document_l = lasagne.layers.InputLayer(\n",
    "            (None,self.sentence_length), \n",
    "            input_var=self.x_document_input\n",
    "        )\n",
    "    \n",
    "        self.document_embedding_l = EmbeddingLayer(\n",
    "            self.document_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=False,\n",
    "        )\n",
    "        \n",
    "        self.document_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.document_embedding_l,\n",
    "            num_filters=350,\n",
    "            filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "            name='document_conv1',\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        )\n",
    "        \n",
    "        self.document_max_l = lasagne.layers.Pool2DLayer(\n",
    "            self.document_conv1_l,\n",
    "            name='document_pool1',\n",
    "            pool_size=(self.sentence_length - self.num_words_to_use_conv, 1),\n",
    "            mode='max',\n",
    "        )\n",
    "\n",
    "        self.document_dens1 = lasagne.layers.DenseLayer(\n",
    "            self.document_max_l,\n",
    "            num_units=300,\n",
    "            name='doucment_dens1',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.document_drop1 = lasagne.layers.DropoutLayer(\n",
    "            self.document_dens1,\n",
    "            p=.25,\n",
    "        )\n",
    "        \n",
    "        document_output_length = 250\n",
    "        \n",
    "        self.document_dens2 = lasagne.layers.DenseLayer(\n",
    "            self.document_drop1,\n",
    "            num_units=document_output_length,\n",
    "            name='document_dens2',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.document_output = lasagne.layers.get_output(self.document_dens2)\n",
    "                \n",
    "        self.surface_input_l = lasagne.layers.InputLayer(\n",
    "            (None, self.sentence_length), \n",
    "            input_var=self.x_surface_text_input\n",
    "        )\n",
    "        \n",
    "        self.surface_embedding_l = EmbeddingLayer(\n",
    "            self.surface_input_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=False,\n",
    "        )\n",
    "        \n",
    "        self.surface_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.surface_embedding_l,\n",
    "            num_filters=350,\n",
    "            filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "            name='surface_conv1',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.surface_dens1 = lasagne.layers.DenseLayer(\n",
    "            self.surface_conv1_l,\n",
    "            name='surface_dens1',\n",
    "            num_units=300,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.surface_drop1 = lasagne.layers.DropoutLayer(\n",
    "            self.surface_dens1,\n",
    "            p=.25,\n",
    "        )\n",
    "        \n",
    "        self.surface_dens2 = lasagne.layers.DenseLayer(\n",
    "            self.surface_drop1,\n",
    "            name='surface_dens2',\n",
    "            num_units=250,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.document_aligned_l = InputLayer(\n",
    "            (None, document_output_length),\n",
    "            input_var=self.document_output[self.x_document_id,:]\n",
    "        )\n",
    "        \n",
    "        self.source_l = lasagne.layers.ConcatLayer(\n",
    "            [self.document_aligned_l, self.surface_dens2]\n",
    "        )\n",
    "        \n",
    "        self.source_dens1 = lasagne.layers.DenseLayer(\n",
    "            self.source_l,\n",
    "            num_units=300,\n",
    "            name='source_dens1',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.source_drop1 = lasagne.layers.DropoutLayer(\n",
    "            self.source_dens1,\n",
    "            p=.25,\n",
    "        )\n",
    "        \n",
    "        self.source_dens2 = lasagne.layers.DenseLayer(\n",
    "            self.source_drop1,\n",
    "            num_units=300,\n",
    "            name='source_dens2',\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.source_out = lasagne.layers.get_output(self.source_dens2)\n",
    "        \n",
    "        self.target_input_l = lasagne.layers.InputLayer(\n",
    "            (None,self.sentence_length), \n",
    "            input_var=self.x_target_input\n",
    "        )\n",
    "        \n",
    "        self.target_embedding_l = EmbeddingLayer(\n",
    "            self.target_input_l,\n",
    "            W=self.embedding_W,\n",
    "            add_word_params=False,\n",
    "        )\n",
    "        \n",
    "        self.target_conv1_l = lasagne.layers.Conv2DLayer(\n",
    "            self.target_embedding_l,\n",
    "            name='target_conv1',\n",
    "            filter_size=(self.num_words_to_use_conv, self.wordvecs.vector_size),\n",
    "            num_filters=300,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.target_dens1 = lasagne.layers.DenseLayer(\n",
    "            self.target_conv1_l,\n",
    "            name='target_dens1',\n",
    "            num_units=300,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.target_drop1 = lasagne.layers.DropoutLayer(\n",
    "            self.target_dens1,\n",
    "            p=.25,\n",
    "        )\n",
    "        \n",
    "        self.target_dens2 = lasagne.layers.DenseLayer(\n",
    "            self.target_drop1,\n",
    "            name='target_dens2',\n",
    "            num_units=300,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "        )\n",
    "        \n",
    "        self.target_out = lasagne.layers.get_output(self.target_dens2)\n",
    "        \n",
    "        # compute the cosine distance between the two layers\n",
    "        self.source_aligned_l = self.source_out[self.x_link_id, :]\n",
    "        \n",
    "        # this uses scan internally, which means that it comes back into python code to run the loop.....fml\n",
    "        self.dotted_vectors =  T.batched_dot(self.target_out, self.source_aligned_l)\n",
    "        # diag also does not support a C version.........\n",
    "        #self.dotted_vectors = T.dot(self.target_out, self.source_aligned_l.T).diagonal()\n",
    "        \n",
    "        def augNorm(v):\n",
    "            return T.maximum(T.basic.pow(T.basic.pow(T.basic.abs_(v), 2).sum(axis=1) + .001, .5), .001)\n",
    "    \n",
    "        self.res_l = self.dotted_vectors / (augNorm(self.target_out) * augNorm(self.source_aligned_l) + .001)\n",
    "#         self.res_l = self.dotted_vectors / ((self.target_out.norm(1, axis=1) + .001) * \n",
    "#                                             (self.source_aligned_l.norm(1, axis=1) + .001))\n",
    "        \n",
    "    \n",
    "        self.all_params = (\n",
    "            lasagne.layers.get_all_params(self.target_dens2) + \n",
    "            lasagne.layers.get_all_params(self.source_dens2) +\n",
    "            lasagne.layers.get_all_params(self.document_dens2)\n",
    "        )\n",
    "        \n",
    "        self.loss_vec = T.nnet.binary_crossentropy(T.clip(self.res_l, .001, .999), self.y_score)\n",
    "        \n",
    "        self.updates = lasagne.updates.adadelta(self.loss_vec.mean(), self.all_params)\n",
    "        \n",
    "        self.train_func = theano.function(\n",
    "            [self.x_document_input,\n",
    "             self.x_surface_text_input, self.x_document_id,\n",
    "             self.x_target_input, self.x_link_id, self.y_score],\n",
    "            [self.res_l, self.loss_vec.sum(), self.loss_vec],\n",
    "            updates=self.updates\n",
    "        )\n",
    "        \n",
    "        self.test_func = theano.function(\n",
    "            [self.x_document_input,\n",
    "             self.x_surface_text_input, self.x_document_id,\n",
    "             self.x_target_input, self.x_link_id, self.y_score],\n",
    "            [self.res_l, self.loss_vec.sum(), self.loss_vec],\n",
    "        )\n",
    "        \n",
    "    def reset_accums(self):\n",
    "        self.current_documents = []\n",
    "        self.current_surface_text = []\n",
    "        self.current_link_id = []\n",
    "        self.current_target_input = []\n",
    "        self.current_target_id = []\n",
    "        self.current_target_goal = []\n",
    "        self.learning_targets = []\n",
    "        \n",
    "    def compute_batch(self, isTraining=True):\n",
    "        if isTraining:\n",
    "            func = self.train_func\n",
    "        else:\n",
    "            func = self.test_func\n",
    "        self.reset_accums()\n",
    "        self.total_links = 0\n",
    "        self.total_loss = 0.0\n",
    "        \n",
    "        for doc, queries in self.queries.iteritems():\n",
    "            # skip the testing documents while training and vice versa\n",
    "            if queries.values()[0]['training'] is not isTraining:\n",
    "                continue\n",
    "            docid = len(self.current_documents)\n",
    "            self.current_documents.append(self.wordvecs.tokenize(doc))\n",
    "            for surtxt, targets in queries.iteritems():\n",
    "                self.current_link_id.append(docid)\n",
    "                surid = len(self.current_surface_text)\n",
    "                self.current_surface_text.append(self.wordvecs.tokenize(surtxt))\n",
    "                for target in targets['vals'].keys():\n",
    "                    # skip the items that we don't know the gold for\n",
    "                    if not targets['gold'] and isTraining:\n",
    "                        continue\n",
    "                    isGold = target == targets['gold']\n",
    "                    cnt = self.page_content.get(WikiRegexes.convertToTitle(target))\n",
    "                    if cnt is None:\n",
    "                        # were not able to find this wikipedia document\n",
    "                        # so just ignore tihs result since trying to train on it will cause\n",
    "                        # issues\n",
    "                        continue\n",
    "                    self.current_target_input.append(cnt)  # page_content already tokenized\n",
    "                    self.current_target_id.append(surid)\n",
    "                    self.current_target_goal.append(isGold)\n",
    "                    self.learning_targets.append((targets, target))\n",
    "            if len(self.current_target_id) > self.batch_size:\n",
    "                self.run_batch(func)\n",
    "        \n",
    "        if len(self.current_target_id) > 0:\n",
    "            self.run_batch(func)\n",
    "            \n",
    "        return self.total_loss / self.total_links\n",
    "        \n",
    "    def run_batch(self, func):\n",
    "        res_vec, loss_sum, loss_vec = func(\n",
    "            self.current_documents,\n",
    "            self.current_surface_text, self.current_link_id,\n",
    "            self.current_target_input, self.current_target_id, self.current_target_goal\n",
    "        )\n",
    "        self.check_params()\n",
    "        self.total_links += len(self.current_target_id)\n",
    "        self.total_loss += loss_sum\n",
    "        for i in xrange(len(res_vec)):\n",
    "            # save the results from this pass\n",
    "            l = self.learning_targets[i]\n",
    "            l[0]['vals'][ l[1] ] = res_vec[i]\n",
    "        self.reset_accums()\n",
    "        \n",
    "    def check_params(self):\n",
    "        if any([np.isnan(v.get_value(borrow=True)).any() for v in self.all_params]):\n",
    "            raise RuntimeError('nan in some of the parameters')\n",
    "        \n",
    "\n",
    "        \n",
    "queries_exp = EntityVectorLinkExp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queries_exp.check_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_results = []\n",
    "\n",
    "for i in xrange(5):\n",
    "    exp_results.append((i, queries_exp.compute_batch()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.compute_batch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.48354288125508632),\n",
       " (1, 0.48579137888633872),\n",
       " (2, 0.48579137888633872),\n",
       " (3, 0.48579137888633872),\n",
       " (4, 0.48579137888633872)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'1921': {u'gold': u'1921',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.44725731,\n",
       "   u'144th New York State Legislature': -0.50102013,\n",
       "   u'1921': -0.50800377,\n",
       "   u'1921 APFA season': -0.45719814,\n",
       "   u'1921 Green Bay Packers season': -0.50838023,\n",
       "   u'1921 Indianapolis 500': -0.50247979,\n",
       "   u'1921 NFL season': 0,\n",
       "   u'1921 VFL season': -0.49588135,\n",
       "   u'1921 World Series': -0.53440392,\n",
       "   u'1921 college football season': -0.48402792,\n",
       "   u'1921 in Canada': -0.53343111,\n",
       "   u'1921 in aviation': -0.52454889,\n",
       "   u'1921 in film': -0.47799212,\n",
       "   u'1921 in literature': -0.46685761,\n",
       "   u'1921 in poetry': -0.49071518,\n",
       "   u'1921 in the United States': -0.49898821,\n",
       "   u'Canadian federal election, 1921': -0.4960916,\n",
       "   u'Irish elections, 1921': -0.51935321,\n",
       "   u'Norwegian parliamentary election, 1921': -0.47823888,\n",
       "   u'XXNILXX': 0}},\n",
       " u'1984': {u'gold': u'1984',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.52077299,\n",
       "   u'1984': -0.50411803,\n",
       "   u'1984 Grand Prix motorcycle racing season': -0.50146693,\n",
       "   u'1984 NBA draft': -0.53861326,\n",
       "   u'1984 NCAA Division I-A football season': -0.48836902,\n",
       "   u'1984 NFL season': -0.50622803,\n",
       "   u'1984 NHL Entry Draft': -0.51177466,\n",
       "   u'1984 Summer Olympics': -0.53941977,\n",
       "   u'1984 Winter Olympics': -0.53946108,\n",
       "   u'1984 in film': -0.49481541,\n",
       "   u'1984 in literature': -0.49707156,\n",
       "   u'1984 in music': -0.53282523,\n",
       "   u'1984 in television': -0.48893926,\n",
       "   u'1984 in video gaming': -0.55997092,\n",
       "   u'Australian federal election, 1984': -0.52321601,\n",
       "   u'Nineteen Eighty-Four': -0.50538307,\n",
       "   u'UEFA Euro 1984': -0.49493232,\n",
       "   u'United States House of Representatives elections, 1984': -0.54652238,\n",
       "   u'United States presidential election, 1984': -0.48242036,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Alfred Hitchcock': {u'gold': u'Alfred Hitchcock',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.455185,\n",
       "   u'Alfred Hitchcock': -0.53510338,\n",
       "   u'Alfred Hitchcock (book)': 0,\n",
       "   u'Alfred Hitchcock (police officer)': 0,\n",
       "   u'Cameron Hitchcock': -0.57876664,\n",
       "   u'E. Hitchcock': 0,\n",
       "   u'Edward Hitchcock': -0.52129102,\n",
       "   u'Hitchcock': 0,\n",
       "   u'Hitchcock (automobile)': -0.54393554,\n",
       "   u'Hitchcock (film)': -0.55284196,\n",
       "   u'Hitchcock County, Nebraska': -0.50554377,\n",
       "   u'Hitchcock, Oklahoma': -0.51050067,\n",
       "   u'Hitchcock, South Dakota': -0.53223187,\n",
       "   u'Hitchcock, Texas': -0.50920027,\n",
       "   u'Ken Hitchcock': -0.50891739,\n",
       "   u'Sterling Hitchcock': -0.50544101,\n",
       "   u'The Birds (film)': -0.52986532,\n",
       "   u'Tom Hitchcock': -0.49845386,\n",
       "   u'Tommy Hitchcock (racing driver)': 0,\n",
       "   u'XXNILXX': 0}},\n",
       " u'August 8': {u'gold': u'August 8',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.45266578,\n",
       "   u'/August': -0.46283489,\n",
       "   u'August': -0.47988752,\n",
       "   u'August (1996 film)': -0.50648201,\n",
       "   u'August (2008 film)': -0.46306005,\n",
       "   u'August (Eric Clapton album)': -0.50947511,\n",
       "   u'August (Fringe)': -0.49207926,\n",
       "   u'August (company)': -0.49715221,\n",
       "   u'August 1966': -0.52904677,\n",
       "   u'August 1971': -0.43684798,\n",
       "   u'August 1972': -0.51545554,\n",
       "   u'August 1973': -0.48168975,\n",
       "   u'August 1975': -0.4883396,\n",
       "   u'August 2007': -0.51215565,\n",
       "   u'August 8': -0.52321732,\n",
       "   u'August 8 (Eastern Orthodox liturgics)': -0.49874681,\n",
       "   u'August, California': -0.52514237,\n",
       "   u'CMLL Super Viernes (August 2014)': -0.51768589,\n",
       "   u'Papal conclave, August 1978': -0.47935462,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Boze Hadleigh': {u'gold': u'Boze Hadleigh',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.51158887,\n",
       "   u'Boze Hadleigh': -0.57779509,\n",
       "   u'Hadleigh': -0.55919367,\n",
       "   u'Hadleigh (TV series)': -0.49476394,\n",
       "   u'Hadleigh (disambiguation)': 0,\n",
       "   u'Hadleigh Airfield': 0,\n",
       "   u'Hadleigh Castle': -0.5534029,\n",
       "   u'Hadleigh railway station': -0.5892899,\n",
       "   u'Hadleigh, Essex': -0.54771817,\n",
       "   u'Hadleigh, Suffolk': -0.54069287,\n",
       "   u'RAF Hadleigh': 0,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Carousel': {u'gold': u'Carousel (film)',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.50149828,\n",
       "   u'Carousel': -0.53789085,\n",
       "   u'Carousel (1923 film)': -0.55384988,\n",
       "   u'Carousel (1956 film)': 0,\n",
       "   u'Carousel (Blink-182 song)': -0.51876026,\n",
       "   u'Carousel (Leila K album)': 0,\n",
       "   u'Carousel (TV channel)': -0.54471624,\n",
       "   u'Carousel (Vanessa Carlton song)': 0,\n",
       "   u'Carousel (advert)': 0,\n",
       "   u'Carousel (advertisement)': -0.51120937,\n",
       "   u'Carousel (album)': -0.53340667,\n",
       "   u'Carousel (ballet)': -0.52801037,\n",
       "   u'Carousel (film)': -0.51209939,\n",
       "   u'Carousel (musical)': -0.54782671,\n",
       "   u'Carousel slide projector': -0.54824263,\n",
       "   u'Cheshire Cat (Blink-182 album)': -0.51379955,\n",
       "   u'Ford Carousel': -0.53034353,\n",
       "   u'Rabbits on the Run': -0.52125347,\n",
       "   u'Westfield Carousel': -0.54826051,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Fred Rutherford': {u'gold': u'Fred Rutherford',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.48162115,\n",
       "   u'Alexander Cameron Rutherford': -0.55182356,\n",
       "   u'Ernest Rutherford': -0.54350454,\n",
       "   u'Fred Rutherford': -0.54758334,\n",
       "   u'Jock Rutherford': -0.57010716,\n",
       "   u'John Rutherford (rugby union)': -0.56193918,\n",
       "   u'Johnny Rutherford': -0.51654124,\n",
       "   u'Rutherford': -0.53406984,\n",
       "   u'Rutherford (NJT station)': -0.5471074,\n",
       "   u'Rutherford AVA': -0.57931453,\n",
       "   u'Rutherford County, North Carolina': -0.52294874,\n",
       "   u'Rutherford County, Tennessee': -0.52949387,\n",
       "   u'Rutherford GO Station': -0.54494739,\n",
       "   u'Rutherford, California': -0.51600975,\n",
       "   u'Rutherford, Edmonton': -0.49904275,\n",
       "   u'Rutherford, New Jersey': -0.55375504,\n",
       "   u'Rutherford, New South Wales': -0.54940617,\n",
       "   u'Rutherford, Pennsylvania': -0.56418902,\n",
       "   u'Rutherford, Tennessee': -0.56387037,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Gordon MacRae': {u'gold': u'Gordon MacRae',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.43666455,\n",
       "   u'Calum MacRae': -0.48098922,\n",
       "   u'Gordon MacRae': -0.51620764,\n",
       "   u'Jade MacRae': -0.51159197,\n",
       "   u'MacRae': -0.50416261,\n",
       "   u'MacRae (surname)': 0,\n",
       "   u'William MacRae': -0.46543944,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Hello , Dolly !': {u'gold': u'Hello, Dolly! (musical)',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.42393178,\n",
       "   u'Hello': -0.49223432,\n",
       "   u'Hello (2008 film)': -0.51292741,\n",
       "   u'Hello (Ice Cube song)': -0.50317681,\n",
       "   u'Hello (Lionel Richie song)': -0.53844434,\n",
       "   u'Hello (Martin Solveig song)': -0.4893105,\n",
       "   u'Hello (band)': -0.49754319,\n",
       "   u'Hello (magazine)': -0.46028918,\n",
       "   u'Hello ,': 0,\n",
       "   u'Hello , Dolly': 0,\n",
       "   u'Hello , Dolly !': 0,\n",
       "   u'Hello Dolly': -0.54698879,\n",
       "   u'Hello Dolly (film)': -0.53397572,\n",
       "   u'Hello Dolly (movie)': 0,\n",
       "   u'Hello Dolly (song)': -0.48072314,\n",
       "   u'Hello, Dolly!': -0.54025447,\n",
       "   u'Hello, Dolly! (film)': -0.51604378,\n",
       "   u'Hello, Dolly! (musical)': -0.50509572,\n",
       "   u'Hello, Dolly! (song)': -0.49564898,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Invasion of the Body Snatchers': {u'gold': u'Invasion of the Body Snatchers',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.52092683,\n",
       "   u'2003 invasion of Iraq': -0.551539,\n",
       "   u'Battle of France': -0.56423175,\n",
       "   u'Invasion': -0.53387803,\n",
       "   u'Invasion (1965 film)': -0.55704802,\n",
       "   u'Invasion (1997 film)': -0.5501911,\n",
       "   u'Invasion (TV series)': -0.57638162,\n",
       "   u'Invasion Body Snatchers': 0,\n",
       "   u'Invasion of': 0,\n",
       "   u'Invasion of Normandy': -0.57967418,\n",
       "   u'Invasion of Poland': -0.52422053,\n",
       "   u'Invasion of Poland (1939)': 0,\n",
       "   u'Invasion of the': 0,\n",
       "   u'Invasion of the Body': 0,\n",
       "   u'Invasion of the Body Snatchers': -0.58657181,\n",
       "   u'Invasion of the Body Snatchers (1956 film)': 0,\n",
       "   u'Invasion of the Body Snatchers (1978 film)': -0.58097214,\n",
       "   u'Invasion of the Body Snatchers (1978 film) ': 0,\n",
       "   u'The Invasion (professional wrestling)': -0.56978685,\n",
       "   u'XXNILXX': 0}},\n",
       " u'John Dehner': {u'gold': u'John Dehner',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.51925373,\n",
       "   u'Dehner': 0,\n",
       "   u'John Dehner': -0.5282554,\n",
       "   u'XXNILXX': 0}},\n",
       " u'May 14': {u'gold': u'May 14',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.46333101,\n",
       "   u'/May': -0.49397925,\n",
       "   u'Ben May': -0.49737206,\n",
       "   u'Brian May': -0.50755304,\n",
       "   u'CMLL Super Viernes (May 2014)': 0,\n",
       "   u'Darrell May': -0.49932578,\n",
       "   u'David May (footballer)': -0.49666607,\n",
       "   u'Jonny May': -0.50975639,\n",
       "   u'Kathy May': 0,\n",
       "   u'List of Pok\\xe9mon anime characters': -0.5161792,\n",
       "   u'May': -0.54522854,\n",
       "   u'May (Pok\\xe9mon)': 0,\n",
       "   u'May (film)': -0.50635105,\n",
       "   u'May 14': -0.49186176,\n",
       "   u'May 14 (Eastern Orthodox liturgics)': -0.50760067,\n",
       "   u'May, Oklahoma': -0.50952393,\n",
       "   u'May, Texas': -0.48057821,\n",
       "   u'Sean May': -0.50714546,\n",
       "   u'Stevie May': -0.45270145,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Philadelphia': {u'gold': u'Philadelphia',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.48014349,\n",
       "   u'2014\\u201315 Philadelphia Flyers season': -0.52016842,\n",
       "   u'Advanta Championships of Philadelphia': -0.54779488,\n",
       "   u'Ala\\u015fehir': -0.51795638,\n",
       "   u'Philadelphia': -0.48660007,\n",
       "   u'Philadelphia (film)': -0.5260554,\n",
       "   u'Philadelphia (magazine)': -0.53707325,\n",
       "   u'Philadelphia 76ers': -0.53223771,\n",
       "   u'Philadelphia County, Pennsylvania': -0.49317989,\n",
       "   u'Philadelphia Eagles': -0.52895671,\n",
       "   u'Philadelphia Flyers': -0.51402062,\n",
       "   u'Philadelphia International Airport': -0.53228712,\n",
       "   u'Philadelphia Phantoms': -0.54373395,\n",
       "   u'Philadelphia Phillies': -0.50051266,\n",
       "   u'Philadelphia Union': -0.53745639,\n",
       "   u'Philadelphia, Mississippi': -0.52503324,\n",
       "   u'Philadelphia, Pennsylvania': 0,\n",
       "   u'Roman Catholic Archdiocese of Philadelphia': -0.49942347,\n",
       "   u'U.S. Pro Indoor': -0.5083974,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Phyllis Diller': {u'gold': u'Phyllis Diller',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.44061005,\n",
       "   u'Diller': -0.46780905,\n",
       "   u'Diller Glacier': -0.46780828,\n",
       "   u'Diller, Nebraska': -0.44370264,\n",
       "   u'LeGrande A. Diller': 0,\n",
       "   u'Phyllis Diller': -0.48779622,\n",
       "   u'XXNILXX': 0}},\n",
       " u'Shirley Jones': {u'gold': u'Shirley Jones',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.52855331,\n",
       "   u'Asjha Jones': -0.5128662,\n",
       "   u'Jermaine Jones': -0.52031082,\n",
       "   u'Jone': -0.53964913,\n",
       "   u'Jone (band)': 0,\n",
       "   u'Jone (opera)': -0.54522771,\n",
       "   u'Jone Pedro': 0,\n",
       "   u'Jone da Silva Pinto': 0,\n",
       "   u'Jones': -0.54243684,\n",
       "   u'Jones County, Texas': -0.52773196,\n",
       "   u'Kenwyne Jones': -0.55848271,\n",
       "   u'Nathan Jones (Australian rules footballer)': -0.51196498,\n",
       "   u'Shirley Jones': -0.5099929,\n",
       "   u'Shirley Jones (R&amp;B singer)': -0.50915939,\n",
       "   u'Shirley Jones (horse)': 0,\n",
       "   u'Shirley Jones (politician)': 0,\n",
       "   u'Stacey Jones': -0.52341968,\n",
       "   u'The Jones Girls': -0.51060236,\n",
       "   u'Todd Jones': -0.50831026,\n",
       "   u'XXNILXX': 0}},\n",
       " u'The Addams Family': {u'gold': u'The Addams Family',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.45547304,\n",
       "   u'Addams Family': 0,\n",
       "   u'Addams Family (pinball)': 0,\n",
       "   u\"Children's film\": -0.50636584,\n",
       "   u'Family': -0.47360879,\n",
       "   u'Family (1976 TV series)': -0.52436292,\n",
       "   u'Family (band)': -0.49320483,\n",
       "   u'Family (biology)': -0.50619847,\n",
       "   u'Family Channel': -0.49114448,\n",
       "   u'The Addams Family': -0.52749956,\n",
       "   u'The Addams Family (1964 TV series)': -0.48547029,\n",
       "   u'The Addams Family (1973 animated series)': -0.49930054,\n",
       "   u'The Addams Family (1992 animated series)': -0.50192082,\n",
       "   u'The Addams Family (film)': -0.48763412,\n",
       "   u'The Addams Family (musical)': -0.50849313,\n",
       "   u'The Addams Family (pinball)': -0.50882864,\n",
       "   u'The Addams Family (video game)': -0.50224102,\n",
       "   u'The Addams Family Theme': -0.48696828,\n",
       "   u'XXNILXX': 0,\n",
       "   u'family (biology)': -0.48824418}},\n",
       " u'The Birds': {u'gold': u'The Birds (film)',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.52158922,\n",
       "   u'Bird': -0.5116384,\n",
       "   u'Bird (disambiguation)': -0.51269156,\n",
       "   u'Bird (film)': -0.57052642,\n",
       "   u'Birds': 0,\n",
       "   u'Birds (Anouk song)': -0.54103291,\n",
       "   u'Birds (Bic Runga album)': -0.57733178,\n",
       "   u'Birds (Kate Nash song)': -0.50796634,\n",
       "   u'Birds, Illinois': -0.56183171,\n",
       "   u'Greg Bird': -0.55842823,\n",
       "   u'Larry Bird': -0.51560491,\n",
       "   u'Ryan Bird': -0.55405563,\n",
       "   u'Sue Bird': -0.58610386,\n",
       "   u'The Birds': 0,\n",
       "   u'The Birds (Respighi)': -0.53834933,\n",
       "   u'The Birds (band)': -0.53721148,\n",
       "   u'The Birds (film)': -0.56833899,\n",
       "   u'The Birds (play)': -0.56123483,\n",
       "   u'The Birds (story)': -0.55288661,\n",
       "   u'XXNILXX': 0}},\n",
       " u'The Dick Van Dyke Show': {u'gold': u'The Dick Van Dyke Show',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.54003793,\n",
       "   u'Agricultural show': -0.56855518,\n",
       "   u'Days of Our Lives': -0.5382458,\n",
       "   u'Days of our Lives': -0.51262397,\n",
       "   u'Dick Van Dyke Show': 0,\n",
       "   u'Dyke Show': 0,\n",
       "   u'Eric Show': -0.52934593,\n",
       "   u'General Hospital': -0.56353372,\n",
       "   u'Show': -0.53913873,\n",
       "   u'Show (The Cure album)': -0.50965303,\n",
       "   u'Show (The Jesus Lizard album)': -0.55422896,\n",
       "   u'Show (film)': -0.58484381,\n",
       "   u'Show (magazine)': -0.5805251,\n",
       "   u'Showbiz (producer)': 0,\n",
       "   u'Showbiz and A.G.': -0.53896254,\n",
       "   u'The Dick Van Dyke Show': -0.52607661,\n",
       "   u'The Dick Van Dyke Show ': 0,\n",
       "   u'The Van Dyke Show': -0.51111579,\n",
       "   u'Van Dyke Show': 0,\n",
       "   u'XXNILXX': 0}},\n",
       " u'The Mothers-in-Law': {u'gold': u'The Mothers-in-Law',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.49521333,\n",
       "   u'Mothers-in-Law': 0,\n",
       "   u'The Mothers-in-Law': -0.53776157,\n",
       "   u'XXNILXX': 0}},\n",
       " u'character actor': {u'gold': u'Character actor',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.53867698,\n",
       "   u'Academy Award for Best Actor': -0.54637265,\n",
       "   u'Acting': -0.53630221,\n",
       "   u'Actor': -0.55748433,\n",
       "   u'Actor (UML)': -0.56299049,\n",
       "   u'Actor (album)': -0.55887055,\n",
       "   u'Actor (mythology)': -0.56323069,\n",
       "   u'Character actor': -0.56091404,\n",
       "   u'Film actor': 0,\n",
       "   u'Golden Globe Award for Best Actor \\u2013 Miniseries or Television Film': -0.54751837,\n",
       "   u'Golden Globe Award for Best Actor \\u2013 Motion Picture Drama': -0.57181472,\n",
       "   u'Golden Globe Award for Best Actor \\u2013 Motion Picture Musical or Comedy': -0.56271279,\n",
       "   u'Pornographic film actor': -0.54601055,\n",
       "   u'XXNILXX': 0,\n",
       "   u'acting': -0.55877519,\n",
       "   u'actor': -0.57138741,\n",
       "   u'character actor': -0.5685668,\n",
       "   u'film actor': 0,\n",
       "   u'pornographic actor': 0,\n",
       "   u'television actor': 0}},\n",
       " u'chef': {u'gold': u'Chef',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.47860512,\n",
       "   u'Celebrity chef': -0.51715487,\n",
       "   u'Chef': -0.50184572,\n",
       "   u'Chef (2014 film)': 0,\n",
       "   u'Chef (South Park character)': 0,\n",
       "   u'Chef (South Park)': -0.5243848,\n",
       "   u'Chef (company)': -0.50981933,\n",
       "   u'Chef (film)': -0.53613734,\n",
       "   u'Chef (programming language)': 0,\n",
       "   u'Chef (software)': -0.50067037,\n",
       "   u\"Chef's uniform\": -0.50838727,\n",
       "   u'Cook (profession)': -0.53988761,\n",
       "   u'Isaac Hayes': -0.52077329,\n",
       "   u'Japanese cuisine': -0.50514531,\n",
       "   u'Magician': -0.50618958,\n",
       "   u'Michael Smith (chef)': -0.49939251,\n",
       "   u'Swedish Chef': -0.47871971,\n",
       "   u'XXNILXX': 0,\n",
       "   u'celebrity chef': -0.49591887,\n",
       "   u'chef': -0.54626298}},\n",
       " u'cookbook': {u'gold': u'cookbook',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.50409168,\n",
       "   u'Cookbook': -0.50430411,\n",
       "   u\"Nanny Ogg's Cookbook\": -0.51469296,\n",
       "   u'XXNILXX': 0,\n",
       "   u'cookbook': -0.53809059}},\n",
       " u'microwave': {u'gold': u'Microwave oven',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.46574548,\n",
       "   u'British Telecom microwave network': -0.50958246,\n",
       "   u'Cavalier Computer': -0.48955449,\n",
       "   u'EM spectrum': 0,\n",
       "   u'Electromagnetic spectrum': -0.49958524,\n",
       "   u'Microwave': -0.4922182,\n",
       "   u'Microwave (game)': 0,\n",
       "   u'Microwave chemistry': -0.50673074,\n",
       "   u'Microwave oven': -0.52164084,\n",
       "   u'Microwave radio relay': 0,\n",
       "   u'Microwave radiometer': -0.52328694,\n",
       "   u'Microwave spectroscopy': 0,\n",
       "   u'Microwave transmission': -0.48534441,\n",
       "   u'Microwaves': 0,\n",
       "   u'Rotational spectroscopy': -0.5055207,\n",
       "   u'Waldorf Microwave': 0,\n",
       "   u'XXNILXX': 0,\n",
       "   u'microwave': -0.50719696,\n",
       "   u'microwave oven': -0.53357142,\n",
       "   u'microwave transmission': -0.47732705}},\n",
       " u'physician': {u'gold': u'Physician',\n",
       "  u'training': True,\n",
       "  u'vals': {u'-NIL-': -0.50492203,\n",
       "   u'Doctor of Medicine': -0.50168985,\n",
       "   u'General practitioner': -0.49731085,\n",
       "   u'Internal medicine': -0.50830442,\n",
       "   u'Islamic medicine': 0,\n",
       "   u'John Snow (physician)': -0.51912665,\n",
       "   u'Medicine': -0.50328642,\n",
       "   u'Medicine in medieval Islam': 0,\n",
       "   u'Medicine in the medieval Islamic world': -0.50034261,\n",
       "   u'Physician': -0.4969874,\n",
       "   u'Physician (horse)': 0,\n",
       "   u'Physics': -0.50309241,\n",
       "   u'Physiology': -0.52638692,\n",
       "   u\"Ship's doctor\": -0.52863151,\n",
       "   u'Traditional Chinese medicine': -0.49747801,\n",
       "   u'XXNILXX': 0,\n",
       "   u'medical doctor': 0,\n",
       "   u'medicine': -0.50487047,\n",
       "   u'physician': -0.53438717,\n",
       "   u'physiology': -0.52940363}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gg_res = queries_exp.test_func(\n",
    "    queries_exp.current_documents, \n",
    "    queries_exp.current_surface_text, queries_exp.current_link_id,\n",
    "    queries_exp.current_target_input, queries_exp.current_target_id, queries_exp.current_target_goal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.isnan(gg_res[0]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(v, np.isnan(v.get_value(borrow=True)).all()) for v in queries_exp.all_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.total_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano.printing.pydotprint(T.grad(queries_exp.loss_vec.mean(), queries_exp.all_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_func = theano.function(\n",
    "            [queries_exp.x_document_input,\n",
    "             queries_exp.x_surface_text_input, queries_exp.x_document_id,\n",
    "             queries_exp.x_target_input, queries_exp.x_link_id, queries_exp.y_score],\n",
    "            T.grad(queries_exp.loss_vec.mean(), lasagne.layers.get_all_params(queries_exp.target_dens2)),\n",
    "#           T.grad(queries_exp.loss_vec.mean(), queries_exp.all_params),\n",
    "    #             [queries_exp.target_out, queries_exp.source_aligned_l, \n",
    "#              T.dot(queries_exp.target_out, queries_exp.source_aligned_l.T).diagonal(),\n",
    "#              queries_exp.target_out.norm(2, axis=1) * queries_exp.source_aligned_l.norm(2, axis=1),\n",
    "#              T.batched_dot(queries_exp.target_out, queries_exp.source_aligned_l),\n",
    "#              lasagne.layers.get_output(queries_exp.target_dens2),\n",
    "#              queries_exp.target_out.norm(2, axis=1),\n",
    "#              #T.grad(queries_exp.loss_vec.mean(), queries_exp.all_params)\n",
    "#             ],\n",
    "        #[queries_exp.res_l, queries_exp.loss_vec.sum(), queries_exp.loss_vec],\n",
    "    on_unused_input='ignore',\n",
    "    mode='DebugMode'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    gg_grad_res = gg_func(\n",
    "        queries_exp.current_documents,\n",
    "        queries_exp.current_surface_text, queries_exp.current_link_id,\n",
    "        queries_exp.current_target_input, queries_exp.current_target_id, queries_exp.current_target_goal\n",
    "    )\n",
    "except Exception as e:\n",
    "    eeee = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[np.isnan(v).any() for v in gg_grad_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eeee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_target_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res = gg_func(\n",
    "    queries_exp.current_documents,\n",
    "    queries_exp.current_surface_text, queries_exp.current_link_id,\n",
    "    queries_exp.current_target_input, queries_exp.current_target_id, queries_exp.current_target_goal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_target_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.isnan(gg_res[5]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[0].shape, gg_res[1].shape, gg_res[2].shape, gg_res[3].shape, gg_res[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.inner(gg_res[0], gg_res[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[0] * gg_res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = np.dot(gg_res[0], gg_res[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa.diagonal().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gg_res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.queried_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_surface_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_link_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_target_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_results = []\n",
    "\n",
    "for i in xrange(5):\n",
    "    exp_results.append((i, queries_exp.compute_batch()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.total_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.total_loss / queries_exp.total_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(queries_exp.current_target_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries_exp.compute_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time queries_exp.run_batch(queries_exp.test_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
